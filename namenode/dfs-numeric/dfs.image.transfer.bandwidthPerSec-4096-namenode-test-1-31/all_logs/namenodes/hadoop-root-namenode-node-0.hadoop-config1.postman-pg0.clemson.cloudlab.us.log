2019-03-26 07:37:01,590 INFO  namenode.NameNode LogAdapter.java:info:51 - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode059.clemson.cloudlab.us/130.127.133.68
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-03-17T18:59Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-03-26 07:37:01,602 INFO  namenode.NameNode LogAdapter.java:info:51 - registered UNIX signal handlers for [TERM, HUP, INT]
2019-03-26 07:37:01,607 INFO  namenode.NameNode NameNode.java:createNameNode:1583 - createNameNode []
2019-03-26 07:37:01,853 INFO  beanutils.FluentPropertyBeanIntrospector FluentPropertyBeanIntrospector.java:introspect:147 - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2019-03-26 07:37:01,896 INFO  impl.MetricsConfig MetricsConfig.java:loadFirst:121 - loaded properties from hadoop-metrics2.properties
2019-03-26 07:37:02,000 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:startTimer:374 - Scheduled Metric snapshot period at 10 second(s).
2019-03-26 07:37:02,000 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:start:191 - NameNode metrics system started
2019-03-26 07:37:02,052 INFO  namenode.NameNodeUtils NameNodeUtils.java:getClientNamenodeAddress:79 - fs.defaultFS is hdfs://mycluster
2019-03-26 07:37:02,053 INFO  namenode.NameNode NameNode.java:<init>:928 - Clients should use mycluster to access this namenode/service.
2019-03-26 07:37:02,217 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:188 - Starting JVM pause monitor
2019-03-26 07:37:02,245 INFO  hdfs.DFSUtil DFSUtil.java:httpServerTemplateForNNAndJN:1605 - Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-03-26 07:37:02,262 INFO  util.log Log.java:initialized:192 - Logging initialized @1191ms
2019-03-26 07:37:02,371 INFO  server.AuthenticationFilter AuthenticationFilter.java:constructSecretProvider:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-03-26 07:37:02,384 INFO  http.HttpRequestLog HttpRequestLog.java:getRequestLog:81 - Http request log for http.requests.namenode is not defined
2019-03-26 07:37:02,395 INFO  http.HttpServer2 HttpServer2.java:addGlobalFilter:968 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-03-26 07:37:02,397 INFO  http.HttpServer2 HttpServer2.java:addFilter:941 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-03-26 07:37:02,399 INFO  http.HttpServer2 HttpServer2.java:addFilter:951 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-03-26 07:37:02,399 INFO  http.HttpServer2 HttpServer2.java:addFilter:951 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-03-26 07:37:02,426 INFO  http.HttpServer2 NameNodeHttpServer.java:initWebHdfs:100 - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-03-26 07:37:02,426 INFO  http.HttpServer2 HttpServer2.java:addJerseyResourcePackage:787 - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-03-26 07:37:02,435 INFO  http.HttpServer2 HttpServer2.java:bindListener:1185 - Jetty bound to port 9870
2019-03-26 07:37:02,436 INFO  server.Server Server.java:doStart:346 - jetty-9.3.19.v20170502
2019-03-26 07:37:02,472 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@221a3fa4{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-03-26 07:37:02,473 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@2b40ff9c{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-03-26 07:37:02,548 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.w.WebAppContext@6c7a164b{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-03-26 07:37:02,567 INFO  server.AbstractConnector AbstractConnector.java:doStart:278 - Started ServerConnector@1cf56a1c{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-03-26 07:37:02,567 INFO  server.Server Server.java:doStart:414 - Started @1498ms
2019-03-26 07:37:02,902 WARN  namenode.FSNamesystem FSNamesystem.java:checkConfiguration:680 - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-03-26 07:37:02,952 INFO  namenode.FSEditLog FSEditLog.java:newInstance:227 - Edit logging is async:true
2019-03-26 07:37:02,966 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:749 - KeyProvider: null
2019-03-26 07:37:02,968 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:122 - fsLock is fair: true
2019-03-26 07:37:02,970 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:138 - Detailed lock hold time metrics enabled: false
2019-03-26 07:37:02,977 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:774 - fsOwner             = root (auth:SIMPLE)
2019-03-26 07:37:02,977 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:775 - supergroup          = supergroup
2019-03-26 07:37:02,977 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:776 - isPermissionEnabled = true
2019-03-26 07:37:02,978 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:785 - Determined nameservice ID: mycluster
2019-03-26 07:37:02,978 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:787 - HA Enabled: true
2019-03-26 07:37:03,020 INFO  common.Util Util.java:isDiskStatsEnabled:395 - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-03-26 07:37:03,033 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:301 - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-03-26 07:37:03,033 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:309 - dfs.namenode.datanode.registration.ip-hostname-check=true
2019-03-26 07:37:03,038 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:79 - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-03-26 07:37:03,038 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:85 - The block deletion will start around 2019 Mar 26 07:37:03
2019-03-26 07:37:03,040 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map BlocksMap
2019-03-26 07:37:03,040 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-26 07:37:03,042 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 2.0% max memory 26.7 GB = 546.1 MB
2019-03-26 07:37:03,042 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^26 = 67108864 entries
2019-03-26 07:37:03,178 INFO  blockmanagement.BlockManager BlockManager.java:createBlockTokenSecretManager:579 - dfs.block.access.token.enable = false
2019-03-26 07:37:03,187 INFO  Configuration.deprecation Configuration.java:logDeprecation:1395 - No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-03-26 07:37:03,187 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:161 - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-03-26 07:37:03,187 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:162 - dfs.namenode.safemode.min.datanodes = 0
2019-03-26 07:37:03,188 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:164 - dfs.namenode.safemode.extension = 30000
2019-03-26 07:37:03,188 INFO  blockmanagement.BlockManager BlockManager.java:<init>:565 - defaultReplication         = 3
2019-03-26 07:37:03,188 INFO  blockmanagement.BlockManager BlockManager.java:<init>:566 - maxReplication             = 512
2019-03-26 07:37:03,188 INFO  blockmanagement.BlockManager BlockManager.java:<init>:567 - minReplication             = 1
2019-03-26 07:37:03,188 INFO  blockmanagement.BlockManager BlockManager.java:<init>:568 - maxReplicationStreams      = 2
2019-03-26 07:37:03,188 INFO  blockmanagement.BlockManager BlockManager.java:<init>:569 - redundancyRecheckInterval  = 3000ms
2019-03-26 07:37:03,188 INFO  blockmanagement.BlockManager BlockManager.java:<init>:570 - encryptDataTransfer        = false
2019-03-26 07:37:03,189 INFO  blockmanagement.BlockManager BlockManager.java:<init>:571 - maxNumBlocksToLog          = 1000
2019-03-26 07:37:03,272 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map INodeMap
2019-03-26 07:37:03,272 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-26 07:37:03,273 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 1.0% max memory 26.7 GB = 273.0 MB
2019-03-26 07:37:03,273 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^25 = 33554432 entries
2019-03-26 07:37:03,346 INFO  namenode.FSDirectory FSDirectory.java:<init>:283 - ACLs enabled? false
2019-03-26 07:37:03,346 INFO  namenode.FSDirectory FSDirectory.java:<init>:287 - POSIX ACL inheritance enabled? true
2019-03-26 07:37:03,346 INFO  namenode.FSDirectory FSDirectory.java:<init>:291 - XAttrs enabled? true
2019-03-26 07:37:03,346 INFO  namenode.NameNode FSDirectory.java:<init>:355 - Caching file names occurring more than 10 times
2019-03-26 07:37:03,353 INFO  snapshot.SnapshotManager SnapshotManager.java:<init>:124 - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-03-26 07:37:03,356 INFO  snapshot.SnapshotManager DirectoryDiffListFactory.java:init:43 - SkipList is disabled
2019-03-26 07:37:03,361 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map cachedBlocks
2019-03-26 07:37:03,362 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-26 07:37:03,362 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.25% max memory 26.7 GB = 68.3 MB
2019-03-26 07:37:03,362 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^23 = 8388608 entries
2019-03-26 07:37:03,390 INFO  metrics.TopMetrics TopMetrics.java:logConf:76 - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-03-26 07:37:03,390 INFO  metrics.TopMetrics TopMetrics.java:logConf:78 - NNTop conf: dfs.namenode.top.num.users = 10
2019-03-26 07:37:03,390 INFO  metrics.TopMetrics TopMetrics.java:logConf:80 - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-03-26 07:37:03,394 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:979 - Retry cache on namenode is enabled
2019-03-26 07:37:03,394 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:987 - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-03-26 07:37:03,397 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map NameNodeRetryCache
2019-03-26 07:37:03,397 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-26 07:37:03,397 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-03-26 07:37:03,397 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^20 = 1048576 entries
2019-03-26 07:37:03,467 INFO  common.Storage Storage.java:tryLock:905 - Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 100065@clnode059.clemson.cloudlab.us
2019-03-26 07:37:04,808 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:205 - Detected pause in JVM or host machine (eg GC): pause of approximately 1086ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=340ms
GC pool 'PS Scavenge' had collection(s): count=1 time=878ms
2019-03-26 07:37:04,966 INFO  namenode.FSImage FSImage.java:loadFSImage:718 - No edit log streams selected.
2019-03-26 07:37:04,966 INFO  namenode.FSImage FSImage.java:loadFSImageFile:782 - Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-03-26 07:37:05,029 INFO  namenode.ErasureCodingPolicyManager ErasureCodingPolicyManager.java:enablePolicy:390 - Enable the erasure coding policy RS-6-3-1024k
2019-03-26 07:37:05,031 INFO  namenode.FSImageFormatPBINode FSImageFormatPBINode.java:loadINodeSection:266 - Loading 1 INodes.
2019-03-26 07:37:05,062 INFO  namenode.FSImageFormatProtobuf FSImageFormatProtobuf.java:load:190 - Loaded FSImage in 0 seconds.
2019-03-26 07:37:05,062 INFO  namenode.FSImage FSImage.java:loadFSImage:951 - Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-03-26 07:37:05,068 INFO  namenode.FSNamesystem FSNamesystem.java:loadFSImage:1091 - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-03-26 07:37:05,068 INFO  namenode.NameCache NameCache.java:initialized:143 - initialized with 0 entries 0 lookups
2019-03-26 07:37:05,068 INFO  namenode.FSNamesystem FSNamesystem.java:loadFromDisk:721 - Finished loading FSImage in 1662 msecs
2019-03-26 07:37:05,247 INFO  namenode.NameNode NameNodeRpcServer.java:<init>:446 - RPC server is binding to node-0-link-0:8020
2019-03-26 07:37:05,252 INFO  ipc.CallQueueManager CallQueueManager.java:<init>:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-03-26 07:37:05,265 INFO  ipc.Server Server.java:run:1070 - Starting Socket Reader #1 for port 8020
2019-03-26 07:37:05,452 INFO  namenode.FSNamesystem FSNamesystem.java:registerMBean:4973 - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-03-26 07:37:05,460 INFO  namenode.LeaseManager LeaseManager.java:getNumUnderConstructionBlocks:171 - Number of blocks under construction: 0
2019-03-26 07:37:05,471 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:396 - STATE* Leaving safe mode after 0 secs
2019-03-26 07:37:05,471 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:402 - STATE* Network topology has 0 racks and 0 datanodes
2019-03-26 07:37:05,471 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:404 - STATE* UnderReplicatedBlocks has 0 blocks
2019-03-26 07:37:05,505 INFO  ipc.Server Server.java:run:1310 - IPC Server Responder: starting
2019-03-26 07:37:05,505 INFO  ipc.Server Server.java:run:1149 - IPC Server listener on 8020: starting
2019-03-26 07:37:05,508 INFO  namenode.NameNode NameNode.java:startCommonServices:812 - NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-03-26 07:37:05,511 INFO  namenode.FSNamesystem FSNamesystem.java:startStandbyServices:1365 - Starting services required for standby state
2019-03-26 07:37:05,516 INFO  ha.EditLogTailer EditLogTailer.java:<init>:188 - Will roll logs on active node every 120 seconds.
2019-03-26 07:37:05,522 INFO  ha.StandbyCheckpointer StandbyCheckpointer.java:start:139 - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-03-26 07:37:10,549 INFO  namenode.TransferFsImage TransferFsImage.java:copyFileToStream:396 - Sending fileName: /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, fileSize: 389. Sent total: 389 bytes. Size of last segment intended to send: -1 bytes.
2019-03-26 07:37:10,725 ERROR namenode.NameNode LogAdapter.java:error:75 - RECEIVED SIGNAL 15: SIGTERM
2019-03-26 07:37:10,727 INFO  namenode.NameNode LogAdapter.java:info:51 - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at clnode059.clemson.cloudlab.us/130.127.133.68
************************************************************/
2019-03-26 07:37:26,748 INFO  namenode.NameNode LogAdapter.java:info:51 - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode059.clemson.cloudlab.us/130.127.133.68
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-03-17T18:59Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-03-26 07:37:26,761 INFO  namenode.NameNode LogAdapter.java:info:51 - registered UNIX signal handlers for [TERM, HUP, INT]
2019-03-26 07:37:26,766 INFO  namenode.NameNode NameNode.java:createNameNode:1583 - createNameNode []
2019-03-26 07:37:27,008 INFO  beanutils.FluentPropertyBeanIntrospector FluentPropertyBeanIntrospector.java:introspect:147 - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2019-03-26 07:37:27,052 INFO  impl.MetricsConfig MetricsConfig.java:loadFirst:121 - loaded properties from hadoop-metrics2.properties
2019-03-26 07:37:27,157 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:startTimer:374 - Scheduled Metric snapshot period at 10 second(s).
2019-03-26 07:37:27,157 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:start:191 - NameNode metrics system started
2019-03-26 07:37:27,209 INFO  namenode.NameNodeUtils NameNodeUtils.java:getClientNamenodeAddress:79 - fs.defaultFS is hdfs://mycluster
2019-03-26 07:37:27,209 INFO  namenode.NameNode NameNode.java:<init>:928 - Clients should use mycluster to access this namenode/service.
2019-03-26 07:37:27,376 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:188 - Starting JVM pause monitor
2019-03-26 07:37:27,403 INFO  hdfs.DFSUtil DFSUtil.java:httpServerTemplateForNNAndJN:1605 - Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-03-26 07:37:27,421 INFO  util.log Log.java:initialized:192 - Logging initialized @1190ms
2019-03-26 07:37:27,530 INFO  server.AuthenticationFilter AuthenticationFilter.java:constructSecretProvider:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-03-26 07:37:27,543 INFO  http.HttpRequestLog HttpRequestLog.java:getRequestLog:81 - Http request log for http.requests.namenode is not defined
2019-03-26 07:37:27,554 INFO  http.HttpServer2 HttpServer2.java:addGlobalFilter:968 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-03-26 07:37:27,557 INFO  http.HttpServer2 HttpServer2.java:addFilter:941 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-03-26 07:37:27,558 INFO  http.HttpServer2 HttpServer2.java:addFilter:951 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-03-26 07:37:27,558 INFO  http.HttpServer2 HttpServer2.java:addFilter:951 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-03-26 07:37:27,585 INFO  http.HttpServer2 NameNodeHttpServer.java:initWebHdfs:100 - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-03-26 07:37:27,585 INFO  http.HttpServer2 HttpServer2.java:addJerseyResourcePackage:787 - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-03-26 07:37:27,594 INFO  http.HttpServer2 HttpServer2.java:bindListener:1185 - Jetty bound to port 9870
2019-03-26 07:37:27,596 INFO  server.Server Server.java:doStart:346 - jetty-9.3.19.v20170502
2019-03-26 07:37:27,631 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@221a3fa4{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-03-26 07:37:27,632 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@2b40ff9c{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-03-26 07:37:27,707 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.w.WebAppContext@6c7a164b{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-03-26 07:37:27,723 INFO  server.AbstractConnector AbstractConnector.java:doStart:278 - Started ServerConnector@1cf56a1c{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-03-26 07:37:27,723 INFO  server.Server Server.java:doStart:414 - Started @1494ms
2019-03-26 07:37:28,059 WARN  namenode.FSNamesystem FSNamesystem.java:checkConfiguration:680 - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-03-26 07:37:28,109 INFO  namenode.FSEditLog FSEditLog.java:newInstance:227 - Edit logging is async:true
2019-03-26 07:37:28,123 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:749 - KeyProvider: null
2019-03-26 07:37:28,125 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:122 - fsLock is fair: true
2019-03-26 07:37:28,128 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:138 - Detailed lock hold time metrics enabled: false
2019-03-26 07:37:28,134 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:774 - fsOwner             = root (auth:SIMPLE)
2019-03-26 07:37:28,135 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:775 - supergroup          = supergroup
2019-03-26 07:37:28,135 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:776 - isPermissionEnabled = true
2019-03-26 07:37:28,135 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:785 - Determined nameservice ID: mycluster
2019-03-26 07:37:28,135 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:787 - HA Enabled: true
2019-03-26 07:37:28,178 INFO  common.Util Util.java:isDiskStatsEnabled:395 - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-03-26 07:37:28,190 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:301 - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-03-26 07:37:28,190 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:309 - dfs.namenode.datanode.registration.ip-hostname-check=true
2019-03-26 07:37:28,195 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:79 - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-03-26 07:37:28,196 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:85 - The block deletion will start around 2019 Mar 26 07:37:28
2019-03-26 07:37:28,198 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map BlocksMap
2019-03-26 07:37:28,198 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-26 07:37:28,199 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 2.0% max memory 26.7 GB = 546.1 MB
2019-03-26 07:37:28,200 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^26 = 67108864 entries
2019-03-26 07:37:28,333 INFO  blockmanagement.BlockManager BlockManager.java:createBlockTokenSecretManager:579 - dfs.block.access.token.enable = false
2019-03-26 07:37:28,342 INFO  Configuration.deprecation Configuration.java:logDeprecation:1395 - No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-03-26 07:37:28,342 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:161 - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-03-26 07:37:28,343 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:162 - dfs.namenode.safemode.min.datanodes = 0
2019-03-26 07:37:28,343 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:164 - dfs.namenode.safemode.extension = 30000
2019-03-26 07:37:28,343 INFO  blockmanagement.BlockManager BlockManager.java:<init>:565 - defaultReplication         = 3
2019-03-26 07:37:28,343 INFO  blockmanagement.BlockManager BlockManager.java:<init>:566 - maxReplication             = 512
2019-03-26 07:37:28,343 INFO  blockmanagement.BlockManager BlockManager.java:<init>:567 - minReplication             = 1
2019-03-26 07:37:28,343 INFO  blockmanagement.BlockManager BlockManager.java:<init>:568 - maxReplicationStreams      = 2
2019-03-26 07:37:28,343 INFO  blockmanagement.BlockManager BlockManager.java:<init>:569 - redundancyRecheckInterval  = 3000ms
2019-03-26 07:37:28,343 INFO  blockmanagement.BlockManager BlockManager.java:<init>:570 - encryptDataTransfer        = false
2019-03-26 07:37:28,344 INFO  blockmanagement.BlockManager BlockManager.java:<init>:571 - maxNumBlocksToLog          = 1000
2019-03-26 07:37:28,437 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map INodeMap
2019-03-26 07:37:28,437 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-26 07:37:28,437 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 1.0% max memory 26.7 GB = 273.0 MB
2019-03-26 07:37:28,438 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^25 = 33554432 entries
2019-03-26 07:37:28,512 INFO  namenode.FSDirectory FSDirectory.java:<init>:283 - ACLs enabled? false
2019-03-26 07:37:28,512 INFO  namenode.FSDirectory FSDirectory.java:<init>:287 - POSIX ACL inheritance enabled? true
2019-03-26 07:37:28,513 INFO  namenode.FSDirectory FSDirectory.java:<init>:291 - XAttrs enabled? true
2019-03-26 07:37:28,513 INFO  namenode.NameNode FSDirectory.java:<init>:355 - Caching file names occurring more than 10 times
2019-03-26 07:37:28,520 INFO  snapshot.SnapshotManager SnapshotManager.java:<init>:124 - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-03-26 07:37:28,522 INFO  snapshot.SnapshotManager DirectoryDiffListFactory.java:init:43 - SkipList is disabled
2019-03-26 07:37:28,528 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map cachedBlocks
2019-03-26 07:37:28,528 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-26 07:37:28,528 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.25% max memory 26.7 GB = 68.3 MB
2019-03-26 07:37:28,528 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^23 = 8388608 entries
2019-03-26 07:37:28,556 INFO  metrics.TopMetrics TopMetrics.java:logConf:76 - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-03-26 07:37:28,556 INFO  metrics.TopMetrics TopMetrics.java:logConf:78 - NNTop conf: dfs.namenode.top.num.users = 10
2019-03-26 07:37:28,556 INFO  metrics.TopMetrics TopMetrics.java:logConf:80 - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-03-26 07:37:28,560 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:979 - Retry cache on namenode is enabled
2019-03-26 07:37:28,561 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:987 - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-03-26 07:37:28,563 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map NameNodeRetryCache
2019-03-26 07:37:28,563 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-26 07:37:28,563 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-03-26 07:37:28,564 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^20 = 1048576 entries
2019-03-26 07:37:28,636 INFO  common.Storage Storage.java:tryLock:905 - Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 100752@clnode059.clemson.cloudlab.us
2019-03-26 07:37:30,136 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:205 - Detected pause in JVM or host machine (eg GC): pause of approximately 1255ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=289ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1083ms
2019-03-26 07:37:31,255 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-26 07:37:31,255 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-26 07:37:31,255 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-26 07:37:32,255 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-26 07:37:32,256 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-26 07:37:32,256 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-26 07:37:33,256 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-26 07:37:33,257 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-26 07:37:33,257 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-26 07:37:34,257 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-26 07:37:34,258 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-26 07:37:34,258 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-26 07:37:34,741 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-03-26 07:37:35,258 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-26 07:37:35,258 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-26 07:37:35,258 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-26 07:37:35,742 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-03-26 07:37:35,851 INFO  namenode.FSImage FSImage.java:loadFSImage:718 - No edit log streams selected.
2019-03-26 07:37:35,852 INFO  namenode.FSImage FSImage.java:loadFSImageFile:782 - Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-03-26 07:37:35,915 INFO  namenode.ErasureCodingPolicyManager ErasureCodingPolicyManager.java:enablePolicy:390 - Enable the erasure coding policy RS-6-3-1024k
2019-03-26 07:37:35,917 INFO  namenode.FSImageFormatPBINode FSImageFormatPBINode.java:loadINodeSection:266 - Loading 1 INodes.
2019-03-26 07:37:35,948 INFO  namenode.FSImageFormatProtobuf FSImageFormatProtobuf.java:load:190 - Loaded FSImage in 0 seconds.
2019-03-26 07:37:35,949 INFO  namenode.FSImage FSImage.java:loadFSImage:951 - Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-03-26 07:37:35,954 INFO  namenode.FSNamesystem FSNamesystem.java:loadFSImage:1091 - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-03-26 07:37:35,954 INFO  namenode.NameCache NameCache.java:initialized:143 - initialized with 0 entries 0 lookups
2019-03-26 07:37:35,954 INFO  namenode.FSNamesystem FSNamesystem.java:loadFromDisk:721 - Finished loading FSImage in 7383 msecs
2019-03-26 07:37:36,135 INFO  namenode.NameNode NameNodeRpcServer.java:<init>:446 - RPC server is binding to node-0-link-0:8020
2019-03-26 07:37:36,140 INFO  ipc.CallQueueManager CallQueueManager.java:<init>:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-03-26 07:37:36,153 INFO  ipc.Server Server.java:run:1070 - Starting Socket Reader #1 for port 8020
2019-03-26 07:37:36,345 INFO  namenode.FSNamesystem FSNamesystem.java:registerMBean:4973 - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-03-26 07:37:36,353 INFO  namenode.LeaseManager LeaseManager.java:getNumUnderConstructionBlocks:171 - Number of blocks under construction: 0
2019-03-26 07:37:36,365 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:396 - STATE* Leaving safe mode after 0 secs
2019-03-26 07:37:36,366 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:402 - STATE* Network topology has 0 racks and 0 datanodes
2019-03-26 07:37:36,366 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:404 - STATE* UnderReplicatedBlocks has 0 blocks
2019-03-26 07:37:36,401 INFO  ipc.Server Server.java:run:1310 - IPC Server Responder: starting
2019-03-26 07:37:36,401 INFO  ipc.Server Server.java:run:1149 - IPC Server listener on 8020: starting
2019-03-26 07:37:36,404 INFO  namenode.NameNode NameNode.java:startCommonServices:812 - NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-03-26 07:37:36,408 INFO  namenode.FSNamesystem FSNamesystem.java:startStandbyServices:1365 - Starting services required for standby state
2019-03-26 07:37:36,415 INFO  ha.EditLogTailer EditLogTailer.java:<init>:188 - Will roll logs on active node every 120 seconds.
2019-03-26 07:37:36,422 INFO  ha.StandbyCheckpointer StandbyCheckpointer.java:start:139 - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-03-26 07:37:36,903 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.6:9866, datanodeUuid=5051f8c2-54f8-4ec3-8389-7cbbf60fa69c, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-16cdee82-81e5-4c3f-aa10-87fe2d494a8b;nsid=674827192;c=1553607419766) storage 5051f8c2-54f8-4ec3-8389-7cbbf60fa69c
2019-03-26 07:37:36,905 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.6:9866
2019-03-26 07:37:36,906 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 5051f8c2-54f8-4ec3-8389-7cbbf60fa69c (10.10.1.6:9866).
2019-03-26 07:37:36,928 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=5e4a25c9-6547-4fc3-ac38-84482ab68c95, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-16cdee82-81e5-4c3f-aa10-87fe2d494a8b;nsid=674827192;c=1553607419766) storage 5e4a25c9-6547-4fc3-ac38-84482ab68c95
2019-03-26 07:37:36,929 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.2:9866
2019-03-26 07:37:36,929 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 5e4a25c9-6547-4fc3-ac38-84482ab68c95 (10.10.1.2:9866).
2019-03-26 07:37:36,929 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=a901873b-1953-4a7e-9c65-3ddf37e371e3, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-16cdee82-81e5-4c3f-aa10-87fe2d494a8b;nsid=674827192;c=1553607419766) storage a901873b-1953-4a7e-9c65-3ddf37e371e3
2019-03-26 07:37:36,930 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.3:9866
2019-03-26 07:37:36,930 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN a901873b-1953-4a7e-9c65-3ddf37e371e3 (10.10.1.3:9866).
2019-03-26 07:37:37,000 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-2ef9ae9d-3c0c-4587-aef0-ab136840818e for DN 10.10.1.3:9866
2019-03-26 07:37:37,004 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-9d1b98b8-4b21-4c94-bf9e-0f245fb8c3ef for DN 10.10.1.6:9866
2019-03-26 07:37:37,005 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-10d2d2b3-5a4d-496d-ac62-8c80a27ce641 for DN 10.10.1.2:9866
2019-03-26 07:37:37,054 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0xdce6b0a4d0673fd0: Processing first storage report for DS-10d2d2b3-5a4d-496d-ac62-8c80a27ce641 from datanode 5e4a25c9-6547-4fc3-ac38-84482ab68c95
2019-03-26 07:37:37,056 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0xdce6b0a4d0673fd0: from storage DS-10d2d2b3-5a4d-496d-ac62-8c80a27ce641 node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=5e4a25c9-6547-4fc3-ac38-84482ab68c95, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-16cdee82-81e5-4c3f-aa10-87fe2d494a8b;nsid=674827192;c=1553607419766), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2019-03-26 07:37:37,056 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0x3a75af85002e4a01: Processing first storage report for DS-2ef9ae9d-3c0c-4587-aef0-ab136840818e from datanode a901873b-1953-4a7e-9c65-3ddf37e371e3
2019-03-26 07:37:37,057 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0x3a75af85002e4a01: from storage DS-2ef9ae9d-3c0c-4587-aef0-ab136840818e node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=a901873b-1953-4a7e-9c65-3ddf37e371e3, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-16cdee82-81e5-4c3f-aa10-87fe2d494a8b;nsid=674827192;c=1553607419766), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-03-26 07:37:37,057 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0xbeebe15a261e08e9: Processing first storage report for DS-9d1b98b8-4b21-4c94-bf9e-0f245fb8c3ef from datanode 5051f8c2-54f8-4ec3-8389-7cbbf60fa69c
2019-03-26 07:37:37,057 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0xbeebe15a261e08e9: from storage DS-9d1b98b8-4b21-4c94-bf9e-0f245fb8c3ef node DatanodeRegistration(10.10.1.6:9866, datanodeUuid=5051f8c2-54f8-4ec3-8389-7cbbf60fa69c, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-16cdee82-81e5-4c3f-aa10-87fe2d494a8b;nsid=674827192;c=1553607419766), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-03-26 07:37:37,275 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=1073cb53-0c0b-49d2-b01a-ea09c01d9739, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-16cdee82-81e5-4c3f-aa10-87fe2d494a8b;nsid=674827192;c=1553607419766) storage 1073cb53-0c0b-49d2-b01a-ea09c01d9739
2019-03-26 07:37:37,275 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.5:9866
2019-03-26 07:37:37,276 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 1073cb53-0c0b-49d2-b01a-ea09c01d9739 (10.10.1.5:9866).
2019-03-26 07:37:37,315 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-6a012b3b-a2e4-4d2f-b0a3-1a544d5f7678 for DN 10.10.1.5:9866
2019-03-26 07:37:37,337 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0x50aa438a788fc833: Processing first storage report for DS-6a012b3b-a2e4-4d2f-b0a3-1a544d5f7678 from datanode 1073cb53-0c0b-49d2-b01a-ea09c01d9739
2019-03-26 07:37:37,338 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0x50aa438a788fc833: from storage DS-6a012b3b-a2e4-4d2f-b0a3-1a544d5f7678 node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=1073cb53-0c0b-49d2-b01a-ea09c01d9739, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-16cdee82-81e5-4c3f-aa10-87fe2d494a8b;nsid=674827192;c=1553607419766), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-03-26 07:38:15,666 INFO  namenode.FSNamesystem FSNamesystem.java:stopStandbyServices:1408 - Stopping services started for standby state
2019-03-26 07:38:15,668 WARN  ha.EditLogTailer EditLogTailer.java:doWork:481 - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:479)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
2019-03-26 07:38:15,671 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1203 - Starting services required for active state
2019-03-26 07:38:15,680 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:435 - Starting recovery process for unclosed journal segments...
2019-03-26 07:38:24,410 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:437 - Successfully started new epoch 2
2019-03-26 07:38:24,410 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:277 - Beginning recovery of unclosed segment starting at txid 1
2019-03-26 07:38:27,642 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:286 - Recovery prepare phase complete. Responses:
10.10.1.5:8485: segmentState { startTxId: 1 endTxId: 136 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 135
10.10.1.2:8485: segmentState { startTxId: 1 endTxId: 136 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 135
2019-03-26 07:38:27,645 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:310 - Using longest log: 10.10.1.5:8485=segmentState {
  startTxId: 1
  endTxId: 136
  isInProgress: true
}
lastWriterEpoch: 1
lastCommittedTxId: 135

2019-03-26 07:38:33,311 INFO  namenode.FileJournalManager FileJournalManager.java:recoverUnfinalizedSegments:396 - Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-03-26 07:38:33,312 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1214 - Catching up to latest edits from old active before taking over writer role in edits logs
2019-03-26 07:38:33,329 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6bd6f894 expecting start txid #1
2019-03-26 07:38:33,329 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A674827192%3A1553607419766%3ACID-16cdee82-81e5-4c3f-aa10-87fe2d494a8b&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A674827192%3A1553607419766%3ACID-16cdee82-81e5-4c3f-aa10-87fe2d494a8b&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-26 07:38:33,332 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A674827192%3A1553607419766%3ACID-16cdee82-81e5-4c3f-aa10-87fe2d494a8b&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A674827192%3A1553607419766%3ACID-16cdee82-81e5-4c3f-aa10-87fe2d494a8b&inProgressOk=true' to transaction ID 1
2019-03-26 07:38:33,333 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A674827192%3A1553607419766%3ACID-16cdee82-81e5-4c3f-aa10-87fe2d494a8b&inProgressOk=true' to transaction ID 1
2019-03-26 07:38:40,446 INFO  namenode.FSEditLogLoader FSEditLogLoader.java:loadEditRecords:289 - replaying edit log: 1/136 transactions completed. (1%)
2019-03-26 07:40:16,972 INFO  http.HttpServer2 ReflectionUtils.java:logThreadInfo:254 - Process Thread Dump: jsp requested
46 active threads
Thread 92 (Scheduler-93740343):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 91 (qtp1068586139-91):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 1
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
    org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
    org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:249)
    org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
    org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
    org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
    org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
    java.lang.Thread.run(Thread.java:748)
Thread 90 (qtp1068586139-90):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 1
  Stack:
    sun.management.ThreadImpl.getThreadInfo1(Native Method)
    sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:178)
    sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:139)
    org.apache.hadoop.util.ReflectionUtils.printThreadInfo(ReflectionUtils.java:169)
    org.apache.hadoop.util.ReflectionUtils.logThreadInfo(ReflectionUtils.java:253)
    org.apache.hadoop.http.HttpServer2$StackServlet.doGet(HttpServer2.java:1468)
    javax.servlet.http.HttpServlet.service(HttpServlet.java:687)
    javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
    org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772)
    org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:110)
    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
    org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1604)
    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
    org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
    org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)
    org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
    org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
    org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
Thread 78 (Logger channel (from single-thread executor) to node-4-link-0/10.10.1.2:8485):
  State: WAITING
  Blocked count: 18
  Waited count: 14
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@328e8b86
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 77 (Logger channel (from single-thread executor) to node-3-link-0/10.10.1.3:8485):
  State: WAITING
  Blocked count: 16
  Waited count: 14
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@101c93c8
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 76 (Logger channel (from single-thread executor) to node-2-link-0/10.10.1.5:8485):
  State: WAITING
  Blocked count: 12
  Waited count: 15
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@52e24bb1
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 73 (pool-11-thread-1):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 72 (AsyncAppender-Dispatcher-Thread-37):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.util.ArrayList@12bfbf96
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:502)
    org.apache.log4j.AsyncAppender$Dispatcher.run(AsyncAppender.java:548)
    java.lang.Thread.run(Thread.java:748)
Thread 71 (IPC Server handler 9 on 8020):
  State: BLOCKED
  Blocked count: 20
  Waited count: 59
  Blocked on org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer@6649ecda
  Blocked by 65 (IPC Server handler 3 on 8020)
  Stack:
    org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getServiceStatus(NameNodeRpcServer.java:1737)
    org.apache.hadoop.ha.protocolPB.HAServiceProtocolServerSideTranslatorPB.getServiceStatus(HAServiceProtocolServerSideTranslatorPB.java:131)
    org.apache.hadoop.ha.proto.HAServiceProtocolProtos$HAServiceProtocolService$2.callBlockingMethod(HAServiceProtocolProtos.java:4464)
    org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
    org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
    org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
    org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
    java.security.AccessController.doPrivileged(Native Method)
    javax.security.auth.Subject.doAs(Subject.java:422)
    org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Thread 70 (IPC Server handler 8 on 8020):
  State: WAITING
  Blocked count: 3
  Waited count: 57
  Waiting on java.util.concurrent.locks.ReentrantReadWriteLock$FairSync@26b69c61
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireShared(AbstractQueuedSynchronizer.java:967)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireShared(AbstractQueuedSynchronizer.java:1283)
    java.util.concurrent.locks.ReentrantReadWriteLock$ReadLock.lock(ReentrantReadWriteLock.java:727)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.readLock(FSNamesystemLock.java:144)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystem.readLock(FSNamesystem.java:1580)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystem.handleHeartbeat(FSNamesystem.java:3849)
    org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.sendHeartbeat(NameNodeRpcServer.java:1504)
    org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.sendHeartbeat(DatanodeProtocolServerSideTranslatorPB.java:119)
    org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31660)
    org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
    org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
    org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
    org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
    java.security.AccessController.doPrivileged(Native Method)
    javax.security.auth.Subject.doAs(Subject.java:422)
    org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Thread 69 (IPC Server handler 7 on 8020):
  State: WAITING
  Blocked count: 20
  Waited count: 59
  Waiting on java.util.concurrent.locks.ReentrantReadWriteLock$FairSync@26b69c61
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireShared(AbstractQueuedSynchronizer.java:967)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireShared(AbstractQueuedSynchronizer.java:1283)
    java.util.concurrent.locks.ReentrantReadWriteLock$ReadLock.lock(ReentrantReadWriteLock.java:727)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.readLock(FSNamesystemLock.java:144)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystem.readLock(FSNamesystem.java:1580)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3088)
    org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:1154)
    org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:966)
    org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
    org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
    org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
    org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
    org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
    java.security.AccessController.doPrivileged(Native Method)
    javax.security.auth.Subject.doAs(Subject.java:422)
    org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Thread 68 (IPC Server handler 6 on 8020):
  State: WAITING
  Blocked count: 0
  Waited count: 59
  Waiting on java.util.concurrent.locks.ReentrantReadWriteLock$FairSync@26b69c61
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireShared(AbstractQueuedSynchronizer.java:967)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireShared(AbstractQueuedSynchronizer.java:1283)
    java.util.concurrent.locks.ReentrantReadWriteLock$ReadLock.lock(ReentrantReadWriteLock.java:727)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.readLock(FSNamesystemLock.java:144)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystem.readLock(FSNamesystem.java:1580)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystem.handleHeartbeat(FSNamesystem.java:3849)
    org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.sendHeartbeat(NameNodeRpcServer.java:1504)
    org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.sendHeartbeat(DatanodeProtocolServerSideTranslatorPB.java:119)
    org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31660)
    org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
    org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
    org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
    org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
    java.security.AccessController.doPrivileged(Native Method)
    javax.security.auth.Subject.doAs(Subject.java:422)
    org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Thread 67 (IPC Server handler 5 on 8020):
  State: WAITING
  Blocked count: 7
  Waited count: 58
  Waiting on java.util.concurrent.locks.ReentrantReadWriteLock$FairSync@26b69c61
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireShared(AbstractQueuedSynchronizer.java:967)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireShared(AbstractQueuedSynchronizer.java:1283)
    java.util.concurrent.locks.ReentrantReadWriteLock$ReadLock.lock(ReentrantReadWriteLock.java:727)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.readLock(FSNamesystemLock.java:144)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystem.readLock(FSNamesystem.java:1580)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystem.handleHeartbeat(FSNamesystem.java:3849)
    org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.sendHeartbeat(NameNodeRpcServer.java:1504)
    org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.sendHeartbeat(DatanodeProtocolServerSideTranslatorPB.java:119)
    org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31660)
    org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
    org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
    org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
    org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
    java.security.AccessController.doPrivileged(Native Method)
    javax.security.auth.Subject.doAs(Subject.java:422)
    org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Thread 66 (IPC Server handler 4 on 8020):
  State: WAITING
  Blocked count: 5
  Waited count: 57
  Waiting on java.util.concurrent.locks.ReentrantReadWriteLock$FairSync@26b69c61
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireShared(AbstractQueuedSynchronizer.java:967)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireShared(AbstractQueuedSynchronizer.java:1283)
    java.util.concurrent.locks.ReentrantReadWriteLock$ReadLock.lock(ReentrantReadWriteLock.java:727)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.readLock(FSNamesystemLock.java:144)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystem.readLock(FSNamesystem.java:1580)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystem.handleHeartbeat(FSNamesystem.java:3849)
    org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.sendHeartbeat(NameNodeRpcServer.java:1504)
    org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.sendHeartbeat(DatanodeProtocolServerSideTranslatorPB.java:119)
    org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31660)
    org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
    org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
    org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
    org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
    java.security.AccessController.doPrivileged(Native Method)
    javax.security.auth.Subject.doAs(Subject.java:422)
    org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Thread 65 (IPC Server handler 3 on 8020):
  State: RUNNABLE
  Blocked count: 12
  Waited count: 68
  Stack:
    java.net.SocketInputStream.socketRead0(Native Method)
    java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
    java.net.SocketInputStream.read(SocketInputStream.java:171)
    java.net.SocketInputStream.read(SocketInputStream.java:141)
    java.io.BufferedInputStream.read1(BufferedInputStream.java:284)
    java.io.BufferedInputStream.read(BufferedInputStream.java:345)
    sun.net.www.MeteredStream.read(MeteredStream.java:134)
    java.io.FilterInputStream.read(FilterInputStream.java:133)
    sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3444)
    java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
    java.io.BufferedInputStream.skip(BufferedInputStream.java:380)
    java.io.FilterInputStream.skip(FilterInputStream.java:151)
    org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader$PositionTrackingInputStream.skip(FSEditLogLoader.java:1375)
    org.apache.hadoop.io.IOUtils.skipFully(IOUtils.java:229)
    org.apache.hadoop.hdfs.server.namenode.EditLogFileInputStream.nextOpImpl(EditLogFileInputStream.java:228)
    org.apache.hadoop.hdfs.server.namenode.EditLogFileInputStream.nextOp(EditLogFileInputStream.java:248)
    org.apache.hadoop.hdfs.server.namenode.EditLogInputStream.readOp(EditLogInputStream.java:85)
    org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream.nextOp(RedundantEditLogInputStream.java:189)
    org.apache.hadoop.hdfs.server.namenode.EditLogInputStream.readOp(EditLogInputStream.java:85)
    org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream.nextOp(RedundantEditLogInputStream.java:189)
Thread 64 (IPC Server handler 2 on 8020):
  State: WAITING
  Blocked count: 37
  Waited count: 67
  Waiting on java.util.concurrent.locks.ReentrantReadWriteLock$FairSync@26b69c61
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireShared(AbstractQueuedSynchronizer.java:967)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireShared(AbstractQueuedSynchronizer.java:1283)
    java.util.concurrent.locks.ReentrantReadWriteLock$ReadLock.lock(ReentrantReadWriteLock.java:727)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.readLock(FSNamesystemLock.java:144)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystem.readLock(FSNamesystem.java:1580)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3088)
    org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:1154)
    org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:966)
    org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
    org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
    org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
    org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
    org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
    java.security.AccessController.doPrivileged(Native Method)
    javax.security.auth.Subject.doAs(Subject.java:422)
    org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Thread 63 (IPC Server handler 1 on 8020):
  State: WAITING
  Blocked count: 31
  Waited count: 72
  Waiting on java.util.concurrent.locks.ReentrantReadWriteLock$FairSync@26b69c61
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireShared(AbstractQueuedSynchronizer.java:967)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireShared(AbstractQueuedSynchronizer.java:1283)
    java.util.concurrent.locks.ReentrantReadWriteLock$ReadLock.lock(ReentrantReadWriteLock.java:727)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.readLock(FSNamesystemLock.java:144)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystem.readLock(FSNamesystem.java:1580)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3088)
    org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:1154)
    org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:966)
    org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
    org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
    org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
    org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
    org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
    java.security.AccessController.doPrivileged(Native Method)
    javax.security.auth.Subject.doAs(Subject.java:422)
    org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Thread 62 (IPC Server handler 0 on 8020):
  State: WAITING
  Blocked count: 22
  Waited count: 65
  Waiting on java.util.concurrent.locks.ReentrantReadWriteLock$FairSync@26b69c61
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireShared(AbstractQueuedSynchronizer.java:967)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireShared(AbstractQueuedSynchronizer.java:1283)
    java.util.concurrent.locks.ReentrantReadWriteLock$ReadLock.lock(ReentrantReadWriteLock.java:727)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.readLock(FSNamesystemLock.java:144)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystem.readLock(FSNamesystem.java:1580)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3088)
    org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:1154)
    org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:966)
    org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
    org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
    org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
    org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
    org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
    java.security.AccessController.doPrivileged(Native Method)
    javax.security.auth.Subject.doAs(Subject.java:422)
    org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Thread 55 (IPC Server listener on 8020):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    org.apache.hadoop.ipc.Server$Listener.run(Server.java:1155)
Thread 58 (IPC Server Responder):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1330)
    org.apache.hadoop.ipc.Server$Responder.run(Server.java:1313)
Thread 43 (Block report processor):
  State: WAITING
  Blocked count: 0
  Waited count: 121
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@2cf66eb5
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
    org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.processQueue(BlockManager.java:4873)
    org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.run(BlockManager.java:4862)
Thread 42 (StorageInfoMonitor):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$StorageInfoDefragmenter.run(BlockManager.java:4549)
    java.lang.Thread.run(Thread.java:748)
Thread 41 (RedundancyMonitor):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 54
  Stack:
    java.lang.Thread.sleep(Native Method)
    java.lang.Thread.sleep(Thread.java:340)
    java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
    org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$RedundancyMonitor.run(BlockManager.java:4514)
    java.lang.Thread.run(Thread.java:748)
Thread 44 (org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@146dfe6):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 33
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor.run(HeartbeatManager.java:456)
    java.lang.Thread.run(Thread.java:748)
Thread 61 (DatanodeAdminMonitor-0):
  State: WAITING
  Blocked count: 0
  Waited count: 3
  Waiting on java.util.concurrent.locks.ReentrantReadWriteLock$FairSync@26b69c61
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:870)
    java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1199)
    java.util.concurrent.locks.ReentrantReadWriteLock$WriteLock.lock(ReentrantReadWriteLock.java:943)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.writeLock(FSNamesystemLock.java:206)
    org.apache.hadoop.hdfs.server.namenode.FSNamesystem.writeLock(FSNamesystem.java:1595)
    org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminManager$Monitor.run(DatanodeAdminManager.java:492)
    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
    java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 60 (org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@6105f8a3):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
    java.lang.Thread.run(Thread.java:748)
Thread 57 (IPC Server idle connection scanner for port 8020):
  State: TIMED_WAITING
  Blocked count: 1
  Waited count: 18
  Stack:
    java.lang.Object.wait(Native Method)
    java.util.TimerThread.mainLoop(Timer.java:552)
    java.util.TimerThread.run(Timer.java:505)
Thread 56 (Socket Reader #1 for port 8020):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1093)
    org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1072)
Thread 38 (org.eclipse.jetty.server.session.HashSessionManager@74287ea3Timer):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 6
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 37 (org.eclipse.jetty.server.session.HashSessionManager@f58853cTimer):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 6
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 36 (org.eclipse.jetty.server.session.HashSessionManager@46d59067Timer):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 6
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 35 (qtp1068586139-35-acceptor-3@5df9257c-ServerConnector@1cf56a1c{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}):
  State: BLOCKED
  Blocked count: 1
  Waited count: 1
  Blocked on java.lang.Object@14c29834
  Blocked by 32 (qtp1068586139-32-acceptor-0@56c77783-ServerConnector@1cf56a1c{HTTP/1.1,[http/1.1]}{node-0-link-0:9870})
  Stack:
    sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:234)
    org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:371)
    org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
    org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
    org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
    java.lang.Thread.run(Thread.java:748)
Thread 34 (qtp1068586139-34-acceptor-2@1bbe1a37-ServerConnector@1cf56a1c{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}):
  State: BLOCKED
  Blocked count: 1
  Waited count: 1
  Blocked on java.lang.Object@14c29834
  Blocked by 32 (qtp1068586139-32-acceptor-0@56c77783-ServerConnector@1cf56a1c{HTTP/1.1,[http/1.1]}{node-0-link-0:9870})
  Stack:
    sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:234)
    org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:371)
    org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
    org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
    org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
    java.lang.Thread.run(Thread.java:748)
Thread 33 (qtp1068586139-33-acceptor-1@52698604-ServerConnector@1cf56a1c{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}):
  State: BLOCKED
  Blocked count: 1
  Waited count: 1
  Blocked on java.lang.Object@14c29834
  Blocked by 32 (qtp1068586139-32-acceptor-0@56c77783-ServerConnector@1cf56a1c{HTTP/1.1,[http/1.1]}{node-0-link-0:9870})
  Stack:
    sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:234)
    org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:371)
    org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
    org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
    org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
    java.lang.Thread.run(Thread.java:748)
Thread 32 (qtp1068586139-32-acceptor-0@56c77783-ServerConnector@1cf56a1c{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}):
  State: RUNNABLE
  Blocked count: 1
  Waited count: 1
  Stack:
    sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
    sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422)
    sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250)
    org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:371)
    org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:601)
    org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
    org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
    java.lang.Thread.run(Thread.java:748)
Thread 31 (qtp1068586139-31):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 1
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
    org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
    org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:249)
    org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
    org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
    org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
    org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
    org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
    java.lang.Thread.run(Thread.java:748)
Thread 30 (qtp1068586139-30):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 1
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
    org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
    org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:249)
    org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
    org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
    org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
    org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
    org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
    java.lang.Thread.run(Thread.java:748)
Thread 29 (qtp1068586139-29):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 1
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
    org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
    org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:249)
    org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
    org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
    org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
    org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
    org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
    java.lang.Thread.run(Thread.java:748)
Thread 28 (qtp1068586139-28):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 2
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:392)
    org.eclipse.jetty.util.thread.QueuedThreadPool.idleJobPoll(QueuedThreadPool.java:563)
    org.eclipse.jetty.util.thread.QueuedThreadPool.access$800(QueuedThreadPool.java:48)
    org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:626)
    java.lang.Thread.run(Thread.java:748)
Thread 27 (pool-2-thread-1):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:748)
Thread 26 (org.apache.hadoop.util.JvmPauseMonitor$Monitor@55f616cf):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 337
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
    java.lang.Thread.run(Thread.java:748)
Thread 25 (Timer for 'NameNode' metrics system):
  State: TIMED_WAITING
  Blocked count: 1
  Waited count: 18
  Stack:
    java.lang.Object.wait(Native Method)
    java.util.TimerThread.mainLoop(Timer.java:552)
    java.util.TimerThread.run(Timer.java:505)
Thread 4 (Signal Dispatcher):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
Thread 3 (Finalizer):
  State: WAITING
  Blocked count: 21
  Waited count: 4
  Waiting on java.lang.ref.ReferenceQueue$Lock@484970b0
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
    java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
    java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:216)
Thread 2 (Reference Handler):
  State: WAITING
  Blocked count: 4
  Waited count: 3
  Waiting on java.lang.ref.Reference$Lock@4470f8a6
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:502)
    java.lang.ref.Reference.tryHandlePending(Reference.java:191)
    java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
Thread 1 (main):
  State: WAITING
  Blocked count: 7
  Waited count: 8
  Waiting on org.apache.hadoop.ipc.ProtobufRpcEngine$Server@2383996
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:502)
    org.apache.hadoop.ipc.Server.join(Server.java:3100)
    org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.join(NameNodeRpcServer.java:576)
    org.apache.hadoop.hdfs.server.namenode.NameNode.join(NameNode.java:983)
    org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1712)

2019-03-26 07:42:48,427 INFO  namenode.FSEditLogLoader FSEditLogLoader.java:loadEditRecords:289 - replaying edit log: 136/136 transactions completed. (100%)
2019-03-26 07:42:48,428 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A674827192%3A1553607419766%3ACID-16cdee82-81e5-4c3f-aa10-87fe2d494a8b&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A674827192%3A1553607419766%3ACID-16cdee82-81e5-4c3f-aa10-87fe2d494a8b&inProgressOk=true of size 1048576 edits # 136 loaded in 255 seconds
2019-03-26 07:42:48,428 INFO  blockmanagement.DatanodeManager DatanodeManager.java:markAllDatanodesStale:1837 - Marking all datanodes as stale
2019-03-26 07:42:48,429 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1225 - Reprocessing replication and invalidation queues
2019-03-26 07:42:48,430 INFO  blockmanagement.BlockManager BlockManager.java:initializeReplQueues:4752 - initializing replication queues
2019-03-26 07:42:48,430 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1236 - Will take over writing edit logs at txnid 137
2019-03-26 07:42:48,439 INFO  namenode.FSEditLog FSEditLog.java:startLogSegment:1361 - Starting log segment at 137
2019-03-26 07:42:48,692 INFO  namenode.FSEditLog FSEditLog.java:printStatistics:774 - Number of transactions: 1 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 0 SyncTimes(ms): 0 49 
2019-03-26 07:42:48,709 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:767 - Initializing quota with 4 thread(s)
2019-03-26 07:42:48,713 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:776 - Quota initialization completed in 4 milliseconds
name space=6
storage space=16106127360
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-03-26 07:42:48,718 INFO  blockmanagement.CacheReplicationMonitor CacheReplicationMonitor.java:run:160 - Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-03-26 07:42:48,718 INFO  namenode.FSNamesystem FSNamesystemLock.java:writeUnlock:282 - FSNamesystem write lock held for 273051 ms via
java.lang.Thread.getStackTrace(Thread.java:1559)
org.apache.hadoop.util.StringUtils.getStackTrace(StringUtils.java:1032)
org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.writeUnlock(FSNamesystemLock.java:284)
org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.writeUnlock(FSNamesystemLock.java:224)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.writeUnlock(FSNamesystem.java:1603)
org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.writeUnlock(NameNode.java:1945)
org.apache.hadoop.hdfs.server.namenode.ha.HAState.setStateInternal(HAState.java:67)
org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.setState(StandbyState.java:49)
org.apache.hadoop.hdfs.server.namenode.NameNode.transitionToActive(NameNode.java:1746)
org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.transitionToActive(NameNodeRpcServer.java:1723)
org.apache.hadoop.ha.protocolPB.HAServiceProtocolServerSideTranslatorPB.transitionToActive(HAServiceProtocolServerSideTranslatorPB.java:107)
org.apache.hadoop.ha.proto.HAServiceProtocolProtos$HAServiceProtocolService$2.callBlockingMethod(HAServiceProtocolProtos.java:4460)
org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
java.security.AccessController.doPrivileged(Native Method)
javax.security.auth.Subject.doAs(Subject.java:422)
org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
	Number of suppressed write-lock reports: 0
	Longest write-lock held interval: 273051
2019-03-26 07:42:48,719 INFO  ipc.Server Server.java:run:865 - IPC Server handler 4 on 8020: skipped Call#0 Retry#0 org.apache.hadoop.ha.HAServiceProtocol.getServiceStatus from 10.10.1.1:60704
2019-03-26 07:42:48,719 INFO  ipc.Server Server.java:run:865 - IPC Server handler 6 on 8020: skipped Call#79 Retry#0 org.apache.hadoop.ha.HAServiceProtocol.transitionToActive from 10.10.1.1:60714
2019-03-26 07:42:48,719 WARN  ipc.Server Server.java:processResponse:1519 - IPC Server handler 3 on 8020, call Call#78 Retry#0 org.apache.hadoop.ha.HAServiceProtocol.transitionToActive from 10.10.1.1:60684: output error
2019-03-26 07:42:48,719 INFO  ipc.Server Server.java:run:865 - IPC Server handler 8 on 8020: skipped Call#0 Retry#0 org.apache.hadoop.ha.HAServiceProtocol.getServiceStatus from 10.10.1.1:60710
2019-03-26 07:42:48,720 INFO  ipc.Server Server.java:run:2691 - IPC Server handler 3 on 8020 caught an exception
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:270)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:461)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3245)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1469)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1539)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2589)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1611)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:936)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:770)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:881)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2019-03-26 07:42:48,720 INFO  ipc.Server Server.java:run:865 - IPC Server handler 6 on 8020: skipped Call#0 Retry#0 org.apache.hadoop.ha.HAServiceProtocol.getServiceStatus from 10.10.1.1:60722
2019-03-26 07:42:48,720 INFO  ipc.Server Server.java:run:865 - IPC Server handler 4 on 8020: skipped Call#80 Retry#0 org.apache.hadoop.ha.HAServiceProtocol.getServiceStatus from 10.10.1.1:60716
2019-03-26 07:42:48,721 INFO  ipc.Server Server.java:run:865 - IPC Server handler 6 on 8020: skipped Call#0 Retry#0 org.apache.hadoop.ha.HAServiceProtocol.getServiceStatus from 10.10.1.1:60740
2019-03-26 07:42:48,720 INFO  ipc.Server Server.java:run:865 - IPC Server handler 3 on 8020: skipped Call#81 Retry#0 org.apache.hadoop.ha.HAServiceProtocol.getServiceStatus from 10.10.1.1:60738
2019-03-26 07:42:48,720 INFO  ipc.Server Server.java:run:865 - IPC Server handler 8 on 8020: skipped Call#0 Retry#0 org.apache.hadoop.ha.HAServiceProtocol.getServiceStatus from 10.10.1.1:60728
2019-03-26 07:42:48,721 INFO  ipc.Server Server.java:run:865 - IPC Server handler 3 on 8020: skipped Call#0 Retry#0 org.apache.hadoop.ha.HAServiceProtocol.getServiceStatus from 10.10.1.1:60754
2019-03-26 07:42:48,721 INFO  ipc.Server Server.java:run:865 - IPC Server handler 6 on 8020: skipped Call#82 Retry#0 org.apache.hadoop.ha.HAServiceProtocol.getServiceStatus from 10.10.1.1:60752
2019-03-26 07:42:48,721 INFO  ipc.Server Server.java:run:865 - IPC Server handler 4 on 8020: skipped Call#0 Retry#0 org.apache.hadoop.ha.HAServiceProtocol.getServiceStatus from 10.10.1.1:60746
2019-03-26 07:42:48,721 INFO  ipc.Server Server.java:run:865 - IPC Server handler 6 on 8020: skipped Call#0 Retry#0 org.apache.hadoop.ha.HAServiceProtocol.getServiceStatus from 10.10.1.1:60768
2019-03-26 07:42:48,721 INFO  ipc.Server Server.java:run:865 - IPC Server handler 3 on 8020: skipped Call#83 Retry#0 org.apache.hadoop.ha.HAServiceProtocol.getServiceStatus from 10.10.1.1:60762
2019-03-26 07:42:48,721 INFO  ipc.Server Server.java:run:865 - IPC Server handler 8 on 8020: skipped Call#0 Retry#0 org.apache.hadoop.ha.HAServiceProtocol.getServiceStatus from 10.10.1.1:60760
2019-03-26 07:42:48,721 INFO  ipc.Server Server.java:run:865 - IPC Server handler 4 on 8020: skipped Call#0 Retry#0 org.apache.hadoop.ha.HAServiceProtocol.getServiceStatus from 10.10.1.1:60774
2019-03-26 07:42:48,722 WARN  ipc.Server Server.java:processResponse:1519 - IPC Server handler 9 on 8020, call Call#0 Retry#0 org.apache.hadoop.ha.HAServiceProtocol.getServiceStatus from 10.10.1.1:60694: output error
2019-03-26 07:42:48,722 INFO  ipc.Server Server.java:run:2691 - IPC Server handler 9 on 8020 caught an exception
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:270)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:461)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3245)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1469)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1539)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2589)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1611)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:936)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:770)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:881)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2019-03-26 07:42:48,785 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3447 - Total number of blocks            = 40
2019-03-26 07:42:48,785 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3448 - Number of invalid blocks          = 0
2019-03-26 07:42:48,785 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3449 - Number of under-replicated blocks = 0
2019-03-26 07:42:48,785 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3450 - Number of  over-replicated blocks = 0
2019-03-26 07:42:48,785 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3452 - Number of blocks being written    = 0
2019-03-26 07:42:48,786 INFO  hdfs.StateChange BlockManager.java:processMisReplicatesAsync:3455 - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 356 msec
2019-03-26 07:43:48,800 INFO  namenode.FSEditLog FSEditLog.java:printStatistics:774 - Number of transactions: 6 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 136 Number of syncs: 5 SyncTimes(ms): 85 79 
2019-03-26 07:43:48,890 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741865_1041, replicas=10.10.1.6:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-03-26 07:43:49,395 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741866_1042, replicas=10.10.1.6:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-03-26 07:43:49,901 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741867_1043, replicas=10.10.1.3:9866, 10.10.1.6:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-03-26 07:43:50,308 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741868_1044, replicas=10.10.1.6:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-03-26 07:43:50,691 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741869_1045, replicas=10.10.1.6:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-03-26 07:43:51,036 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741870_1046, replicas=10.10.1.6:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-03-26 07:43:51,248 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741871_1047, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.6:9866 for /myfile4._COPYING_
2019-03-26 07:43:51,438 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741872_1048, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-03-26 07:43:51,583 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741873_1049, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-03-26 07:43:51,890 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741874_1050, replicas=10.10.1.2:9866, 10.10.1.6:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-03-26 07:43:51,894 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741875_1051, replicas=10.10.1.2:9866, 10.10.1.6:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-03-26 07:43:52,143 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741876_1052, replicas=10.10.1.6:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-03-26 07:43:52,306 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741877_1053, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.6:9866 for /myfile4._COPYING_
2019-03-26 07:43:52,366 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile1._COPYING_ is closed by DFSClient_NONMAPREDUCE_-477450308_1
2019-03-26 07:43:52,506 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741878_1054, replicas=10.10.1.3:9866, 10.10.1.6:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-03-26 07:43:52,630 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741879_1055, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-03-26 07:43:52,730 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741880_1056, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-03-26 07:43:53,107 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741881_1057, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-03-26 07:43:53,141 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741882_1058, replicas=10.10.1.6:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-03-26 07:43:53,170 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741883_1059, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-03-26 07:43:53,534 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741884_1060, replicas=10.10.1.6:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-03-26 07:43:53,557 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741885_1061, replicas=10.10.1.6:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-03-26 07:43:53,567 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741886_1062, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-03-26 07:43:53,988 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741887_1063, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.6:9866 for /myfile5._COPYING_
2019-03-26 07:43:54,014 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741888_1064, replicas=10.10.1.6:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-03-26 07:43:54,060 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741889_1065, replicas=10.10.1.6:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-03-26 07:43:54,426 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741890_1066, replicas=10.10.1.6:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-03-26 07:43:54,836 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741891_1067, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-03-26 07:43:55,217 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741892_1068, replicas=10.10.1.6:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-03-26 07:43:55,218 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741893_1069, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-03-26 07:43:55,292 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1674ms to send a batch of 4 edits (198 bytes) to remote journal 10.10.1.3:8485
2019-03-26 07:43:55,671 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741894_1070, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.6:9866 for /myfile2._COPYING_
2019-03-26 07:43:55,674 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile4._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1693244976_1
2019-03-26 07:43:55,689 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile5._COPYING_ is closed by DFSClient_NONMAPREDUCE_367298093_1
2019-03-26 07:43:56,083 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741895_1071, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-03-26 07:43:56,535 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741896_1072, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-03-26 07:43:56,926 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile2._COPYING_ is closed by DFSClient_NONMAPREDUCE_-340381107_1
2019-03-26 07:43:58,270 INFO  ipc.Server Server.java:doRead:1252 - Socket Reader #1 for port 8020: readAndProcess from client 10.10.1.7:42162 threw exception [java.io.IOException: Connection reset by peer]
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.ipc.Server.channelRead(Server.java:3265)
	at org.apache.hadoop.ipc.Server.access$2600(Server.java:137)
	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2040)
	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1245)
	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1101)
	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1072)

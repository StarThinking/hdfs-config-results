2019-03-27 08:43:11,173 INFO  namenode.NameNode LogAdapter.java:info:51 - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode059.clemson.cloudlab.us/130.127.133.68
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-03-17T18:59Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-03-27 08:43:11,185 INFO  namenode.NameNode LogAdapter.java:info:51 - registered UNIX signal handlers for [TERM, HUP, INT]
2019-03-27 08:43:11,190 INFO  namenode.NameNode NameNode.java:createNameNode:1583 - createNameNode []
2019-03-27 08:43:11,434 INFO  beanutils.FluentPropertyBeanIntrospector FluentPropertyBeanIntrospector.java:introspect:147 - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2019-03-27 08:43:11,478 INFO  impl.MetricsConfig MetricsConfig.java:loadFirst:121 - loaded properties from hadoop-metrics2.properties
2019-03-27 08:43:11,585 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:startTimer:374 - Scheduled Metric snapshot period at 10 second(s).
2019-03-27 08:43:11,586 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:start:191 - NameNode metrics system started
2019-03-27 08:43:11,638 INFO  namenode.NameNodeUtils NameNodeUtils.java:getClientNamenodeAddress:79 - fs.defaultFS is hdfs://mycluster
2019-03-27 08:43:11,638 INFO  namenode.NameNode NameNode.java:<init>:928 - Clients should use mycluster to access this namenode/service.
2019-03-27 08:43:11,809 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:188 - Starting JVM pause monitor
2019-03-27 08:43:11,837 INFO  hdfs.DFSUtil DFSUtil.java:httpServerTemplateForNNAndJN:1605 - Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-03-27 08:43:11,854 INFO  util.log Log.java:initialized:192 - Logging initialized @1202ms
2019-03-27 08:43:11,964 INFO  server.AuthenticationFilter AuthenticationFilter.java:constructSecretProvider:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-03-27 08:43:11,977 INFO  http.HttpRequestLog HttpRequestLog.java:getRequestLog:81 - Http request log for http.requests.namenode is not defined
2019-03-27 08:43:11,988 INFO  http.HttpServer2 HttpServer2.java:addGlobalFilter:968 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-03-27 08:43:11,991 INFO  http.HttpServer2 HttpServer2.java:addFilter:941 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-03-27 08:43:11,992 INFO  http.HttpServer2 HttpServer2.java:addFilter:951 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-03-27 08:43:11,992 INFO  http.HttpServer2 HttpServer2.java:addFilter:951 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-03-27 08:43:12,019 INFO  http.HttpServer2 NameNodeHttpServer.java:initWebHdfs:100 - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-03-27 08:43:12,019 INFO  http.HttpServer2 HttpServer2.java:addJerseyResourcePackage:787 - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-03-27 08:43:12,028 INFO  http.HttpServer2 HttpServer2.java:bindListener:1185 - Jetty bound to port 9870
2019-03-27 08:43:12,030 INFO  server.Server Server.java:doStart:346 - jetty-9.3.19.v20170502
2019-03-27 08:43:12,065 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@221a3fa4{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-03-27 08:43:12,066 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@2b40ff9c{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-03-27 08:43:12,140 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.w.WebAppContext@6c7a164b{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-03-27 08:43:12,163 INFO  server.AbstractConnector AbstractConnector.java:doStart:278 - Started ServerConnector@1cf56a1c{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-03-27 08:43:12,163 INFO  server.Server Server.java:doStart:414 - Started @1513ms
2019-03-27 08:43:12,509 WARN  namenode.FSNamesystem FSNamesystem.java:checkConfiguration:680 - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-03-27 08:43:12,559 INFO  namenode.FSEditLog FSEditLog.java:newInstance:227 - Edit logging is async:true
2019-03-27 08:43:12,574 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:749 - KeyProvider: null
2019-03-27 08:43:12,576 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:122 - fsLock is fair: true
2019-03-27 08:43:12,578 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:138 - Detailed lock hold time metrics enabled: false
2019-03-27 08:43:12,585 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:774 - fsOwner             = root (auth:SIMPLE)
2019-03-27 08:43:12,585 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:775 - supergroup          = supergroup
2019-03-27 08:43:12,585 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:776 - isPermissionEnabled = true
2019-03-27 08:43:12,586 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:785 - Determined nameservice ID: mycluster
2019-03-27 08:43:12,586 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:787 - HA Enabled: true
2019-03-27 08:43:12,629 INFO  common.Util Util.java:isDiskStatsEnabled:395 - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-03-27 08:43:12,642 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:301 - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-03-27 08:43:12,642 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:309 - dfs.namenode.datanode.registration.ip-hostname-check=true
2019-03-27 08:43:12,646 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:79 - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-03-27 08:43:12,647 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:85 - The block deletion will start around 2019 Mar 27 08:43:12
2019-03-27 08:43:12,649 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map BlocksMap
2019-03-27 08:43:12,649 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 08:43:12,651 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 2.0% max memory 26.7 GB = 546.1 MB
2019-03-27 08:43:12,651 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^26 = 67108864 entries
2019-03-27 08:43:12,789 INFO  blockmanagement.BlockManager BlockManager.java:createBlockTokenSecretManager:579 - dfs.block.access.token.enable = false
2019-03-27 08:43:12,798 INFO  Configuration.deprecation Configuration.java:logDeprecation:1395 - No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-03-27 08:43:12,798 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:161 - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-03-27 08:43:12,799 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:162 - dfs.namenode.safemode.min.datanodes = 0
2019-03-27 08:43:12,799 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:164 - dfs.namenode.safemode.extension = 30000
2019-03-27 08:43:12,799 INFO  blockmanagement.BlockManager BlockManager.java:<init>:565 - defaultReplication         = 3
2019-03-27 08:43:12,799 INFO  blockmanagement.BlockManager BlockManager.java:<init>:566 - maxReplication             = 512
2019-03-27 08:43:12,799 INFO  blockmanagement.BlockManager BlockManager.java:<init>:567 - minReplication             = 1
2019-03-27 08:43:12,799 INFO  blockmanagement.BlockManager BlockManager.java:<init>:568 - maxReplicationStreams      = 2
2019-03-27 08:43:12,799 INFO  blockmanagement.BlockManager BlockManager.java:<init>:569 - redundancyRecheckInterval  = 3000ms
2019-03-27 08:43:12,800 INFO  blockmanagement.BlockManager BlockManager.java:<init>:570 - encryptDataTransfer        = false
2019-03-27 08:43:12,800 INFO  blockmanagement.BlockManager BlockManager.java:<init>:571 - maxNumBlocksToLog          = 1000
2019-03-27 08:43:12,883 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map INodeMap
2019-03-27 08:43:12,883 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 08:43:12,884 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 1.0% max memory 26.7 GB = 273.0 MB
2019-03-27 08:43:12,884 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^25 = 33554432 entries
2019-03-27 08:43:12,957 INFO  namenode.FSDirectory FSDirectory.java:<init>:283 - ACLs enabled? false
2019-03-27 08:43:12,958 INFO  namenode.FSDirectory FSDirectory.java:<init>:287 - POSIX ACL inheritance enabled? true
2019-03-27 08:43:12,958 INFO  namenode.FSDirectory FSDirectory.java:<init>:291 - XAttrs enabled? true
2019-03-27 08:43:12,958 INFO  namenode.NameNode FSDirectory.java:<init>:355 - Caching file names occurring more than 10 times
2019-03-27 08:43:12,965 INFO  snapshot.SnapshotManager SnapshotManager.java:<init>:124 - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-03-27 08:43:12,968 INFO  snapshot.SnapshotManager DirectoryDiffListFactory.java:init:43 - SkipList is disabled
2019-03-27 08:43:12,973 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map cachedBlocks
2019-03-27 08:43:12,973 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 08:43:12,974 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.25% max memory 26.7 GB = 68.3 MB
2019-03-27 08:43:12,974 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^23 = 8388608 entries
2019-03-27 08:43:13,001 INFO  metrics.TopMetrics TopMetrics.java:logConf:76 - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-03-27 08:43:13,002 INFO  metrics.TopMetrics TopMetrics.java:logConf:78 - NNTop conf: dfs.namenode.top.num.users = 10
2019-03-27 08:43:13,002 INFO  metrics.TopMetrics TopMetrics.java:logConf:80 - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-03-27 08:43:13,006 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:979 - Retry cache on namenode is enabled
2019-03-27 08:43:13,006 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:987 - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-03-27 08:43:13,009 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map NameNodeRetryCache
2019-03-27 08:43:13,009 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 08:43:13,009 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-03-27 08:43:13,009 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^20 = 1048576 entries
2019-03-27 08:43:13,085 INFO  common.Storage Storage.java:tryLock:905 - Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 64462@clnode059.clemson.cloudlab.us
2019-03-27 08:43:14,372 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:205 - Detected pause in JVM or host machine (eg GC): pause of approximately 1058ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=317ms
GC pool 'PS Scavenge' had collection(s): count=1 time=836ms
2019-03-27 08:43:14,523 INFO  namenode.FSImage FSImage.java:loadFSImage:718 - No edit log streams selected.
2019-03-27 08:43:14,524 INFO  namenode.FSImage FSImage.java:loadFSImageFile:782 - Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-03-27 08:43:14,587 INFO  namenode.ErasureCodingPolicyManager ErasureCodingPolicyManager.java:enablePolicy:390 - Enable the erasure coding policy RS-6-3-1024k
2019-03-27 08:43:14,589 INFO  namenode.FSImageFormatPBINode FSImageFormatPBINode.java:loadINodeSection:266 - Loading 1 INodes.
2019-03-27 08:43:14,620 INFO  namenode.FSImageFormatProtobuf FSImageFormatProtobuf.java:load:190 - Loaded FSImage in 0 seconds.
2019-03-27 08:43:14,621 INFO  namenode.FSImage FSImage.java:loadFSImage:951 - Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-03-27 08:43:14,626 INFO  namenode.FSNamesystem FSNamesystem.java:loadFSImage:1091 - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-03-27 08:43:14,626 INFO  namenode.NameCache NameCache.java:initialized:143 - initialized with 0 entries 0 lookups
2019-03-27 08:43:14,626 INFO  namenode.FSNamesystem FSNamesystem.java:loadFromDisk:721 - Finished loading FSImage in 1609 msecs
2019-03-27 08:43:14,808 INFO  namenode.NameNode NameNodeRpcServer.java:<init>:446 - RPC server is binding to node-0-link-0:8020
2019-03-27 08:43:14,813 INFO  ipc.CallQueueManager CallQueueManager.java:<init>:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-03-27 08:43:14,825 INFO  ipc.Server Server.java:run:1070 - Starting Socket Reader #1 for port 8020
2019-03-27 08:43:15,012 INFO  namenode.FSNamesystem FSNamesystem.java:registerMBean:4973 - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-03-27 08:43:15,021 INFO  namenode.LeaseManager LeaseManager.java:getNumUnderConstructionBlocks:171 - Number of blocks under construction: 0
2019-03-27 08:43:15,031 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:396 - STATE* Leaving safe mode after 0 secs
2019-03-27 08:43:15,031 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:402 - STATE* Network topology has 0 racks and 0 datanodes
2019-03-27 08:43:15,031 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:404 - STATE* UnderReplicatedBlocks has 0 blocks
2019-03-27 08:43:15,064 INFO  ipc.Server Server.java:run:1310 - IPC Server Responder: starting
2019-03-27 08:43:15,066 INFO  ipc.Server Server.java:run:1149 - IPC Server listener on 8020: starting
2019-03-27 08:43:15,068 INFO  namenode.NameNode NameNode.java:startCommonServices:812 - NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-03-27 08:43:15,072 INFO  namenode.FSNamesystem FSNamesystem.java:startStandbyServices:1365 - Starting services required for standby state
2019-03-27 08:43:15,076 INFO  ha.EditLogTailer EditLogTailer.java:<init>:188 - Will roll logs on active node every 120 seconds.
2019-03-27 08:43:15,082 INFO  ha.StandbyCheckpointer StandbyCheckpointer.java:start:139 - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-03-27 08:43:20,127 INFO  namenode.TransferFsImage TransferFsImage.java:copyFileToStream:396 - Sending fileName: /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, fileSize: 389. Sent total: 389 bytes. Size of last segment intended to send: -1 bytes.
2019-03-27 08:43:20,282 ERROR namenode.NameNode LogAdapter.java:error:75 - RECEIVED SIGNAL 15: SIGTERM
2019-03-27 08:43:20,284 INFO  namenode.NameNode LogAdapter.java:info:51 - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at clnode059.clemson.cloudlab.us/130.127.133.68
************************************************************/
2019-03-27 08:43:36,229 INFO  namenode.NameNode LogAdapter.java:info:51 - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode059.clemson.cloudlab.us/130.127.133.68
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-03-17T18:59Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-03-27 08:43:36,241 INFO  namenode.NameNode LogAdapter.java:info:51 - registered UNIX signal handlers for [TERM, HUP, INT]
2019-03-27 08:43:36,246 INFO  namenode.NameNode NameNode.java:createNameNode:1583 - createNameNode []
2019-03-27 08:43:36,486 INFO  beanutils.FluentPropertyBeanIntrospector FluentPropertyBeanIntrospector.java:introspect:147 - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2019-03-27 08:43:36,531 INFO  impl.MetricsConfig MetricsConfig.java:loadFirst:121 - loaded properties from hadoop-metrics2.properties
2019-03-27 08:43:36,638 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:startTimer:374 - Scheduled Metric snapshot period at 10 second(s).
2019-03-27 08:43:36,639 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:start:191 - NameNode metrics system started
2019-03-27 08:43:36,690 INFO  namenode.NameNodeUtils NameNodeUtils.java:getClientNamenodeAddress:79 - fs.defaultFS is hdfs://mycluster
2019-03-27 08:43:36,690 INFO  namenode.NameNode NameNode.java:<init>:928 - Clients should use mycluster to access this namenode/service.
2019-03-27 08:43:36,853 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:188 - Starting JVM pause monitor
2019-03-27 08:43:36,880 INFO  hdfs.DFSUtil DFSUtil.java:httpServerTemplateForNNAndJN:1605 - Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-03-27 08:43:36,897 INFO  util.log Log.java:initialized:192 - Logging initialized @1177ms
2019-03-27 08:43:37,003 INFO  server.AuthenticationFilter AuthenticationFilter.java:constructSecretProvider:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-03-27 08:43:37,015 INFO  http.HttpRequestLog HttpRequestLog.java:getRequestLog:81 - Http request log for http.requests.namenode is not defined
2019-03-27 08:43:37,026 INFO  http.HttpServer2 HttpServer2.java:addGlobalFilter:968 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-03-27 08:43:37,030 INFO  http.HttpServer2 HttpServer2.java:addFilter:941 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-03-27 08:43:37,031 INFO  http.HttpServer2 HttpServer2.java:addFilter:951 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-03-27 08:43:37,031 INFO  http.HttpServer2 HttpServer2.java:addFilter:951 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-03-27 08:43:37,058 INFO  http.HttpServer2 NameNodeHttpServer.java:initWebHdfs:100 - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-03-27 08:43:37,058 INFO  http.HttpServer2 HttpServer2.java:addJerseyResourcePackage:787 - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-03-27 08:43:37,067 INFO  http.HttpServer2 HttpServer2.java:bindListener:1185 - Jetty bound to port 9870
2019-03-27 08:43:37,068 INFO  server.Server Server.java:doStart:346 - jetty-9.3.19.v20170502
2019-03-27 08:43:37,103 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@221a3fa4{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-03-27 08:43:37,104 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@2b40ff9c{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-03-27 08:43:37,177 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.w.WebAppContext@6c7a164b{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-03-27 08:43:37,199 INFO  server.AbstractConnector AbstractConnector.java:doStart:278 - Started ServerConnector@1cf56a1c{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-03-27 08:43:37,199 INFO  server.Server Server.java:doStart:414 - Started @1480ms
2019-03-27 08:43:37,572 WARN  namenode.FSNamesystem FSNamesystem.java:checkConfiguration:680 - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-03-27 08:43:37,624 INFO  namenode.FSEditLog FSEditLog.java:newInstance:227 - Edit logging is async:true
2019-03-27 08:43:37,638 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:749 - KeyProvider: null
2019-03-27 08:43:37,640 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:122 - fsLock is fair: true
2019-03-27 08:43:37,643 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:138 - Detailed lock hold time metrics enabled: false
2019-03-27 08:43:37,649 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:774 - fsOwner             = root (auth:SIMPLE)
2019-03-27 08:43:37,650 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:775 - supergroup          = supergroup
2019-03-27 08:43:37,650 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:776 - isPermissionEnabled = true
2019-03-27 08:43:37,650 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:785 - Determined nameservice ID: mycluster
2019-03-27 08:43:37,650 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:787 - HA Enabled: true
2019-03-27 08:43:37,693 INFO  common.Util Util.java:isDiskStatsEnabled:395 - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-03-27 08:43:37,706 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:301 - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-03-27 08:43:37,706 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:309 - dfs.namenode.datanode.registration.ip-hostname-check=true
2019-03-27 08:43:37,711 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:79 - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-03-27 08:43:37,711 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:85 - The block deletion will start around 2019 Mar 27 08:43:37
2019-03-27 08:43:37,713 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map BlocksMap
2019-03-27 08:43:37,713 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 08:43:37,715 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 2.0% max memory 26.7 GB = 546.1 MB
2019-03-27 08:43:37,715 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^26 = 67108864 entries
2019-03-27 08:43:37,860 INFO  blockmanagement.BlockManager BlockManager.java:createBlockTokenSecretManager:579 - dfs.block.access.token.enable = false
2019-03-27 08:43:37,870 INFO  Configuration.deprecation Configuration.java:logDeprecation:1395 - No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-03-27 08:43:37,870 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:161 - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-03-27 08:43:37,871 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:162 - dfs.namenode.safemode.min.datanodes = 0
2019-03-27 08:43:37,871 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:164 - dfs.namenode.safemode.extension = 30000
2019-03-27 08:43:37,871 INFO  blockmanagement.BlockManager BlockManager.java:<init>:565 - defaultReplication         = 3
2019-03-27 08:43:37,871 INFO  blockmanagement.BlockManager BlockManager.java:<init>:566 - maxReplication             = 512
2019-03-27 08:43:37,871 INFO  blockmanagement.BlockManager BlockManager.java:<init>:567 - minReplication             = 1
2019-03-27 08:43:37,871 INFO  blockmanagement.BlockManager BlockManager.java:<init>:568 - maxReplicationStreams      = 2
2019-03-27 08:43:37,871 INFO  blockmanagement.BlockManager BlockManager.java:<init>:569 - redundancyRecheckInterval  = 3000ms
2019-03-27 08:43:37,872 INFO  blockmanagement.BlockManager BlockManager.java:<init>:570 - encryptDataTransfer        = false
2019-03-27 08:43:37,872 INFO  blockmanagement.BlockManager BlockManager.java:<init>:571 - maxNumBlocksToLog          = 1000
2019-03-27 08:43:37,956 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map INodeMap
2019-03-27 08:43:37,956 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 08:43:37,957 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 1.0% max memory 26.7 GB = 273.0 MB
2019-03-27 08:43:37,957 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^25 = 33554432 entries
2019-03-27 08:43:38,030 INFO  namenode.FSDirectory FSDirectory.java:<init>:283 - ACLs enabled? false
2019-03-27 08:43:38,030 INFO  namenode.FSDirectory FSDirectory.java:<init>:287 - POSIX ACL inheritance enabled? true
2019-03-27 08:43:38,030 INFO  namenode.FSDirectory FSDirectory.java:<init>:291 - XAttrs enabled? true
2019-03-27 08:43:38,031 INFO  namenode.NameNode FSDirectory.java:<init>:355 - Caching file names occurring more than 10 times
2019-03-27 08:43:38,038 INFO  snapshot.SnapshotManager SnapshotManager.java:<init>:124 - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-03-27 08:43:38,040 INFO  snapshot.SnapshotManager DirectoryDiffListFactory.java:init:43 - SkipList is disabled
2019-03-27 08:43:38,046 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map cachedBlocks
2019-03-27 08:43:38,046 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 08:43:38,046 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.25% max memory 26.7 GB = 68.3 MB
2019-03-27 08:43:38,047 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^23 = 8388608 entries
2019-03-27 08:43:38,074 INFO  metrics.TopMetrics TopMetrics.java:logConf:76 - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-03-27 08:43:38,074 INFO  metrics.TopMetrics TopMetrics.java:logConf:78 - NNTop conf: dfs.namenode.top.num.users = 10
2019-03-27 08:43:38,075 INFO  metrics.TopMetrics TopMetrics.java:logConf:80 - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-03-27 08:43:38,079 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:979 - Retry cache on namenode is enabled
2019-03-27 08:43:38,079 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:987 - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-03-27 08:43:38,081 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map NameNodeRetryCache
2019-03-27 08:43:38,082 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 08:43:38,082 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-03-27 08:43:38,082 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^20 = 1048576 entries
2019-03-27 08:43:38,145 INFO  common.Storage Storage.java:tryLock:905 - Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 65149@clnode059.clemson.cloudlab.us
2019-03-27 08:43:39,702 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:205 - Detected pause in JVM or host machine (eg GC): pause of approximately 1345ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=333ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1096ms
2019-03-27 08:43:40,819 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:43:40,819 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:43:40,819 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:43:41,820 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:43:41,820 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:43:41,820 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:43:42,821 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:43:42,821 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:43:42,821 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:43:43,822 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:43:43,822 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:43:43,822 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:43:44,250 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-03-27 08:43:44,822 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:43:44,822 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:43:44,823 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:43:45,251 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. Succeeded so far: [10.10.1.5:8485]
2019-03-27 08:43:45,424 INFO  namenode.FSImage FSImage.java:loadFSImage:718 - No edit log streams selected.
2019-03-27 08:43:45,424 INFO  namenode.FSImage FSImage.java:loadFSImageFile:782 - Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-03-27 08:43:45,488 INFO  namenode.ErasureCodingPolicyManager ErasureCodingPolicyManager.java:enablePolicy:390 - Enable the erasure coding policy RS-6-3-1024k
2019-03-27 08:43:45,491 INFO  namenode.FSImageFormatPBINode FSImageFormatPBINode.java:loadINodeSection:266 - Loading 1 INodes.
2019-03-27 08:43:45,522 INFO  namenode.FSImageFormatProtobuf FSImageFormatProtobuf.java:load:190 - Loaded FSImage in 0 seconds.
2019-03-27 08:43:45,522 INFO  namenode.FSImage FSImage.java:loadFSImage:951 - Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-03-27 08:43:45,527 INFO  namenode.FSNamesystem FSNamesystem.java:loadFSImage:1091 - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-03-27 08:43:45,527 INFO  namenode.NameCache NameCache.java:initialized:143 - initialized with 0 entries 0 lookups
2019-03-27 08:43:45,527 INFO  namenode.FSNamesystem FSNamesystem.java:loadFromDisk:721 - Finished loading FSImage in 7438 msecs
2019-03-27 08:43:45,707 INFO  namenode.NameNode NameNodeRpcServer.java:<init>:446 - RPC server is binding to node-0-link-0:8020
2019-03-27 08:43:45,712 INFO  ipc.CallQueueManager CallQueueManager.java:<init>:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-03-27 08:43:45,725 INFO  ipc.Server Server.java:run:1070 - Starting Socket Reader #1 for port 8020
2019-03-27 08:43:45,912 INFO  namenode.FSNamesystem FSNamesystem.java:registerMBean:4973 - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-03-27 08:43:45,920 INFO  namenode.LeaseManager LeaseManager.java:getNumUnderConstructionBlocks:171 - Number of blocks under construction: 0
2019-03-27 08:43:45,931 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:396 - STATE* Leaving safe mode after 0 secs
2019-03-27 08:43:45,931 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:402 - STATE* Network topology has 0 racks and 0 datanodes
2019-03-27 08:43:45,932 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:404 - STATE* UnderReplicatedBlocks has 0 blocks
2019-03-27 08:43:45,966 INFO  ipc.Server Server.java:run:1310 - IPC Server Responder: starting
2019-03-27 08:43:45,966 INFO  ipc.Server Server.java:run:1149 - IPC Server listener on 8020: starting
2019-03-27 08:43:45,972 INFO  namenode.NameNode NameNode.java:startCommonServices:812 - NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-03-27 08:43:45,976 INFO  namenode.FSNamesystem FSNamesystem.java:startStandbyServices:1365 - Starting services required for standby state
2019-03-27 08:43:45,981 INFO  ha.EditLogTailer EditLogTailer.java:<init>:188 - Will roll logs on active node every 120 seconds.
2019-03-27 08:43:45,987 INFO  ha.StandbyCheckpointer StandbyCheckpointer.java:start:139 - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-03-27 08:43:46,467 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.6:9866, datanodeUuid=59167fb6-d46b-44c7-b033-39293f37b06f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a37ce093-ea4c-4553-9e93-92e2b2c117f2;nsid=1513208489;c=1553697789297) storage 59167fb6-d46b-44c7-b033-39293f37b06f
2019-03-27 08:43:46,469 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.6:9866
2019-03-27 08:43:46,470 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 59167fb6-d46b-44c7-b033-39293f37b06f (10.10.1.6:9866).
2019-03-27 08:43:46,515 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=70d1067c-9657-4e93-8b66-2c2c764c9dc1, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a37ce093-ea4c-4553-9e93-92e2b2c117f2;nsid=1513208489;c=1553697789297) storage 70d1067c-9657-4e93-8b66-2c2c764c9dc1
2019-03-27 08:43:46,516 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.3:9866
2019-03-27 08:43:46,516 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 70d1067c-9657-4e93-8b66-2c2c764c9dc1 (10.10.1.3:9866).
2019-03-27 08:43:46,552 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=7e7d4313-7bec-4f08-b24a-1cef8fa683ed, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a37ce093-ea4c-4553-9e93-92e2b2c117f2;nsid=1513208489;c=1553697789297) storage 7e7d4313-7bec-4f08-b24a-1cef8fa683ed
2019-03-27 08:43:46,553 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.2:9866
2019-03-27 08:43:46,553 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 7e7d4313-7bec-4f08-b24a-1cef8fa683ed (10.10.1.2:9866).
2019-03-27 08:43:46,562 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-9cbc3003-3f4e-4e6d-8724-a83ef54c39ff for DN 10.10.1.6:9866
2019-03-27 08:43:46,566 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-19008192-022c-4f35-ab35-a8e81f742fbe for DN 10.10.1.3:9866
2019-03-27 08:43:46,603 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-a4f98693-ca8c-4c02-b808-21c1ddbc355b for DN 10.10.1.2:9866
2019-03-27 08:43:46,614 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0x15d2b9993722a8e: Processing first storage report for DS-19008192-022c-4f35-ab35-a8e81f742fbe from datanode 70d1067c-9657-4e93-8b66-2c2c764c9dc1
2019-03-27 08:43:46,616 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0x15d2b9993722a8e: from storage DS-19008192-022c-4f35-ab35-a8e81f742fbe node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=70d1067c-9657-4e93-8b66-2c2c764c9dc1, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a37ce093-ea4c-4553-9e93-92e2b2c117f2;nsid=1513208489;c=1553697789297), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2019-03-27 08:43:46,616 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0x2e8b20e2dd877aed: Processing first storage report for DS-9cbc3003-3f4e-4e6d-8724-a83ef54c39ff from datanode 59167fb6-d46b-44c7-b033-39293f37b06f
2019-03-27 08:43:46,617 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0x2e8b20e2dd877aed: from storage DS-9cbc3003-3f4e-4e6d-8724-a83ef54c39ff node DatanodeRegistration(10.10.1.6:9866, datanodeUuid=59167fb6-d46b-44c7-b033-39293f37b06f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a37ce093-ea4c-4553-9e93-92e2b2c117f2;nsid=1513208489;c=1553697789297), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-03-27 08:43:46,628 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0xd847b88e255a2142: Processing first storage report for DS-a4f98693-ca8c-4c02-b808-21c1ddbc355b from datanode 7e7d4313-7bec-4f08-b24a-1cef8fa683ed
2019-03-27 08:43:46,629 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0xd847b88e255a2142: from storage DS-a4f98693-ca8c-4c02-b808-21c1ddbc355b node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=7e7d4313-7bec-4f08-b24a-1cef8fa683ed, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a37ce093-ea4c-4553-9e93-92e2b2c117f2;nsid=1513208489;c=1553697789297), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-03-27 08:43:46,764 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=e7260d66-194e-483e-b074-f9a916384eba, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a37ce093-ea4c-4553-9e93-92e2b2c117f2;nsid=1513208489;c=1553697789297) storage e7260d66-194e-483e-b074-f9a916384eba
2019-03-27 08:43:46,765 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.5:9866
2019-03-27 08:43:46,765 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN e7260d66-194e-483e-b074-f9a916384eba (10.10.1.5:9866).
2019-03-27 08:43:46,807 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-3819b486-f720-4501-986b-97a4a1efcff1 for DN 10.10.1.5:9866
2019-03-27 08:43:46,831 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0xac60957adaf923cf: Processing first storage report for DS-3819b486-f720-4501-986b-97a4a1efcff1 from datanode e7260d66-194e-483e-b074-f9a916384eba
2019-03-27 08:43:46,831 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0xac60957adaf923cf: from storage DS-3819b486-f720-4501-986b-97a4a1efcff1 node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=e7260d66-194e-483e-b074-f9a916384eba, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a37ce093-ea4c-4553-9e93-92e2b2c117f2;nsid=1513208489;c=1553697789297), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-03-27 08:44:25,151 INFO  namenode.FSNamesystem FSNamesystem.java:stopStandbyServices:1408 - Stopping services started for standby state
2019-03-27 08:44:25,152 WARN  ha.EditLogTailer EditLogTailer.java:doWork:481 - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:479)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
2019-03-27 08:44:25,155 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1203 - Starting services required for active state
2019-03-27 08:44:25,164 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:435 - Starting recovery process for unclosed journal segments...
2019-03-27 08:44:25,247 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:437 - Successfully started new epoch 2
2019-03-27 08:44:25,248 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:277 - Beginning recovery of unclosed segment starting at txid 1
2019-03-27 08:44:25,280 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:286 - Recovery prepare phase complete. Responses:
10.10.1.2:8485: segmentState { startTxId: 1 endTxId: 136 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 135
10.10.1.5:8485: segmentState { startTxId: 1 endTxId: 136 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 135
2019-03-27 08:44:25,283 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:310 - Using longest log: 10.10.1.2:8485=segmentState {
  startTxId: 1
  endTxId: 136
  isInProgress: true
}
lastWriterEpoch: 1
lastCommittedTxId: 135

2019-03-27 08:44:25,366 INFO  namenode.FileJournalManager FileJournalManager.java:recoverUnfinalizedSegments:396 - Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-03-27 08:44:25,366 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1214 - Catching up to latest edits from old active before taking over writer role in edits logs
2019-03-27 08:44:25,381 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5adbe4a3 expecting start txid #1
2019-03-27 08:44:25,381 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-27 08:44:25,385 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true' to transaction ID 1
2019-03-27 08:44:25,385 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true' to transaction ID 1
2019-03-27 08:44:25,565 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true of size 1048576 edits # 136 loaded in 0 seconds
2019-03-27 08:44:25,565 INFO  blockmanagement.DatanodeManager DatanodeManager.java:markAllDatanodesStale:1837 - Marking all datanodes as stale
2019-03-27 08:44:25,566 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1225 - Reprocessing replication and invalidation queues
2019-03-27 08:44:25,566 INFO  blockmanagement.BlockManager BlockManager.java:initializeReplQueues:4752 - initializing replication queues
2019-03-27 08:44:25,567 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1236 - Will take over writing edit logs at txnid 137
2019-03-27 08:44:25,569 INFO  namenode.FSEditLog FSEditLog.java:startLogSegment:1361 - Starting log segment at 137
2019-03-27 08:44:25,859 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:767 - Initializing quota with 4 thread(s)
2019-03-27 08:44:25,862 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:776 - Quota initialization completed in 3 milliseconds
name space=6
storage space=16106127360
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-03-27 08:44:25,867 INFO  blockmanagement.CacheReplicationMonitor CacheReplicationMonitor.java:run:160 - Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-03-27 08:44:25,933 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3447 - Total number of blocks            = 40
2019-03-27 08:44:25,933 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3448 - Number of invalid blocks          = 0
2019-03-27 08:44:25,934 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3449 - Number of under-replicated blocks = 0
2019-03-27 08:44:25,934 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3450 - Number of  over-replicated blocks = 0
2019-03-27 08:44:25,934 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3452 - Number of blocks being written    = 0
2019-03-27 08:44:25,934 INFO  hdfs.StateChange BlockManager.java:processMisReplicatesAsync:3455 - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 367 msec
2019-03-27 08:44:51,699 ERROR namenode.NameNode LogAdapter.java:error:75 - RECEIVED SIGNAL 15: SIGTERM
2019-03-27 08:44:51,701 INFO  namenode.NameNode LogAdapter.java:info:51 - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at clnode059.clemson.cloudlab.us/130.127.133.68
************************************************************/
2019-03-27 08:45:20,189 INFO  namenode.NameNode LogAdapter.java:info:51 - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode059.clemson.cloudlab.us/130.127.133.68
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-03-17T18:59Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-03-27 08:45:20,201 INFO  namenode.NameNode LogAdapter.java:info:51 - registered UNIX signal handlers for [TERM, HUP, INT]
2019-03-27 08:45:20,206 INFO  namenode.NameNode NameNode.java:createNameNode:1583 - createNameNode []
2019-03-27 08:45:20,449 INFO  beanutils.FluentPropertyBeanIntrospector FluentPropertyBeanIntrospector.java:introspect:147 - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2019-03-27 08:45:20,493 INFO  impl.MetricsConfig MetricsConfig.java:loadFirst:121 - loaded properties from hadoop-metrics2.properties
2019-03-27 08:45:20,599 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:startTimer:374 - Scheduled Metric snapshot period at 10 second(s).
2019-03-27 08:45:20,600 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:start:191 - NameNode metrics system started
2019-03-27 08:45:20,651 INFO  namenode.NameNodeUtils NameNodeUtils.java:getClientNamenodeAddress:79 - fs.defaultFS is hdfs://mycluster
2019-03-27 08:45:20,651 INFO  namenode.NameNode NameNode.java:<init>:928 - Clients should use mycluster to access this namenode/service.
2019-03-27 08:45:20,817 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:188 - Starting JVM pause monitor
2019-03-27 08:45:20,845 INFO  hdfs.DFSUtil DFSUtil.java:httpServerTemplateForNNAndJN:1605 - Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-03-27 08:45:20,862 INFO  util.log Log.java:initialized:192 - Logging initialized @1191ms
2019-03-27 08:45:20,971 INFO  server.AuthenticationFilter AuthenticationFilter.java:constructSecretProvider:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-03-27 08:45:20,983 INFO  http.HttpRequestLog HttpRequestLog.java:getRequestLog:81 - Http request log for http.requests.namenode is not defined
2019-03-27 08:45:20,994 INFO  http.HttpServer2 HttpServer2.java:addGlobalFilter:968 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-03-27 08:45:20,997 INFO  http.HttpServer2 HttpServer2.java:addFilter:941 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-03-27 08:45:20,998 INFO  http.HttpServer2 HttpServer2.java:addFilter:951 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-03-27 08:45:20,999 INFO  http.HttpServer2 HttpServer2.java:addFilter:951 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-03-27 08:45:21,025 INFO  http.HttpServer2 NameNodeHttpServer.java:initWebHdfs:100 - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-03-27 08:45:21,025 INFO  http.HttpServer2 HttpServer2.java:addJerseyResourcePackage:787 - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-03-27 08:45:21,034 INFO  http.HttpServer2 HttpServer2.java:bindListener:1185 - Jetty bound to port 9870
2019-03-27 08:45:21,036 INFO  server.Server Server.java:doStart:346 - jetty-9.3.19.v20170502
2019-03-27 08:45:21,071 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@221a3fa4{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-03-27 08:45:21,072 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@2b40ff9c{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-03-27 08:45:21,146 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.w.WebAppContext@6c7a164b{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-03-27 08:45:21,167 INFO  server.AbstractConnector AbstractConnector.java:doStart:278 - Started ServerConnector@1cf56a1c{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-03-27 08:45:21,167 INFO  server.Server Server.java:doStart:414 - Started @1498ms
2019-03-27 08:45:21,500 WARN  namenode.FSNamesystem FSNamesystem.java:checkConfiguration:680 - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-03-27 08:45:21,558 INFO  namenode.FSEditLog FSEditLog.java:newInstance:227 - Edit logging is async:true
2019-03-27 08:45:21,573 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:749 - KeyProvider: null
2019-03-27 08:45:21,574 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:122 - fsLock is fair: true
2019-03-27 08:45:21,577 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:138 - Detailed lock hold time metrics enabled: false
2019-03-27 08:45:21,584 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:774 - fsOwner             = root (auth:SIMPLE)
2019-03-27 08:45:21,584 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:775 - supergroup          = supergroup
2019-03-27 08:45:21,584 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:776 - isPermissionEnabled = true
2019-03-27 08:45:21,585 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:785 - Determined nameservice ID: mycluster
2019-03-27 08:45:21,585 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:787 - HA Enabled: true
2019-03-27 08:45:21,628 INFO  common.Util Util.java:isDiskStatsEnabled:395 - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-03-27 08:45:21,640 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:301 - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-03-27 08:45:21,640 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:309 - dfs.namenode.datanode.registration.ip-hostname-check=true
2019-03-27 08:45:21,645 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:79 - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-03-27 08:45:21,645 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:85 - The block deletion will start around 2019 Mar 27 08:45:21
2019-03-27 08:45:21,647 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map BlocksMap
2019-03-27 08:45:21,648 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 08:45:21,649 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 2.0% max memory 26.7 GB = 546.1 MB
2019-03-27 08:45:21,649 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^26 = 67108864 entries
2019-03-27 08:45:21,785 INFO  blockmanagement.BlockManager BlockManager.java:createBlockTokenSecretManager:579 - dfs.block.access.token.enable = false
2019-03-27 08:45:21,794 INFO  Configuration.deprecation Configuration.java:logDeprecation:1395 - No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-03-27 08:45:21,794 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:161 - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-03-27 08:45:21,795 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:162 - dfs.namenode.safemode.min.datanodes = 0
2019-03-27 08:45:21,795 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:164 - dfs.namenode.safemode.extension = 30000
2019-03-27 08:45:21,795 INFO  blockmanagement.BlockManager BlockManager.java:<init>:565 - defaultReplication         = 3
2019-03-27 08:45:21,795 INFO  blockmanagement.BlockManager BlockManager.java:<init>:566 - maxReplication             = 512
2019-03-27 08:45:21,795 INFO  blockmanagement.BlockManager BlockManager.java:<init>:567 - minReplication             = 1
2019-03-27 08:45:21,795 INFO  blockmanagement.BlockManager BlockManager.java:<init>:568 - maxReplicationStreams      = 2
2019-03-27 08:45:21,796 INFO  blockmanagement.BlockManager BlockManager.java:<init>:569 - redundancyRecheckInterval  = 3000ms
2019-03-27 08:45:21,796 INFO  blockmanagement.BlockManager BlockManager.java:<init>:570 - encryptDataTransfer        = false
2019-03-27 08:45:21,796 INFO  blockmanagement.BlockManager BlockManager.java:<init>:571 - maxNumBlocksToLog          = 1000
2019-03-27 08:45:21,881 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map INodeMap
2019-03-27 08:45:21,881 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 08:45:21,881 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 1.0% max memory 26.7 GB = 273.0 MB
2019-03-27 08:45:21,881 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^25 = 33554432 entries
2019-03-27 08:45:21,954 INFO  namenode.FSDirectory FSDirectory.java:<init>:283 - ACLs enabled? false
2019-03-27 08:45:21,954 INFO  namenode.FSDirectory FSDirectory.java:<init>:287 - POSIX ACL inheritance enabled? true
2019-03-27 08:45:21,955 INFO  namenode.FSDirectory FSDirectory.java:<init>:291 - XAttrs enabled? true
2019-03-27 08:45:21,955 INFO  namenode.NameNode FSDirectory.java:<init>:355 - Caching file names occurring more than 10 times
2019-03-27 08:45:21,962 INFO  snapshot.SnapshotManager SnapshotManager.java:<init>:124 - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-03-27 08:45:21,965 INFO  snapshot.SnapshotManager DirectoryDiffListFactory.java:init:43 - SkipList is disabled
2019-03-27 08:45:21,970 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map cachedBlocks
2019-03-27 08:45:21,970 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 08:45:21,971 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.25% max memory 26.7 GB = 68.3 MB
2019-03-27 08:45:21,971 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^23 = 8388608 entries
2019-03-27 08:45:21,998 INFO  metrics.TopMetrics TopMetrics.java:logConf:76 - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-03-27 08:45:21,999 INFO  metrics.TopMetrics TopMetrics.java:logConf:78 - NNTop conf: dfs.namenode.top.num.users = 10
2019-03-27 08:45:21,999 INFO  metrics.TopMetrics TopMetrics.java:logConf:80 - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-03-27 08:45:22,003 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:979 - Retry cache on namenode is enabled
2019-03-27 08:45:22,003 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:987 - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-03-27 08:45:22,006 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map NameNodeRetryCache
2019-03-27 08:45:22,006 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 08:45:22,006 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-03-27 08:45:22,006 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^20 = 1048576 entries
2019-03-27 08:45:22,077 INFO  common.Storage Storage.java:tryLock:905 - Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 67153@clnode059.clemson.cloudlab.us
2019-03-27 08:45:23,644 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:205 - Detected pause in JVM or host machine (eg GC): pause of approximately 1322ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=338ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1099ms
2019-03-27 08:45:23,811 INFO  namenode.FSImage FSImage.java:loadFSImageFile:782 - Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-03-27 08:45:23,875 INFO  namenode.ErasureCodingPolicyManager ErasureCodingPolicyManager.java:enablePolicy:390 - Enable the erasure coding policy RS-6-3-1024k
2019-03-27 08:45:23,877 INFO  namenode.FSImageFormatPBINode FSImageFormatPBINode.java:loadINodeSection:266 - Loading 1 INodes.
2019-03-27 08:45:23,909 INFO  namenode.FSImageFormatProtobuf FSImageFormatProtobuf.java:load:190 - Loaded FSImage in 0 seconds.
2019-03-27 08:45:23,909 INFO  namenode.FSImage FSImage.java:loadFSImage:951 - Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-03-27 08:45:23,915 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@68b6f0d6 expecting start txid #1
2019-03-27 08:45:23,915 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-27 08:45:23,919 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true' to transaction ID 1
2019-03-27 08:45:23,919 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true' to transaction ID 1
2019-03-27 08:45:24,100 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true of size 1048576 edits # 136 loaded in 0 seconds
2019-03-27 08:45:24,100 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4044fb95 expecting start txid #137
2019-03-27 08:45:24,101 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=137&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=137&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=137&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-27 08:45:24,101 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=137&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=137&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=137&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true' to transaction ID 1
2019-03-27 08:45:24,101 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=137&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true' to transaction ID 1
2019-03-27 08:45:24,107 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=137&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=137&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=137&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-03-27 08:45:24,107 INFO  namenode.FSNamesystem FSNamesystem.java:loadFSImage:1091 - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-03-27 08:45:24,108 INFO  namenode.NameCache NameCache.java:initialized:143 - initialized with 0 entries 0 lookups
2019-03-27 08:45:24,108 INFO  namenode.FSNamesystem FSNamesystem.java:loadFromDisk:721 - Finished loading FSImage in 2093 msecs
2019-03-27 08:45:24,293 INFO  namenode.NameNode NameNodeRpcServer.java:<init>:446 - RPC server is binding to node-0-link-0:8020
2019-03-27 08:45:24,298 INFO  ipc.CallQueueManager CallQueueManager.java:<init>:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-03-27 08:45:24,310 INFO  ipc.Server Server.java:run:1070 - Starting Socket Reader #1 for port 8020
2019-03-27 08:45:24,497 INFO  namenode.FSNamesystem FSNamesystem.java:registerMBean:4973 - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-03-27 08:45:24,505 INFO  namenode.LeaseManager LeaseManager.java:getNumUnderConstructionBlocks:171 - Number of blocks under construction: 0
2019-03-27 08:45:24,517 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:602 - STATE* Safe mode ON. 
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-03-27 08:45:24,547 INFO  ipc.Server Server.java:run:1310 - IPC Server Responder: starting
2019-03-27 08:45:24,547 INFO  ipc.Server Server.java:run:1149 - IPC Server listener on 8020: starting
2019-03-27 08:45:24,551 INFO  namenode.NameNode NameNode.java:startCommonServices:812 - NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-03-27 08:45:24,554 INFO  namenode.FSNamesystem FSNamesystem.java:startStandbyServices:1365 - Starting services required for standby state
2019-03-27 08:45:24,560 INFO  ha.EditLogTailer EditLogTailer.java:<init>:188 - Will roll logs on active node every 120 seconds.
2019-03-27 08:45:24,565 INFO  ha.StandbyCheckpointer StandbyCheckpointer.java:start:139 - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-03-27 08:45:24,758 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.6:9866, datanodeUuid=59167fb6-d46b-44c7-b033-39293f37b06f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a37ce093-ea4c-4553-9e93-92e2b2c117f2;nsid=1513208489;c=1553697789297) storage 59167fb6-d46b-44c7-b033-39293f37b06f
2019-03-27 08:45:24,759 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.6:9866
2019-03-27 08:45:24,760 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 59167fb6-d46b-44c7-b033-39293f37b06f (10.10.1.6:9866).
2019-03-27 08:45:24,762 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=70d1067c-9657-4e93-8b66-2c2c764c9dc1, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a37ce093-ea4c-4553-9e93-92e2b2c117f2;nsid=1513208489;c=1553697789297) storage 70d1067c-9657-4e93-8b66-2c2c764c9dc1
2019-03-27 08:45:24,762 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.3:9866
2019-03-27 08:45:24,762 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 70d1067c-9657-4e93-8b66-2c2c764c9dc1 (10.10.1.3:9866).
2019-03-27 08:45:24,762 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=7e7d4313-7bec-4f08-b24a-1cef8fa683ed, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a37ce093-ea4c-4553-9e93-92e2b2c117f2;nsid=1513208489;c=1553697789297) storage 7e7d4313-7bec-4f08-b24a-1cef8fa683ed
2019-03-27 08:45:24,763 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.2:9866
2019-03-27 08:45:24,763 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 7e7d4313-7bec-4f08-b24a-1cef8fa683ed (10.10.1.2:9866).
2019-03-27 08:45:24,775 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-a4f98693-ca8c-4c02-b808-21c1ddbc355b for DN 10.10.1.2:9866
2019-03-27 08:45:24,778 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-9cbc3003-3f4e-4e6d-8724-a83ef54c39ff for DN 10.10.1.6:9866
2019-03-27 08:45:24,779 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-19008192-022c-4f35-ab35-a8e81f742fbe for DN 10.10.1.3:9866
2019-03-27 08:45:24,791 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0x15d2b9993722a8f: Processing first storage report for DS-19008192-022c-4f35-ab35-a8e81f742fbe from datanode 70d1067c-9657-4e93-8b66-2c2c764c9dc1
2019-03-27 08:45:24,798 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0x15d2b9993722a8f: from storage DS-19008192-022c-4f35-ab35-a8e81f742fbe node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=70d1067c-9657-4e93-8b66-2c2c764c9dc1, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a37ce093-ea4c-4553-9e93-92e2b2c117f2;nsid=1513208489;c=1553697789297), blocks: 34, hasStaleStorage: false, processing time: 6 msecs, invalidatedBlocks: 0
2019-03-27 08:45:24,798 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0xd847b88e255a2143: Processing first storage report for DS-a4f98693-ca8c-4c02-b808-21c1ddbc355b from datanode 7e7d4313-7bec-4f08-b24a-1cef8fa683ed
2019-03-27 08:45:24,800 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0xd847b88e255a2143: from storage DS-a4f98693-ca8c-4c02-b808-21c1ddbc355b node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=7e7d4313-7bec-4f08-b24a-1cef8fa683ed, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a37ce093-ea4c-4553-9e93-92e2b2c117f2;nsid=1513208489;c=1553697789297), blocks: 31, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2019-03-27 08:45:24,800 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0x2e8b20e2dd877aee: Processing first storage report for DS-9cbc3003-3f4e-4e6d-8724-a83ef54c39ff from datanode 59167fb6-d46b-44c7-b033-39293f37b06f
2019-03-27 08:45:24,801 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0x2e8b20e2dd877aee: from storage DS-9cbc3003-3f4e-4e6d-8724-a83ef54c39ff node DatanodeRegistration(10.10.1.6:9866, datanodeUuid=59167fb6-d46b-44c7-b033-39293f37b06f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a37ce093-ea4c-4553-9e93-92e2b2c117f2;nsid=1513208489;c=1553697789297), blocks: 28, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-03-27 08:45:24,803 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=e7260d66-194e-483e-b074-f9a916384eba, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a37ce093-ea4c-4553-9e93-92e2b2c117f2;nsid=1513208489;c=1553697789297) storage e7260d66-194e-483e-b074-f9a916384eba
2019-03-27 08:45:24,803 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.5:9866
2019-03-27 08:45:24,803 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN e7260d66-194e-483e-b074-f9a916384eba (10.10.1.5:9866).
2019-03-27 08:45:24,805 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-3819b486-f720-4501-986b-97a4a1efcff1 for DN 10.10.1.5:9866
2019-03-27 08:45:24,806 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0xac60957adaf923d0: Processing first storage report for DS-3819b486-f720-4501-986b-97a4a1efcff1 from datanode e7260d66-194e-483e-b074-f9a916384eba
2019-03-27 08:45:24,807 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0xac60957adaf923d0: from storage DS-3819b486-f720-4501-986b-97a4a1efcff1 node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=e7260d66-194e-483e-b074-f9a916384eba, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a37ce093-ea4c-4553-9e93-92e2b2c117f2;nsid=1513208489;c=1553697789297), blocks: 27, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-03-27 08:46:04,623 INFO  namenode.FSNamesystem FSNamesystem.java:stopStandbyServices:1408 - Stopping services started for standby state
2019-03-27 08:46:04,624 WARN  ha.EditLogTailer EditLogTailer.java:doWork:481 - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:479)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
2019-03-27 08:46:04,627 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1203 - Starting services required for active state
2019-03-27 08:46:04,635 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:435 - Starting recovery process for unclosed journal segments...
2019-03-27 08:46:04,688 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:437 - Successfully started new epoch 4
2019-03-27 08:46:04,688 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:277 - Beginning recovery of unclosed segment starting at txid 138
2019-03-27 08:46:04,710 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:286 - Recovery prepare phase complete. Responses:
10.10.1.2:8485: segmentState { startTxId: 138 endTxId: 138 isInProgress: true } lastWriterEpoch: 3 lastCommittedTxId: 138
10.10.1.5:8485: segmentState { startTxId: 138 endTxId: 138 isInProgress: true } lastWriterEpoch: 3 lastCommittedTxId: 135
2019-03-27 08:46:04,712 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:310 - Using longest log: 10.10.1.2:8485=segmentState {
  startTxId: 138
  endTxId: 138
  isInProgress: true
}
lastWriterEpoch: 3
lastCommittedTxId: 138

2019-03-27 08:46:04,755 INFO  namenode.FileJournalManager FileJournalManager.java:recoverUnfinalizedSegments:396 - Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-03-27 08:46:04,769 INFO  namenode.FileJournalManager FileJournalManager.java:finalizeLogSegment:143 - Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000137 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000137-0000000000000000137
2019-03-27 08:46:04,785 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1214 - Catching up to latest edits from old active before taking over writer role in edits logs
2019-03-27 08:46:04,792 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5b53e8eb expecting start txid #138
2019-03-27 08:46:04,793 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=138&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=138&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-27 08:46:04,793 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=138&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=138&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true' to transaction ID 138
2019-03-27 08:46:04,793 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=138&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true' to transaction ID 138
2019-03-27 08:46:04,801 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=138&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=138&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-03-27 08:46:04,801 INFO  blockmanagement.DatanodeManager DatanodeManager.java:markAllDatanodesStale:1837 - Marking all datanodes as stale
2019-03-27 08:46:04,802 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1236 - Will take over writing edit logs at txnid 139
2019-03-27 08:46:04,805 INFO  namenode.FSEditLog FSEditLog.java:startLogSegment:1361 - Starting log segment at 139
2019-03-27 08:46:05,100 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:767 - Initializing quota with 4 thread(s)
2019-03-27 08:46:05,104 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:776 - Quota initialization completed in 3 milliseconds
name space=6
storage space=16106127360
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-03-27 08:46:05,109 INFO  blockmanagement.CacheReplicationMonitor CacheReplicationMonitor.java:run:160 - Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-03-27 08:46:05,109 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:602 - STATE* Safe mode ON. 
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-03-27 08:46:05,195 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 2 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53394
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:05,195 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 3 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53392
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:05,210 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 9 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53394
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:05,210 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53392
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:05,955 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 6 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53394
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:06,309 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 6 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53392
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:07,793 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 3 on 8020, call Call#3 Retry#3 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53394
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:08,349 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 5 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53408
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:08,363 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 3 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53408
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:08,933 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 6 on 8020, call Call#3 Retry#3 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53392
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:09,084 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 1 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53408
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:10,940 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 8 on 8020, call Call#3 Retry#3 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53408
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:11,782 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 4 on 8020, call Call#3 Retry#4 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53392
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:11,793 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 8 on 8020, call Call#3 Retry#4 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53394
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:13,613 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 3 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53416
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:13,634 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 9 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53416
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:14,905 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 8 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53418
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:14,919 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 1 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53418
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:15,134 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 3 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53416
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:16,015 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 7 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53418
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:16,513 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 6 on 8020, call Call#3 Retry#4 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53408
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:17,018 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 2 on 8020, call Call#3 Retry#5 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53392
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:17,736 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 8 on 8020, call Call#3 Retry#5 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53394
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:17,951 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 7 on 8020, call Call#3 Retry#3 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53416
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:18,232 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 1 on 8020, call Call#3 Retry#3 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53418
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:20,978 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 6 on 8020, call Call#3 Retry#4 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53416
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:21,532 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 6 on 8020, call Call#3 Retry#4 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53418
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:22,536 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 4 on 8020, call Call#3 Retry#5 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53408
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:26,848 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 6 on 8020, call Call#3 Retry#5 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53418
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:29,584 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 5 on 8020, call Call#3 Retry#5 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:53416
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-0-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 08:46:31,739 ERROR namenode.NameNode LogAdapter.java:error:75 - RECEIVED SIGNAL 15: SIGTERM
2019-03-27 08:46:31,741 INFO  namenode.NameNode LogAdapter.java:info:51 - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at clnode059.clemson.cloudlab.us/130.127.133.68
************************************************************/
2019-03-27 08:46:35,863 INFO  namenode.NameNode LogAdapter.java:info:51 - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode059.clemson.cloudlab.us/130.127.133.68
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-03-17T18:59Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-03-27 08:46:35,874 INFO  namenode.NameNode LogAdapter.java:info:51 - registered UNIX signal handlers for [TERM, HUP, INT]
2019-03-27 08:46:35,879 INFO  namenode.NameNode NameNode.java:createNameNode:1583 - createNameNode []
2019-03-27 08:46:36,124 INFO  beanutils.FluentPropertyBeanIntrospector FluentPropertyBeanIntrospector.java:introspect:147 - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2019-03-27 08:46:36,168 INFO  impl.MetricsConfig MetricsConfig.java:loadFirst:121 - loaded properties from hadoop-metrics2.properties
2019-03-27 08:46:36,273 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:startTimer:374 - Scheduled Metric snapshot period at 10 second(s).
2019-03-27 08:46:36,274 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:start:191 - NameNode metrics system started
2019-03-27 08:46:36,325 INFO  namenode.NameNodeUtils NameNodeUtils.java:getClientNamenodeAddress:79 - fs.defaultFS is hdfs://mycluster
2019-03-27 08:46:36,326 INFO  namenode.NameNode NameNode.java:<init>:928 - Clients should use mycluster to access this namenode/service.
2019-03-27 08:46:36,495 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:188 - Starting JVM pause monitor
2019-03-27 08:46:36,522 INFO  hdfs.DFSUtil DFSUtil.java:httpServerTemplateForNNAndJN:1605 - Starting Web-server for hdfs at: http://node-0-link-0:9870
2019-03-27 08:46:36,540 INFO  util.log Log.java:initialized:192 - Logging initialized @1195ms
2019-03-27 08:46:36,650 INFO  server.AuthenticationFilter AuthenticationFilter.java:constructSecretProvider:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-03-27 08:46:36,662 INFO  http.HttpRequestLog HttpRequestLog.java:getRequestLog:81 - Http request log for http.requests.namenode is not defined
2019-03-27 08:46:36,673 INFO  http.HttpServer2 HttpServer2.java:addGlobalFilter:968 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-03-27 08:46:36,677 INFO  http.HttpServer2 HttpServer2.java:addFilter:941 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-03-27 08:46:36,678 INFO  http.HttpServer2 HttpServer2.java:addFilter:951 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-03-27 08:46:36,678 INFO  http.HttpServer2 HttpServer2.java:addFilter:951 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-03-27 08:46:36,705 INFO  http.HttpServer2 NameNodeHttpServer.java:initWebHdfs:100 - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-03-27 08:46:36,705 INFO  http.HttpServer2 HttpServer2.java:addJerseyResourcePackage:787 - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-03-27 08:46:36,714 INFO  http.HttpServer2 HttpServer2.java:bindListener:1185 - Jetty bound to port 9870
2019-03-27 08:46:36,716 INFO  server.Server Server.java:doStart:346 - jetty-9.3.19.v20170502
2019-03-27 08:46:36,751 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@221a3fa4{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-03-27 08:46:36,752 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@2b40ff9c{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-03-27 08:46:36,827 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.w.WebAppContext@6c7a164b{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-03-27 08:46:36,847 INFO  server.AbstractConnector AbstractConnector.java:doStart:278 - Started ServerConnector@1cf56a1c{HTTP/1.1,[http/1.1]}{node-0-link-0:9870}
2019-03-27 08:46:36,847 INFO  server.Server Server.java:doStart:414 - Started @1504ms
2019-03-27 08:46:37,179 WARN  namenode.FSNamesystem FSNamesystem.java:checkConfiguration:680 - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-03-27 08:46:37,230 INFO  namenode.FSEditLog FSEditLog.java:newInstance:227 - Edit logging is async:true
2019-03-27 08:46:37,245 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:749 - KeyProvider: null
2019-03-27 08:46:37,247 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:122 - fsLock is fair: true
2019-03-27 08:46:37,249 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:138 - Detailed lock hold time metrics enabled: false
2019-03-27 08:46:37,256 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:774 - fsOwner             = root (auth:SIMPLE)
2019-03-27 08:46:37,256 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:775 - supergroup          = supergroup
2019-03-27 08:46:37,256 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:776 - isPermissionEnabled = true
2019-03-27 08:46:37,257 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:785 - Determined nameservice ID: mycluster
2019-03-27 08:46:37,257 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:787 - HA Enabled: true
2019-03-27 08:46:37,300 INFO  common.Util Util.java:isDiskStatsEnabled:395 - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-03-27 08:46:37,313 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:301 - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-03-27 08:46:37,313 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:309 - dfs.namenode.datanode.registration.ip-hostname-check=true
2019-03-27 08:46:37,318 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:79 - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-03-27 08:46:37,318 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:85 - The block deletion will start around 2019 Mar 27 08:46:37
2019-03-27 08:46:37,320 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map BlocksMap
2019-03-27 08:46:37,320 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 08:46:37,322 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 2.0% max memory 26.7 GB = 546.1 MB
2019-03-27 08:46:37,322 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^26 = 67108864 entries
2019-03-27 08:46:37,455 INFO  blockmanagement.BlockManager BlockManager.java:createBlockTokenSecretManager:579 - dfs.block.access.token.enable = false
2019-03-27 08:46:37,465 INFO  Configuration.deprecation Configuration.java:logDeprecation:1395 - No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-03-27 08:46:37,465 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:161 - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-03-27 08:46:37,465 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:162 - dfs.namenode.safemode.min.datanodes = 0
2019-03-27 08:46:37,465 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:164 - dfs.namenode.safemode.extension = 30000
2019-03-27 08:46:37,465 INFO  blockmanagement.BlockManager BlockManager.java:<init>:565 - defaultReplication         = 3
2019-03-27 08:46:37,466 INFO  blockmanagement.BlockManager BlockManager.java:<init>:566 - maxReplication             = 512
2019-03-27 08:46:37,466 INFO  blockmanagement.BlockManager BlockManager.java:<init>:567 - minReplication             = 1
2019-03-27 08:46:37,466 INFO  blockmanagement.BlockManager BlockManager.java:<init>:568 - maxReplicationStreams      = 2
2019-03-27 08:46:37,466 INFO  blockmanagement.BlockManager BlockManager.java:<init>:569 - redundancyRecheckInterval  = 3000ms
2019-03-27 08:46:37,466 INFO  blockmanagement.BlockManager BlockManager.java:<init>:570 - encryptDataTransfer        = false
2019-03-27 08:46:37,466 INFO  blockmanagement.BlockManager BlockManager.java:<init>:571 - maxNumBlocksToLog          = 1000
2019-03-27 08:46:37,551 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map INodeMap
2019-03-27 08:46:37,551 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 08:46:37,551 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 1.0% max memory 26.7 GB = 273.0 MB
2019-03-27 08:46:37,551 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^25 = 33554432 entries
2019-03-27 08:46:37,624 INFO  namenode.FSDirectory FSDirectory.java:<init>:283 - ACLs enabled? false
2019-03-27 08:46:37,624 INFO  namenode.FSDirectory FSDirectory.java:<init>:287 - POSIX ACL inheritance enabled? true
2019-03-27 08:46:37,625 INFO  namenode.FSDirectory FSDirectory.java:<init>:291 - XAttrs enabled? true
2019-03-27 08:46:37,625 INFO  namenode.NameNode FSDirectory.java:<init>:355 - Caching file names occurring more than 10 times
2019-03-27 08:46:37,632 INFO  snapshot.SnapshotManager SnapshotManager.java:<init>:124 - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-03-27 08:46:37,635 INFO  snapshot.SnapshotManager DirectoryDiffListFactory.java:init:43 - SkipList is disabled
2019-03-27 08:46:37,640 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map cachedBlocks
2019-03-27 08:46:37,640 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 08:46:37,641 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.25% max memory 26.7 GB = 68.3 MB
2019-03-27 08:46:37,641 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^23 = 8388608 entries
2019-03-27 08:46:37,668 INFO  metrics.TopMetrics TopMetrics.java:logConf:76 - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-03-27 08:46:37,669 INFO  metrics.TopMetrics TopMetrics.java:logConf:78 - NNTop conf: dfs.namenode.top.num.users = 10
2019-03-27 08:46:37,669 INFO  metrics.TopMetrics TopMetrics.java:logConf:80 - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-03-27 08:46:37,673 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:979 - Retry cache on namenode is enabled
2019-03-27 08:46:37,673 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:987 - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-03-27 08:46:37,676 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map NameNodeRetryCache
2019-03-27 08:46:37,676 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 08:46:37,676 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-03-27 08:46:37,676 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^20 = 1048576 entries
2019-03-27 08:46:37,771 INFO  common.Storage Storage.java:tryLock:905 - Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 68826@clnode059.clemson.cloudlab.us
2019-03-27 08:46:39,344 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:205 - Detected pause in JVM or host machine (eg GC): pause of approximately 1345ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=326ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1102ms
2019-03-27 08:46:39,494 INFO  namenode.FSImage FSImage.java:loadFSImageFile:782 - Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-03-27 08:46:39,560 INFO  namenode.ErasureCodingPolicyManager ErasureCodingPolicyManager.java:enablePolicy:390 - Enable the erasure coding policy RS-6-3-1024k
2019-03-27 08:46:39,562 INFO  namenode.FSImageFormatPBINode FSImageFormatPBINode.java:loadINodeSection:266 - Loading 1 INodes.
2019-03-27 08:46:39,594 INFO  namenode.FSImageFormatProtobuf FSImageFormatProtobuf.java:load:190 - Loaded FSImage in 0 seconds.
2019-03-27 08:46:39,594 INFO  namenode.FSImage FSImage.java:loadFSImage:951 - Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-03-27 08:46:39,599 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@68b6f0d6 expecting start txid #1
2019-03-27 08:46:39,600 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-27 08:46:39,604 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true' to transaction ID 1
2019-03-27 08:46:39,604 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true' to transaction ID 1
2019-03-27 08:46:39,698 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true of size 1048576 edits # 136 loaded in 0 seconds
2019-03-27 08:46:39,698 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4044fb95 expecting start txid #137
2019-03-27 08:46:39,698 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=137&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=137&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=137&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-27 08:46:39,698 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=137&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=137&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=137&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true' to transaction ID 1
2019-03-27 08:46:39,699 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=137&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true' to transaction ID 1
2019-03-27 08:46:39,703 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=137&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=137&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=137&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-03-27 08:46:39,703 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@aa549e5 expecting start txid #138
2019-03-27 08:46:39,703 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=138&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=138&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=138&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-27 08:46:39,703 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=138&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=138&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=138&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true' to transaction ID 1
2019-03-27 08:46:39,703 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=138&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true' to transaction ID 1
2019-03-27 08:46:39,709 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=138&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=138&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=138&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-03-27 08:46:39,709 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@36f48b4 expecting start txid #139
2019-03-27 08:46:39,709 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=139&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=139&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=139&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-27 08:46:39,709 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=139&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=139&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=139&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true' to transaction ID 1
2019-03-27 08:46:39,710 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=139&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true' to transaction ID 1
2019-03-27 08:46:39,715 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=139&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=139&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=139&storageInfo=-64%3A1513208489%3A1553697789297%3ACID-a37ce093-ea4c-4553-9e93-92e2b2c117f2&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-03-27 08:46:39,716 INFO  namenode.FSNamesystem FSNamesystem.java:loadFSImage:1091 - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-03-27 08:46:39,716 INFO  namenode.NameCache NameCache.java:initialized:143 - initialized with 0 entries 0 lookups
2019-03-27 08:46:39,716 INFO  namenode.FSNamesystem FSNamesystem.java:loadFromDisk:721 - Finished loading FSImage in 2032 msecs
2019-03-27 08:46:39,902 INFO  namenode.NameNode NameNodeRpcServer.java:<init>:446 - RPC server is binding to node-0-link-0:8020
2019-03-27 08:46:39,907 INFO  ipc.CallQueueManager CallQueueManager.java:<init>:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-03-27 08:46:39,920 INFO  ipc.Server Server.java:run:1070 - Starting Socket Reader #1 for port 8020
2019-03-27 08:46:40,107 INFO  namenode.FSNamesystem FSNamesystem.java:registerMBean:4973 - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-03-27 08:46:40,116 INFO  namenode.LeaseManager LeaseManager.java:getNumUnderConstructionBlocks:171 - Number of blocks under construction: 0
2019-03-27 08:46:40,128 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:602 - STATE* Safe mode ON. 
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-03-27 08:46:40,162 INFO  ipc.Server Server.java:run:1310 - IPC Server Responder: starting
2019-03-27 08:46:40,162 INFO  ipc.Server Server.java:run:1149 - IPC Server listener on 8020: starting
2019-03-27 08:46:40,165 INFO  namenode.NameNode NameNode.java:startCommonServices:812 - NameNode RPC up at: node-0-link-0/10.10.1.1:8020
2019-03-27 08:46:40,169 INFO  namenode.FSNamesystem FSNamesystem.java:startStandbyServices:1365 - Starting services required for standby state
2019-03-27 08:46:40,175 INFO  ha.EditLogTailer EditLogTailer.java:<init>:188 - Will roll logs on active node every 120 seconds.
2019-03-27 08:46:40,181 INFO  ha.StandbyCheckpointer StandbyCheckpointer.java:start:139 - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-1-link-0:9870]
Serving checkpoints at http://node-0-link-0:9870
2019-03-27 08:46:40,917 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=e7260d66-194e-483e-b074-f9a916384eba, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a37ce093-ea4c-4553-9e93-92e2b2c117f2;nsid=1513208489;c=1553697789297) storage e7260d66-194e-483e-b074-f9a916384eba
2019-03-27 08:46:40,919 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.5:9866
2019-03-27 08:46:40,920 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN e7260d66-194e-483e-b074-f9a916384eba (10.10.1.5:9866).
2019-03-27 08:46:40,921 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.6:9866, datanodeUuid=59167fb6-d46b-44c7-b033-39293f37b06f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a37ce093-ea4c-4553-9e93-92e2b2c117f2;nsid=1513208489;c=1553697789297) storage 59167fb6-d46b-44c7-b033-39293f37b06f
2019-03-27 08:46:40,921 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.6:9866
2019-03-27 08:46:40,922 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 59167fb6-d46b-44c7-b033-39293f37b06f (10.10.1.6:9866).
2019-03-27 08:46:40,922 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=7e7d4313-7bec-4f08-b24a-1cef8fa683ed, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a37ce093-ea4c-4553-9e93-92e2b2c117f2;nsid=1513208489;c=1553697789297) storage 7e7d4313-7bec-4f08-b24a-1cef8fa683ed
2019-03-27 08:46:40,923 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.2:9866
2019-03-27 08:46:40,923 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 7e7d4313-7bec-4f08-b24a-1cef8fa683ed (10.10.1.2:9866).
2019-03-27 08:46:40,923 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=70d1067c-9657-4e93-8b66-2c2c764c9dc1, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a37ce093-ea4c-4553-9e93-92e2b2c117f2;nsid=1513208489;c=1553697789297) storage 70d1067c-9657-4e93-8b66-2c2c764c9dc1
2019-03-27 08:46:40,923 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.3:9866
2019-03-27 08:46:40,924 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 70d1067c-9657-4e93-8b66-2c2c764c9dc1 (10.10.1.3:9866).
2019-03-27 08:46:40,932 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-19008192-022c-4f35-ab35-a8e81f742fbe for DN 10.10.1.3:9866
2019-03-27 08:46:40,935 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-a4f98693-ca8c-4c02-b808-21c1ddbc355b for DN 10.10.1.2:9866
2019-03-27 08:46:40,936 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-3819b486-f720-4501-986b-97a4a1efcff1 for DN 10.10.1.5:9866
2019-03-27 08:46:40,936 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-9cbc3003-3f4e-4e6d-8724-a83ef54c39ff for DN 10.10.1.6:9866
2019-03-27 08:46:40,948 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0xac60957adaf923d1: Processing first storage report for DS-3819b486-f720-4501-986b-97a4a1efcff1 from datanode e7260d66-194e-483e-b074-f9a916384eba
2019-03-27 08:46:40,955 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0xac60957adaf923d1: from storage DS-3819b486-f720-4501-986b-97a4a1efcff1 node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=e7260d66-194e-483e-b074-f9a916384eba, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a37ce093-ea4c-4553-9e93-92e2b2c117f2;nsid=1513208489;c=1553697789297), blocks: 27, hasStaleStorage: false, processing time: 7 msecs, invalidatedBlocks: 0
2019-03-27 08:46:40,955 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0xd847b88e255a2144: Processing first storage report for DS-a4f98693-ca8c-4c02-b808-21c1ddbc355b from datanode 7e7d4313-7bec-4f08-b24a-1cef8fa683ed
2019-03-27 08:46:40,956 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0xd847b88e255a2144: from storage DS-a4f98693-ca8c-4c02-b808-21c1ddbc355b node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=7e7d4313-7bec-4f08-b24a-1cef8fa683ed, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a37ce093-ea4c-4553-9e93-92e2b2c117f2;nsid=1513208489;c=1553697789297), blocks: 31, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-03-27 08:46:40,956 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0x2e8b20e2dd877aef: Processing first storage report for DS-9cbc3003-3f4e-4e6d-8724-a83ef54c39ff from datanode 59167fb6-d46b-44c7-b033-39293f37b06f
2019-03-27 08:46:40,957 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0x2e8b20e2dd877aef: from storage DS-9cbc3003-3f4e-4e6d-8724-a83ef54c39ff node DatanodeRegistration(10.10.1.6:9866, datanodeUuid=59167fb6-d46b-44c7-b033-39293f37b06f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a37ce093-ea4c-4553-9e93-92e2b2c117f2;nsid=1513208489;c=1553697789297), blocks: 28, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-03-27 08:46:40,957 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0x15d2b9993722a90: Processing first storage report for DS-19008192-022c-4f35-ab35-a8e81f742fbe from datanode 70d1067c-9657-4e93-8b66-2c2c764c9dc1
2019-03-27 08:46:40,959 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0x15d2b9993722a90: from storage DS-19008192-022c-4f35-ab35-a8e81f742fbe node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=70d1067c-9657-4e93-8b66-2c2c764c9dc1, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-a37ce093-ea4c-4553-9e93-92e2b2c117f2;nsid=1513208489;c=1553697789297), blocks: 34, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0

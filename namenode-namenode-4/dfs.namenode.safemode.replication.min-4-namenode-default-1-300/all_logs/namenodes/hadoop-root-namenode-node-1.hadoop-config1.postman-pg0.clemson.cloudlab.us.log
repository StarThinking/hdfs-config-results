2019-03-27 08:54:12,938 INFO  namenode.NameNode LogAdapter.java:info:51 - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode043.clemson.cloudlab.us/130.127.133.52
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-03-17T18:59Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-03-27 08:54:12,950 INFO  namenode.NameNode LogAdapter.java:info:51 - registered UNIX signal handlers for [TERM, HUP, INT]
2019-03-27 08:54:12,955 INFO  namenode.NameNode NameNode.java:createNameNode:1583 - createNameNode []
2019-03-27 08:54:13,198 INFO  beanutils.FluentPropertyBeanIntrospector FluentPropertyBeanIntrospector.java:introspect:147 - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2019-03-27 08:54:13,242 INFO  impl.MetricsConfig MetricsConfig.java:loadFirst:121 - loaded properties from hadoop-metrics2.properties
2019-03-27 08:54:13,346 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:startTimer:374 - Scheduled Metric snapshot period at 10 second(s).
2019-03-27 08:54:13,346 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:start:191 - NameNode metrics system started
2019-03-27 08:54:13,401 INFO  namenode.NameNodeUtils NameNodeUtils.java:getClientNamenodeAddress:79 - fs.defaultFS is hdfs://mycluster
2019-03-27 08:54:13,401 INFO  namenode.NameNode NameNode.java:<init>:928 - Clients should use mycluster to access this namenode/service.
2019-03-27 08:54:13,568 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:188 - Starting JVM pause monitor
2019-03-27 08:54:13,596 INFO  hdfs.DFSUtil DFSUtil.java:httpServerTemplateForNNAndJN:1605 - Starting Web-server for hdfs at: http://node-1-link-0:9870
2019-03-27 08:54:13,613 INFO  util.log Log.java:initialized:192 - Logging initialized @1190ms
2019-03-27 08:54:13,721 INFO  server.AuthenticationFilter AuthenticationFilter.java:constructSecretProvider:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-03-27 08:54:13,733 INFO  http.HttpRequestLog HttpRequestLog.java:getRequestLog:81 - Http request log for http.requests.namenode is not defined
2019-03-27 08:54:13,744 INFO  http.HttpServer2 HttpServer2.java:addGlobalFilter:968 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-03-27 08:54:13,747 INFO  http.HttpServer2 HttpServer2.java:addFilter:941 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-03-27 08:54:13,748 INFO  http.HttpServer2 HttpServer2.java:addFilter:951 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-03-27 08:54:13,749 INFO  http.HttpServer2 HttpServer2.java:addFilter:951 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-03-27 08:54:13,780 INFO  http.HttpServer2 NameNodeHttpServer.java:initWebHdfs:100 - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-03-27 08:54:13,780 INFO  http.HttpServer2 HttpServer2.java:addJerseyResourcePackage:787 - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-03-27 08:54:13,790 INFO  http.HttpServer2 HttpServer2.java:bindListener:1185 - Jetty bound to port 9870
2019-03-27 08:54:13,791 INFO  server.Server Server.java:doStart:346 - jetty-9.3.19.v20170502
2019-03-27 08:54:13,827 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@221a3fa4{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-03-27 08:54:13,828 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@2b40ff9c{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-03-27 08:54:13,902 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.w.WebAppContext@6c7a164b{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-03-27 08:54:13,929 INFO  server.AbstractConnector AbstractConnector.java:doStart:278 - Started ServerConnector@1cf56a1c{HTTP/1.1,[http/1.1]}{node-1-link-0:9870}
2019-03-27 08:54:13,930 INFO  server.Server Server.java:doStart:414 - Started @1508ms
2019-03-27 08:54:14,278 WARN  namenode.FSNamesystem FSNamesystem.java:checkConfiguration:680 - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-03-27 08:54:14,336 INFO  namenode.FSEditLog FSEditLog.java:newInstance:227 - Edit logging is async:true
2019-03-27 08:54:14,351 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:749 - KeyProvider: null
2019-03-27 08:54:14,352 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:122 - fsLock is fair: true
2019-03-27 08:54:14,355 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:138 - Detailed lock hold time metrics enabled: false
2019-03-27 08:54:14,362 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:774 - fsOwner             = root (auth:SIMPLE)
2019-03-27 08:54:14,362 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:775 - supergroup          = supergroup
2019-03-27 08:54:14,362 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:776 - isPermissionEnabled = true
2019-03-27 08:54:14,363 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:785 - Determined nameservice ID: mycluster
2019-03-27 08:54:14,363 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:787 - HA Enabled: true
2019-03-27 08:54:14,406 INFO  common.Util Util.java:isDiskStatsEnabled:395 - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-03-27 08:54:14,418 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:301 - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-03-27 08:54:14,419 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:309 - dfs.namenode.datanode.registration.ip-hostname-check=true
2019-03-27 08:54:14,423 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:79 - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-03-27 08:54:14,424 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:85 - The block deletion will start around 2019 Mar 27 08:54:14
2019-03-27 08:54:14,426 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map BlocksMap
2019-03-27 08:54:14,426 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 08:54:14,428 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 2.0% max memory 26.7 GB = 546.1 MB
2019-03-27 08:54:14,428 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^26 = 67108864 entries
2019-03-27 08:54:14,554 INFO  blockmanagement.BlockManager BlockManager.java:createBlockTokenSecretManager:579 - dfs.block.access.token.enable = false
2019-03-27 08:54:14,564 INFO  Configuration.deprecation Configuration.java:logDeprecation:1395 - No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-03-27 08:54:14,564 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:161 - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-03-27 08:54:14,564 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:162 - dfs.namenode.safemode.min.datanodes = 0
2019-03-27 08:54:14,564 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:164 - dfs.namenode.safemode.extension = 30000
2019-03-27 08:54:14,564 INFO  blockmanagement.BlockManager BlockManager.java:<init>:565 - defaultReplication         = 3
2019-03-27 08:54:14,564 INFO  blockmanagement.BlockManager BlockManager.java:<init>:566 - maxReplication             = 512
2019-03-27 08:54:14,565 INFO  blockmanagement.BlockManager BlockManager.java:<init>:567 - minReplication             = 1
2019-03-27 08:54:14,565 INFO  blockmanagement.BlockManager BlockManager.java:<init>:568 - maxReplicationStreams      = 2
2019-03-27 08:54:14,565 INFO  blockmanagement.BlockManager BlockManager.java:<init>:569 - redundancyRecheckInterval  = 3000ms
2019-03-27 08:54:14,565 INFO  blockmanagement.BlockManager BlockManager.java:<init>:570 - encryptDataTransfer        = false
2019-03-27 08:54:14,565 INFO  blockmanagement.BlockManager BlockManager.java:<init>:571 - maxNumBlocksToLog          = 1000
2019-03-27 08:54:14,649 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map INodeMap
2019-03-27 08:54:14,650 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 08:54:14,650 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 1.0% max memory 26.7 GB = 273.0 MB
2019-03-27 08:54:14,650 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^25 = 33554432 entries
2019-03-27 08:54:14,723 INFO  namenode.FSDirectory FSDirectory.java:<init>:283 - ACLs enabled? false
2019-03-27 08:54:14,723 INFO  namenode.FSDirectory FSDirectory.java:<init>:287 - POSIX ACL inheritance enabled? true
2019-03-27 08:54:14,724 INFO  namenode.FSDirectory FSDirectory.java:<init>:291 - XAttrs enabled? true
2019-03-27 08:54:14,724 INFO  namenode.NameNode FSDirectory.java:<init>:355 - Caching file names occurring more than 10 times
2019-03-27 08:54:14,731 INFO  snapshot.SnapshotManager SnapshotManager.java:<init>:124 - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-03-27 08:54:14,734 INFO  snapshot.SnapshotManager DirectoryDiffListFactory.java:init:43 - SkipList is disabled
2019-03-27 08:54:14,739 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map cachedBlocks
2019-03-27 08:54:14,739 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 08:54:14,740 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.25% max memory 26.7 GB = 68.3 MB
2019-03-27 08:54:14,740 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^23 = 8388608 entries
2019-03-27 08:54:14,768 INFO  metrics.TopMetrics TopMetrics.java:logConf:76 - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-03-27 08:54:14,768 INFO  metrics.TopMetrics TopMetrics.java:logConf:78 - NNTop conf: dfs.namenode.top.num.users = 10
2019-03-27 08:54:14,768 INFO  metrics.TopMetrics TopMetrics.java:logConf:80 - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-03-27 08:54:14,772 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:979 - Retry cache on namenode is enabled
2019-03-27 08:54:14,772 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:987 - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-03-27 08:54:14,775 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map NameNodeRetryCache
2019-03-27 08:54:14,775 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 08:54:14,775 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-03-27 08:54:14,775 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^20 = 1048576 entries
2019-03-27 08:54:14,812 INFO  common.Storage Storage.java:tryLock:905 - Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 40004@clnode043.clemson.cloudlab.us
2019-03-27 08:54:16,359 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:205 - Detected pause in JVM or host machine (eg GC): pause of approximately 1287ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=358ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1063ms
2019-03-27 08:54:17,482 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:54:17,482 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:54:17,482 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:54:18,483 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:54:18,483 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:54:18,483 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:54:19,483 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:54:19,483 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:54:19,484 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:54:20,484 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:54:20,484 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:54:20,484 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-2-link-0/10.10.1.5:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:54:20,915 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2019-03-27 08:54:21,485 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-4-link-0/10.10.1.2:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:54:21,485 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-3-link-0/10.10.1.3:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-27 08:54:21,853 INFO  namenode.FSImage FSImage.java:loadFSImage:718 - No edit log streams selected.
2019-03-27 08:54:21,853 INFO  namenode.FSImage FSImage.java:loadFSImageFile:782 - Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-03-27 08:54:21,916 INFO  namenode.ErasureCodingPolicyManager ErasureCodingPolicyManager.java:enablePolicy:390 - Enable the erasure coding policy RS-6-3-1024k
2019-03-27 08:54:21,918 INFO  namenode.FSImageFormatPBINode FSImageFormatPBINode.java:loadINodeSection:266 - Loading 1 INodes.
2019-03-27 08:54:21,949 INFO  namenode.FSImageFormatProtobuf FSImageFormatProtobuf.java:load:190 - Loaded FSImage in 0 seconds.
2019-03-27 08:54:21,949 INFO  namenode.FSImage FSImage.java:loadFSImage:951 - Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-03-27 08:54:21,955 INFO  namenode.FSNamesystem FSNamesystem.java:loadFSImage:1091 - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-03-27 08:54:21,955 INFO  namenode.NameCache NameCache.java:initialized:143 - initialized with 0 entries 0 lookups
2019-03-27 08:54:21,955 INFO  namenode.FSNamesystem FSNamesystem.java:loadFromDisk:721 - Finished loading FSImage in 7171 msecs
2019-03-27 08:54:22,134 INFO  namenode.NameNode NameNodeRpcServer.java:<init>:446 - RPC server is binding to node-1-link-0:8020
2019-03-27 08:54:22,139 INFO  ipc.CallQueueManager CallQueueManager.java:<init>:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-03-27 08:54:22,151 INFO  ipc.Server Server.java:run:1070 - Starting Socket Reader #1 for port 8020
2019-03-27 08:54:22,341 INFO  namenode.FSNamesystem FSNamesystem.java:registerMBean:4973 - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-03-27 08:54:22,350 INFO  namenode.LeaseManager LeaseManager.java:getNumUnderConstructionBlocks:171 - Number of blocks under construction: 0
2019-03-27 08:54:22,361 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:396 - STATE* Leaving safe mode after 0 secs
2019-03-27 08:54:22,361 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:402 - STATE* Network topology has 0 racks and 0 datanodes
2019-03-27 08:54:22,361 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:404 - STATE* UnderReplicatedBlocks has 0 blocks
2019-03-27 08:54:22,394 INFO  ipc.Server Server.java:run:1310 - IPC Server Responder: starting
2019-03-27 08:54:22,395 INFO  ipc.Server Server.java:run:1149 - IPC Server listener on 8020: starting
2019-03-27 08:54:22,398 INFO  namenode.NameNode NameNode.java:startCommonServices:812 - NameNode RPC up at: node-1-link-0/10.10.1.4:8020
2019-03-27 08:54:22,401 INFO  namenode.FSNamesystem FSNamesystem.java:startStandbyServices:1365 - Starting services required for standby state
2019-03-27 08:54:22,405 INFO  ha.EditLogTailer EditLogTailer.java:<init>:188 - Will roll logs on active node every 120 seconds.
2019-03-27 08:54:22,411 INFO  ha.StandbyCheckpointer StandbyCheckpointer.java:start:139 - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-0-link-0:9870]
Serving checkpoints at http://node-1-link-0:9870
2019-03-27 08:54:22,931 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=6e69d58b-f6d6-408d-bbfa-c678889f5467, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-00d2bbc7-ad11-46b1-bf42-22535ada86e2;nsid=1637633049;c=1553698433502) storage 6e69d58b-f6d6-408d-bbfa-c678889f5467
2019-03-27 08:54:22,933 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.3:9866
2019-03-27 08:54:22,934 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 6e69d58b-f6d6-408d-bbfa-c678889f5467 (10.10.1.3:9866).
2019-03-27 08:54:22,937 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.6:9866, datanodeUuid=d06206ae-c96d-4ca6-8711-ba00daed279b, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-00d2bbc7-ad11-46b1-bf42-22535ada86e2;nsid=1637633049;c=1553698433502) storage d06206ae-c96d-4ca6-8711-ba00daed279b
2019-03-27 08:54:22,937 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.6:9866
2019-03-27 08:54:22,937 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN d06206ae-c96d-4ca6-8711-ba00daed279b (10.10.1.6:9866).
2019-03-27 08:54:23,009 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=36eb9c4c-124a-4aaf-abf1-4b02b4d256cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-00d2bbc7-ad11-46b1-bf42-22535ada86e2;nsid=1637633049;c=1553698433502) storage 36eb9c4c-124a-4aaf-abf1-4b02b4d256cb
2019-03-27 08:54:23,010 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.2:9866
2019-03-27 08:54:23,010 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 36eb9c4c-124a-4aaf-abf1-4b02b4d256cb (10.10.1.2:9866).
2019-03-27 08:54:23,027 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-f267b79f-d66e-4e74-a11c-9ad21a64e5e3 for DN 10.10.1.6:9866
2019-03-27 08:54:23,030 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-2af6710e-c2dc-4164-9cf9-8919442919d8 for DN 10.10.1.3:9866
2019-03-27 08:54:23,060 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-aa725396-6ab5-49f5-ac22-cf2ca765891e for DN 10.10.1.2:9866
2019-03-27 08:54:23,079 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0x2d89a2fff59814ae: Processing first storage report for DS-2af6710e-c2dc-4164-9cf9-8919442919d8 from datanode 6e69d58b-f6d6-408d-bbfa-c678889f5467
2019-03-27 08:54:23,081 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0x2d89a2fff59814ae: from storage DS-2af6710e-c2dc-4164-9cf9-8919442919d8 node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=6e69d58b-f6d6-408d-bbfa-c678889f5467, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-00d2bbc7-ad11-46b1-bf42-22535ada86e2;nsid=1637633049;c=1553698433502), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2019-03-27 08:54:23,081 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0x3cf7b5b2504141cd: Processing first storage report for DS-f267b79f-d66e-4e74-a11c-9ad21a64e5e3 from datanode d06206ae-c96d-4ca6-8711-ba00daed279b
2019-03-27 08:54:23,081 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0x3cf7b5b2504141cd: from storage DS-f267b79f-d66e-4e74-a11c-9ad21a64e5e3 node DatanodeRegistration(10.10.1.6:9866, datanodeUuid=d06206ae-c96d-4ca6-8711-ba00daed279b, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-00d2bbc7-ad11-46b1-bf42-22535ada86e2;nsid=1637633049;c=1553698433502), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-03-27 08:54:23,085 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0xe830df9dc6cd7702: Processing first storage report for DS-aa725396-6ab5-49f5-ac22-cf2ca765891e from datanode 36eb9c4c-124a-4aaf-abf1-4b02b4d256cb
2019-03-27 08:54:23,085 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0xe830df9dc6cd7702: from storage DS-aa725396-6ab5-49f5-ac22-cf2ca765891e node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=36eb9c4c-124a-4aaf-abf1-4b02b4d256cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-00d2bbc7-ad11-46b1-bf42-22535ada86e2;nsid=1637633049;c=1553698433502), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-03-27 08:54:23,367 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=1978fbe6-d702-4915-b411-89d23e2a28ce, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-00d2bbc7-ad11-46b1-bf42-22535ada86e2;nsid=1637633049;c=1553698433502) storage 1978fbe6-d702-4915-b411-89d23e2a28ce
2019-03-27 08:54:23,367 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.5:9866
2019-03-27 08:54:23,368 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 1978fbe6-d702-4915-b411-89d23e2a28ce (10.10.1.5:9866).
2019-03-27 08:54:23,409 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-59cf5bf6-1b40-4dc8-a503-21bae09e29ab for DN 10.10.1.5:9866
2019-03-27 08:54:23,431 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0x71932b9a350ba1cb: Processing first storage report for DS-59cf5bf6-1b40-4dc8-a503-21bae09e29ab from datanode 1978fbe6-d702-4915-b411-89d23e2a28ce
2019-03-27 08:54:23,431 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0x71932b9a350ba1cb: from storage DS-59cf5bf6-1b40-4dc8-a503-21bae09e29ab node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=1978fbe6-d702-4915-b411-89d23e2a28ce, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-00d2bbc7-ad11-46b1-bf42-22535ada86e2;nsid=1637633049;c=1553698433502), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-03-27 08:54:23,730 INFO  namenode.FSNamesystem FSNamesystem.java:stopStandbyServices:1408 - Stopping services started for standby state
2019-03-27 08:54:23,732 WARN  ha.EditLogTailer EditLogTailer.java:doWork:481 - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:479)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
2019-03-27 08:54:23,835 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1203 - Starting services required for active state
2019-03-27 08:54:23,844 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:435 - Starting recovery process for unclosed journal segments...
2019-03-27 08:54:23,940 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:437 - Successfully started new epoch 1
2019-03-27 08:54:23,941 INFO  namenode.FileJournalManager FileJournalManager.java:recoverUnfinalizedSegments:396 - Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-03-27 08:54:23,941 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1214 - Catching up to latest edits from old active before taking over writer role in edits logs
2019-03-27 08:54:23,945 INFO  blockmanagement.DatanodeManager DatanodeManager.java:markAllDatanodesStale:1837 - Marking all datanodes as stale
2019-03-27 08:54:23,947 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1225 - Reprocessing replication and invalidation queues
2019-03-27 08:54:23,947 INFO  blockmanagement.BlockManager BlockManager.java:initializeReplQueues:4752 - initializing replication queues
2019-03-27 08:54:23,948 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1236 - Will take over writing edit logs at txnid 1
2019-03-27 08:54:23,950 INFO  namenode.FSEditLog FSEditLog.java:startLogSegment:1361 - Starting log segment at 1
2019-03-27 08:54:24,440 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:767 - Initializing quota with 4 thread(s)
2019-03-27 08:54:24,446 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:776 - Quota initialization completed in 4 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-03-27 08:54:24,451 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3447 - Total number of blocks            = 0
2019-03-27 08:54:24,451 INFO  blockmanagement.CacheReplicationMonitor CacheReplicationMonitor.java:run:160 - Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-03-27 08:54:24,451 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3448 - Number of invalid blocks          = 0
2019-03-27 08:54:24,451 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3449 - Number of under-replicated blocks = 0
2019-03-27 08:54:24,451 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3450 - Number of  over-replicated blocks = 0
2019-03-27 08:54:24,451 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3452 - Number of blocks being written    = 0
2019-03-27 08:54:24,451 INFO  hdfs.StateChange BlockManager.java:processMisReplicatesAsync:3455 - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 503 msec
2019-03-27 08:54:30,081 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741825_1001, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-03-27 08:54:30,084 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741826_1002, replicas=10.10.1.2:9866, 10.10.1.6:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-03-27 08:54:30,085 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741827_1003, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-03-27 08:54:30,086 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741828_1004, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-03-27 08:54:30,086 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741829_1005, replicas=10.10.1.3:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-03-27 08:54:31,049 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741830_1006, replicas=10.10.1.6:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-03-27 08:54:31,052 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741831_1007, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-03-27 08:54:31,052 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741832_1008, replicas=10.10.1.3:9866, 10.10.1.6:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-03-27 08:54:31,066 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741833_1009, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.6:9866 for /myfile4._COPYING_
2019-03-27 08:54:31,109 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741834_1010, replicas=10.10.1.2:9866, 10.10.1.6:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-03-27 08:54:32,574 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1525ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.5:8485
2019-03-27 08:54:33,695 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2645ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.2:8485
2019-03-27 08:54:33,746 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2697ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.3:8485
2019-03-27 08:54:34,204 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741835_1011, replicas=10.10.1.6:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-03-27 08:54:34,310 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741836_1012, replicas=10.10.1.6:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-03-27 08:54:34,341 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741837_1013, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.6:9866 for /myfile3._COPYING_
2019-03-27 08:54:34,397 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741838_1014, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-03-27 08:54:34,399 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741839_1015, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-03-27 08:54:34,816 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741840_1016, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.6:9866 for /myfile4._COPYING_
2019-03-27 08:54:34,903 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741841_1017, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-03-27 08:54:34,918 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741842_1018, replicas=10.10.1.2:9866, 10.10.1.6:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-03-27 08:54:34,986 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741843_1019, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-03-27 08:54:34,990 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741844_1020, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-03-27 08:54:35,492 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741845_1021, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-03-27 08:54:35,521 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741846_1022, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-03-27 08:54:35,583 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741847_1023, replicas=10.10.1.3:9866, 10.10.1.6:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-03-27 08:54:35,908 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741848_1024, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-03-27 08:54:36,320 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741849_1025, replicas=10.10.1.6:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-03-27 08:54:37,296 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741850_1026, replicas=10.10.1.6:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile3._COPYING_
2019-03-27 08:54:37,298 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741851_1027, replicas=10.10.1.6:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-03-27 08:54:37,703 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741852_1028, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-03-27 08:54:37,756 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741853_1029, replicas=10.10.1.6:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-03-27 08:54:37,779 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741854_1030, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.6:9866 for /myfile5._COPYING_
2019-03-27 08:54:39,315 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2994ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.5:8485
2019-03-27 08:54:42,772 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 5475ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.2:8485
2019-03-27 08:54:42,862 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 5565ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.3:8485
2019-03-27 08:54:44,292 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741855_1031, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.6:9866 for /myfile5._COPYING_
2019-03-27 08:54:44,293 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741856_1032, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-03-27 08:54:44,302 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741857_1033, replicas=10.10.1.3:9866, 10.10.1.6:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-03-27 08:54:44,313 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1522ms to send a batch of 13 edits (570 bytes) to remote journal 10.10.1.2:8485
2019-03-27 08:54:44,625 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741858_1034, replicas=10.10.1.6:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-03-27 08:54:44,632 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile1._COPYING_ is closed by DFSClient_NONMAPREDUCE_1399546767_1
2019-03-27 08:54:44,812 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741859_1035, replicas=10.10.1.2:9866, 10.10.1.6:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-03-27 08:54:44,863 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741860_1036, replicas=10.10.1.6:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-03-27 08:54:44,888 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741861_1037, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile3._COPYING_
2019-03-27 08:54:45,145 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741862_1038, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.6:9866 for /myfile2._COPYING_
2019-03-27 08:54:45,297 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741863_1039, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-03-27 08:54:45,357 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile5._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1809197693_1
2019-03-27 08:54:45,364 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741864_1040, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.6:9866 for /myfile3._COPYING_
2019-03-27 08:54:45,716 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile4._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1415559891_1
2019-03-27 08:54:48,978 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile2._COPYING_ is closed by DFSClient_NONMAPREDUCE_-818916755_1
2019-03-27 08:54:48,979 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile3._COPYING_ is closed by DFSClient_NONMAPREDUCE_1906236932_1
2019-03-27 08:56:12,101 INFO  namenode.FSEditLog FSEditLog.java:printStatistics:774 - Number of transactions: 137 Total time for transactions(ms): 23 Number of transactions batched in Syncs: 83 Number of syncs: 53 SyncTimes(ms): 9578 595 
2019-03-27 08:56:16,694 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741865_1041, replicas=10.10.1.6:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-03-27 08:56:17,197 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741866_1042, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-03-27 08:56:17,614 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741867_1043, replicas=10.10.1.3:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-03-27 08:56:18,053 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741868_1044, replicas=10.10.1.6:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-03-27 08:56:18,118 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741869_1045, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.6:9866 for /myfile1._COPYING_
2019-03-27 08:56:18,450 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741870_1046, replicas=10.10.1.3:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-03-27 08:56:18,700 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741871_1047, replicas=10.10.1.6:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-03-27 08:56:18,910 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741872_1048, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.6:9866 for /myfile4._COPYING_
2019-03-27 08:56:19,114 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741873_1049, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.6:9866 for /myfile1._COPYING_
2019-03-27 08:56:19,342 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741874_1050, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-03-27 08:56:19,526 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741875_1051, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-03-27 08:56:19,762 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741876_1052, replicas=10.10.1.6:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-03-27 08:56:19,975 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741877_1053, replicas=10.10.1.6:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-03-27 08:56:20,154 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile4._COPYING_ is closed by DFSClient_NONMAPREDUCE_-65785359_1
2019-03-27 08:56:20,373 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741878_1054, replicas=10.10.1.6:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-03-27 08:56:20,718 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741879_1055, replicas=10.10.1.6:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-03-27 08:56:20,766 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741880_1056, replicas=10.10.1.2:9866, 10.10.1.6:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-03-27 08:56:21,184 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741881_1057, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-03-27 08:56:21,302 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741882_1058, replicas=10.10.1.6:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile3._COPYING_
2019-03-27 08:56:22,486 INFO  namenode.FSNamesystem FSNamesystem.java:rollEditLog:4646 - Roll Edit Log from 10.10.1.1
2019-03-27 08:56:22,486 INFO  namenode.FSEditLog FSEditLog.java:rollEditLog:1314 - Rolling edit logs
2019-03-27 08:56:22,487 INFO  namenode.FSEditLog FSEditLog.java:endCurrentLogSegment:1406 - Ending log segment 1, 198
2019-03-27 08:56:23,512 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2209ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.2:8485
2019-03-27 08:56:23,541 INFO  namenode.FSEditLog FSEditLog.java:printStatistics:774 - Number of transactions: 199 Total time for transactions(ms): 26 Number of transactions batched in Syncs: 102 Number of syncs: 97 SyncTimes(ms): 10946 838 
2019-03-27 08:56:23,572 INFO  namenode.FileJournalManager FileJournalManager.java:finalizeLogSegment:143 - Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000001 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000001-0000000000000000199
2019-03-27 08:56:23,589 INFO  namenode.FSEditLog FSEditLog.java:startLogSegment:1361 - Starting log segment at 200
2019-03-27 08:56:23,772 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile1._COPYING_ is closed by DFSClient_NONMAPREDUCE_-212510399_1
2019-03-27 08:56:24,965 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741883_1059, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-03-27 08:56:25,036 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2548ms to send a batch of 1 edits (17 bytes) to remote journal 10.10.1.3:8485
2019-03-27 08:56:25,421 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741884_1060, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.6:9866 for /myfile3._COPYING_
2019-03-27 08:56:25,823 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741885_1061, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-03-27 08:56:26,244 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741886_1062, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile3._COPYING_
2019-03-27 08:56:26,670 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741887_1063, replicas=10.10.1.6:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile3._COPYING_
2019-03-27 08:56:28,267 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2023ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.5:8485
2019-03-27 08:56:32,217 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3901ms to send a batch of 2 edits (246 bytes) to remote journal 10.10.1.3:8485
2019-03-27 08:56:32,283 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741888_1064, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-03-27 08:56:32,586 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 5915ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.2:8485
2019-03-27 08:56:34,837 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2251ms to send a batch of 2 edits (246 bytes) to remote journal 10.10.1.2:8485
2019-03-27 08:56:36,260 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 4021ms to send a batch of 1 edits (172 bytes) to remote journal 10.10.1.5:8485
2019-03-27 08:56:38,241 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6002 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [10.10.1.5:8485]
2019-03-27 08:56:38,329 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 6089ms to send a batch of 1 edits (172 bytes) to remote journal 10.10.1.3:8485
2019-03-27 08:56:38,393 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741889_1065, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-03-27 08:56:38,397 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741890_1066, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.6:9866 for /myfile2._COPYING_
2019-03-27 08:56:39,362 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1009ms to send a batch of 3 edits (106 bytes) to remote journal 10.10.1.3:8485
2019-03-27 08:56:41,113 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 6275ms to send a batch of 1 edits (172 bytes) to remote journal 10.10.1.2:8485
2019-03-27 08:56:41,778 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3425ms to send a batch of 3 edits (106 bytes) to remote journal 10.10.1.5:8485
2019-03-27 08:56:43,332 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1531ms to send a batch of 6 edits (230 bytes) to remote journal 10.10.1.5:8485
2019-03-27 08:56:45,452 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3650ms to send a batch of 6 edits (230 bytes) to remote journal 10.10.1.3:8485
2019-03-27 08:56:47,435 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 6321ms to send a batch of 3 edits (106 bytes) to remote journal 10.10.1.2:8485
2019-03-27 08:56:49,403 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741891_1067, replicas=10.10.1.6:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-03-27 08:56:49,412 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741892_1068, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile2._COPYING_
2019-03-27 08:56:49,428 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile3._COPYING_ is closed by DFSClient_NONMAPREDUCE_1876218397_1
2019-03-27 08:56:50,817 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1413ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.3:8485
2019-03-27 08:56:51,835 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2432ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.2:8485
2019-03-27 08:56:52,795 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3392ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.5:8485
2019-03-27 08:56:52,932 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1077ms to send a batch of 5 edits (483 bytes) to remote journal 10.10.1.2:8485
2019-03-27 08:56:53,391 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741893_1069, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.6:9866 for /myfile2._COPYING_
2019-03-27 08:56:53,409 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741894_1070, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-03-27 08:56:53,829 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741895_1071, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-03-27 08:56:53,834 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741896_1072, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.6:9866 for /myfile2._COPYING_
2019-03-27 08:56:54,418 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1622ms to send a batch of 5 edits (483 bytes) to remote journal 10.10.1.5:8485
2019-03-27 08:56:56,397 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741897_1073, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-03-27 08:56:56,398 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741898_1074, replicas=10.10.1.6:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-03-27 08:56:56,843 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741899_1075, replicas=10.10.1.6:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-03-27 08:56:56,847 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741900_1076, replicas=10.10.1.6:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-03-27 08:56:57,287 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741901_1077, replicas=10.10.1.3:9866, 10.10.1.6:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-03-27 08:56:57,323 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741902_1078, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.6:9866 for /myfile5._COPYING_
2019-03-27 08:56:57,734 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741903_1079, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-03-27 08:56:57,742 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741904_1080, replicas=10.10.1.6:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-03-27 08:56:58,178 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile5._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1782018518_1
2019-03-27 08:56:58,200 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile2._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1735059966_1
2019-03-27 08:56:59,500 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1321ms to send a batch of 1 edits (285 bytes) to remote journal 10.10.1.5:8485
2019-03-27 08:57:03,935 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 6200ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.2:8485
2019-03-27 08:57:04,968 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 5451ms to send a batch of 1 edits (285 bytes) to remote journal 10.10.1.3:8485
2019-03-27 08:57:46,547 INFO  namenode.FSEditLog FSEditLog.java:printStatistics:774 - Number of transactions: 80 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 40 Number of syncs: 39 SyncTimes(ms): 29340 495 
2019-03-27 08:57:48,830 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2282ms to send a batch of 1 edits (57 bytes) to remote journal 10.10.1.5:8485
2019-03-27 08:57:52,246 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741905_1081, replicas=10.10.1.3:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-03-27 08:57:52,804 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741906_1082, replicas=10.10.1.6:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-03-27 08:57:53,285 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741907_1083, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-03-27 08:57:53,676 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741908_1084, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.6:9866 for /myfile4._COPYING_
2019-03-27 08:57:54,094 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741909_1085, replicas=10.10.1.2:9866, 10.10.1.6:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-03-27 08:57:54,360 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741910_1086, replicas=10.10.1.6:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-03-27 08:57:54,531 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741911_1087, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-03-27 08:57:54,957 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741912_1088, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-03-27 08:57:54,958 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741913_1089, replicas=10.10.1.2:9866, 10.10.1.6:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-03-27 08:57:55,361 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741914_1090, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-03-27 08:57:55,409 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741915_1091, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-03-27 08:57:55,797 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile4._COPYING_ is closed by DFSClient_NONMAPREDUCE_738759576_1
2019-03-27 08:57:55,812 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741916_1092, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.6:9866 for /myfile1._COPYING_
2019-03-27 08:57:56,209 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741917_1093, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-03-27 08:57:56,632 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741918_1094, replicas=10.10.1.6:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-03-27 08:57:57,004 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741919_1095, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.6:9866 for /myfile1._COPYING_
2019-03-27 08:57:57,416 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741920_1096, replicas=10.10.1.6:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-03-27 08:57:57,863 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile1._COPYING_ is closed by DFSClient_NONMAPREDUCE_-453744678_1
2019-03-27 08:58:20,469 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1614ms to send a batch of 1 edits (172 bytes) to remote journal 10.10.1.5:8485
2019-03-27 08:58:20,535 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741921_1097, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile3._COPYING_
2019-03-27 08:58:21,755 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2899ms to send a batch of 1 edits (172 bytes) to remote journal 10.10.1.2:8485
2019-03-27 08:58:24,005 INFO  namenode.FSNamesystem FSNamesystem.java:rollEditLog:4646 - Roll Edit Log from 10.10.1.1
2019-03-27 08:58:24,006 INFO  namenode.FSEditLog FSEditLog.java:rollEditLog:1314 - Rolling edit logs
2019-03-27 08:58:24,006 INFO  namenode.FSEditLog FSEditLog.java:endCurrentLogSegment:1406 - Ending log segment 200, 338
2019-03-27 08:58:26,322 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 5786ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.3:8485
2019-03-27 08:58:27,652 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1310ms to send a batch of 2 edits (73 bytes) to remote journal 10.10.1.3:8485
2019-03-27 08:58:29,953 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3611ms to send a batch of 2 edits (73 bytes) to remote journal 10.10.1.5:8485
2019-03-27 08:58:29,973 INFO  namenode.FSEditLog FSEditLog.java:printStatistics:774 - Number of transactions: 141 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 61 Number of syncs: 80 SyncTimes(ms): 41612 847 
2019-03-27 08:58:32,672 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 10917ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.2:8485
2019-03-27 08:58:32,782 INFO  namenode.FileJournalManager FileJournalManager.java:finalizeLogSegment:143 - Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000200 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000200-0000000000000000340
2019-03-27 08:58:32,782 INFO  namenode.FSEditLog FSEditLog.java:startLogSegment:1361 - Starting log segment at 341
2019-03-27 08:58:39,582 INFO  namenode.FSNamesystem FSNamesystemLock.java:writeUnlock:282 - FSNamesystem write lock held for 15576 ms via
java.lang.Thread.getStackTrace(Thread.java:1559)
org.apache.hadoop.util.StringUtils.getStackTrace(StringUtils.java:1032)
org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.writeUnlock(FSNamesystemLock.java:284)
org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.writeUnlock(FSNamesystemLock.java:234)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.writeUnlock(FSNamesystem.java:1606)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4650)
org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1292)
org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:146)
org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12974)
org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
java.security.AccessController.doPrivileged(Native Method)
javax.security.auth.Subject.doAs(Subject.java:422)
org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
	Number of suppressed write-lock reports: 0
	Longest write-lock held interval: 15576
2019-03-27 08:58:39,592 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741922_1098, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.6:9866 for /myfile3._COPYING_
2019-03-27 08:58:40,528 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741923_1099, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-03-27 08:58:41,785 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 4178ms to send a batch of 1 edits (17 bytes) to remote journal 10.10.1.5:8485
2019-03-27 08:58:42,181 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741924_1100, replicas=10.10.1.3:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile3._COPYING_
2019-03-27 08:58:42,684 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741925_1101, replicas=10.10.1.6:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile3._COPYING_
2019-03-27 08:58:43,153 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741926_1102, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile3._COPYING_
2019-03-27 08:58:43,546 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741927_1103, replicas=10.10.1.6:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile3._COPYING_
2019-03-27 08:58:43,982 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741928_1104, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile3._COPYING_
2019-03-27 08:58:44,163 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741929_1105, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-03-27 08:58:44,264 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2082ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.5:8485
2019-03-27 08:58:44,395 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile3._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1818928663_1
2019-03-27 08:58:44,713 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741930_1106, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-03-27 08:58:45,129 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741931_1107, replicas=10.10.1.6:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-03-27 08:58:45,543 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741932_1108, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.6:9866 for /myfile2._COPYING_
2019-03-27 08:58:45,930 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741933_1109, replicas=10.10.1.6:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-03-27 08:58:46,349 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741934_1110, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-03-27 08:58:46,773 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741935_1111, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-03-27 08:58:47,170 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741936_1112, replicas=10.10.1.2:9866, 10.10.1.6:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-03-27 08:58:47,571 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile2._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1168165157_1
2019-03-27 08:58:52,288 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741937_1113, replicas=10.10.1.3:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-03-27 08:58:52,829 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741938_1114, replicas=10.10.1.3:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-03-27 08:58:53,270 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741939_1115, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.6:9866 for /myfile5._COPYING_
2019-03-27 08:58:53,693 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741940_1116, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.6:9866 for /myfile5._COPYING_
2019-03-27 08:58:54,091 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741941_1117, replicas=10.10.1.6:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-03-27 08:58:54,483 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741942_1118, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-03-27 08:58:54,895 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741943_1119, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.6:9866 for /myfile5._COPYING_
2019-03-27 08:58:55,310 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741944_1120, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-03-27 08:58:55,735 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile5._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1617522593_1
2019-03-27 08:59:27,988 ERROR namenode.NameNode LogAdapter.java:error:75 - RECEIVED SIGNAL 15: SIGTERM
2019-03-27 08:59:27,990 INFO  namenode.NameNode LogAdapter.java:info:51 - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at clnode043.clemson.cloudlab.us/130.127.133.52
************************************************************/
2019-03-27 08:59:51,833 INFO  namenode.NameNode LogAdapter.java:info:51 - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode043.clemson.cloudlab.us/130.127.133.52
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-03-17T18:59Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-03-27 08:59:51,847 INFO  namenode.NameNode LogAdapter.java:info:51 - registered UNIX signal handlers for [TERM, HUP, INT]
2019-03-27 08:59:51,852 INFO  namenode.NameNode NameNode.java:createNameNode:1583 - createNameNode []
2019-03-27 08:59:52,095 INFO  beanutils.FluentPropertyBeanIntrospector FluentPropertyBeanIntrospector.java:introspect:147 - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2019-03-27 08:59:52,139 INFO  impl.MetricsConfig MetricsConfig.java:loadFirst:121 - loaded properties from hadoop-metrics2.properties
2019-03-27 08:59:52,245 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:startTimer:374 - Scheduled Metric snapshot period at 10 second(s).
2019-03-27 08:59:52,245 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:start:191 - NameNode metrics system started
2019-03-27 08:59:52,296 INFO  namenode.NameNodeUtils NameNodeUtils.java:getClientNamenodeAddress:79 - fs.defaultFS is hdfs://mycluster
2019-03-27 08:59:52,297 INFO  namenode.NameNode NameNode.java:<init>:928 - Clients should use mycluster to access this namenode/service.
2019-03-27 08:59:52,466 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:188 - Starting JVM pause monitor
2019-03-27 08:59:52,493 INFO  hdfs.DFSUtil DFSUtil.java:httpServerTemplateForNNAndJN:1605 - Starting Web-server for hdfs at: http://node-1-link-0:9870
2019-03-27 08:59:52,510 INFO  util.log Log.java:initialized:192 - Logging initialized @1192ms
2019-03-27 08:59:52,618 INFO  server.AuthenticationFilter AuthenticationFilter.java:constructSecretProvider:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-03-27 08:59:52,631 INFO  http.HttpRequestLog HttpRequestLog.java:getRequestLog:81 - Http request log for http.requests.namenode is not defined
2019-03-27 08:59:52,642 INFO  http.HttpServer2 HttpServer2.java:addGlobalFilter:968 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-03-27 08:59:52,645 INFO  http.HttpServer2 HttpServer2.java:addFilter:941 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-03-27 08:59:52,646 INFO  http.HttpServer2 HttpServer2.java:addFilter:951 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-03-27 08:59:52,647 INFO  http.HttpServer2 HttpServer2.java:addFilter:951 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-03-27 08:59:52,673 INFO  http.HttpServer2 NameNodeHttpServer.java:initWebHdfs:100 - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-03-27 08:59:52,674 INFO  http.HttpServer2 HttpServer2.java:addJerseyResourcePackage:787 - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-03-27 08:59:52,683 INFO  http.HttpServer2 HttpServer2.java:bindListener:1185 - Jetty bound to port 9870
2019-03-27 08:59:52,684 INFO  server.Server Server.java:doStart:346 - jetty-9.3.19.v20170502
2019-03-27 08:59:52,720 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@221a3fa4{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-03-27 08:59:52,721 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@2b40ff9c{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-03-27 08:59:52,795 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.w.WebAppContext@6c7a164b{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-03-27 08:59:52,817 INFO  server.AbstractConnector AbstractConnector.java:doStart:278 - Started ServerConnector@1cf56a1c{HTTP/1.1,[http/1.1]}{node-1-link-0:9870}
2019-03-27 08:59:52,817 INFO  server.Server Server.java:doStart:414 - Started @1500ms
2019-03-27 08:59:53,155 WARN  namenode.FSNamesystem FSNamesystem.java:checkConfiguration:680 - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-03-27 08:59:53,205 INFO  namenode.FSEditLog FSEditLog.java:newInstance:227 - Edit logging is async:true
2019-03-27 08:59:53,219 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:749 - KeyProvider: null
2019-03-27 08:59:53,221 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:122 - fsLock is fair: true
2019-03-27 08:59:53,224 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:138 - Detailed lock hold time metrics enabled: false
2019-03-27 08:59:53,230 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:774 - fsOwner             = root (auth:SIMPLE)
2019-03-27 08:59:53,230 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:775 - supergroup          = supergroup
2019-03-27 08:59:53,231 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:776 - isPermissionEnabled = true
2019-03-27 08:59:53,231 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:785 - Determined nameservice ID: mycluster
2019-03-27 08:59:53,231 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:787 - HA Enabled: true
2019-03-27 08:59:53,274 INFO  common.Util Util.java:isDiskStatsEnabled:395 - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-03-27 08:59:53,286 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:301 - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-03-27 08:59:53,287 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:309 - dfs.namenode.datanode.registration.ip-hostname-check=true
2019-03-27 08:59:53,291 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:79 - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-03-27 08:59:53,292 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:85 - The block deletion will start around 2019 Mar 27 08:59:53
2019-03-27 08:59:53,294 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map BlocksMap
2019-03-27 08:59:53,294 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 08:59:53,296 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 2.0% max memory 26.7 GB = 546.1 MB
2019-03-27 08:59:53,296 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^26 = 67108864 entries
2019-03-27 08:59:53,430 INFO  blockmanagement.BlockManager BlockManager.java:createBlockTokenSecretManager:579 - dfs.block.access.token.enable = false
2019-03-27 08:59:53,439 INFO  Configuration.deprecation Configuration.java:logDeprecation:1395 - No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-03-27 08:59:53,439 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:161 - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-03-27 08:59:53,439 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:162 - dfs.namenode.safemode.min.datanodes = 0
2019-03-27 08:59:53,439 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:164 - dfs.namenode.safemode.extension = 30000
2019-03-27 08:59:53,440 INFO  blockmanagement.BlockManager BlockManager.java:<init>:565 - defaultReplication         = 3
2019-03-27 08:59:53,440 INFO  blockmanagement.BlockManager BlockManager.java:<init>:566 - maxReplication             = 512
2019-03-27 08:59:53,440 INFO  blockmanagement.BlockManager BlockManager.java:<init>:567 - minReplication             = 1
2019-03-27 08:59:53,440 INFO  blockmanagement.BlockManager BlockManager.java:<init>:568 - maxReplicationStreams      = 2
2019-03-27 08:59:53,440 INFO  blockmanagement.BlockManager BlockManager.java:<init>:569 - redundancyRecheckInterval  = 3000ms
2019-03-27 08:59:53,440 INFO  blockmanagement.BlockManager BlockManager.java:<init>:570 - encryptDataTransfer        = false
2019-03-27 08:59:53,440 INFO  blockmanagement.BlockManager BlockManager.java:<init>:571 - maxNumBlocksToLog          = 1000
2019-03-27 08:59:53,524 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map INodeMap
2019-03-27 08:59:53,524 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 08:59:53,525 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 1.0% max memory 26.7 GB = 273.0 MB
2019-03-27 08:59:53,525 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^25 = 33554432 entries
2019-03-27 08:59:53,598 INFO  namenode.FSDirectory FSDirectory.java:<init>:283 - ACLs enabled? false
2019-03-27 08:59:53,598 INFO  namenode.FSDirectory FSDirectory.java:<init>:287 - POSIX ACL inheritance enabled? true
2019-03-27 08:59:53,598 INFO  namenode.FSDirectory FSDirectory.java:<init>:291 - XAttrs enabled? true
2019-03-27 08:59:53,599 INFO  namenode.NameNode FSDirectory.java:<init>:355 - Caching file names occurring more than 10 times
2019-03-27 08:59:53,606 INFO  snapshot.SnapshotManager SnapshotManager.java:<init>:124 - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-03-27 08:59:53,608 INFO  snapshot.SnapshotManager DirectoryDiffListFactory.java:init:43 - SkipList is disabled
2019-03-27 08:59:53,614 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map cachedBlocks
2019-03-27 08:59:53,614 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 08:59:53,614 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.25% max memory 26.7 GB = 68.3 MB
2019-03-27 08:59:53,614 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^23 = 8388608 entries
2019-03-27 08:59:53,642 INFO  metrics.TopMetrics TopMetrics.java:logConf:76 - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-03-27 08:59:53,642 INFO  metrics.TopMetrics TopMetrics.java:logConf:78 - NNTop conf: dfs.namenode.top.num.users = 10
2019-03-27 08:59:53,643 INFO  metrics.TopMetrics TopMetrics.java:logConf:80 - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-03-27 08:59:53,647 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:979 - Retry cache on namenode is enabled
2019-03-27 08:59:53,647 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:987 - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-03-27 08:59:53,649 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map NameNodeRetryCache
2019-03-27 08:59:53,649 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 08:59:53,650 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-03-27 08:59:53,650 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^20 = 1048576 entries
2019-03-27 08:59:53,708 INFO  common.Storage Storage.java:tryLock:905 - Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 40467@clnode043.clemson.cloudlab.us
2019-03-27 08:59:55,271 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:205 - Detected pause in JVM or host machine (eg GC): pause of approximately 1301ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=352ms
GC pool 'PS Scavenge' had collection(s): count=1 time=1087ms
2019-03-27 08:59:55,441 INFO  namenode.FSImage FSImage.java:loadFSImageFile:782 - Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-03-27 08:59:55,503 INFO  namenode.ErasureCodingPolicyManager ErasureCodingPolicyManager.java:enablePolicy:390 - Enable the erasure coding policy RS-6-3-1024k
2019-03-27 08:59:55,506 INFO  namenode.FSImageFormatPBINode FSImageFormatPBINode.java:loadINodeSection:266 - Loading 1 INodes.
2019-03-27 08:59:55,537 INFO  namenode.FSImageFormatProtobuf FSImageFormatProtobuf.java:load:190 - Loaded FSImage in 0 seconds.
2019-03-27 08:59:55,537 INFO  namenode.FSImage FSImage.java:loadFSImage:951 - Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-03-27 08:59:55,542 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@68b6f0d6 expecting start txid #1
2019-03-27 08:59:55,542 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-27 08:59:55,546 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true' to transaction ID 1
2019-03-27 08:59:55,546 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true' to transaction ID 1
2019-03-27 08:59:55,648 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true of size 10802 edits # 199 loaded in 0 seconds
2019-03-27 08:59:55,648 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4044fb95 expecting start txid #200
2019-03-27 08:59:55,648 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=200&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=200&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-27 08:59:55,649 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=200&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=200&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true' to transaction ID 1
2019-03-27 08:59:55,649 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=200&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true' to transaction ID 1
2019-03-27 08:59:55,665 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=200&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=200&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true of size 8102 edits # 141 loaded in 0 seconds
2019-03-27 08:59:55,665 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@aa549e5 expecting start txid #341
2019-03-27 08:59:55,665 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=341&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=341&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-27 08:59:55,665 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=341&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=341&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true' to transaction ID 1
2019-03-27 08:59:55,665 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=341&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true' to transaction ID 1
2019-03-27 08:59:55,677 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=341&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=341&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true of size 1048576 edits # 81 loaded in 0 seconds
2019-03-27 08:59:55,677 INFO  namenode.FSNamesystem FSNamesystem.java:loadFSImage:1091 - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-03-27 08:59:55,678 INFO  namenode.NameCache NameCache.java:initialized:143 - initialized with 0 entries 0 lookups
2019-03-27 08:59:55,678 INFO  namenode.FSNamesystem FSNamesystem.java:loadFromDisk:721 - Finished loading FSImage in 2020 msecs
2019-03-27 08:59:55,865 INFO  namenode.NameNode NameNodeRpcServer.java:<init>:446 - RPC server is binding to node-1-link-0:8020
2019-03-27 08:59:55,870 INFO  ipc.CallQueueManager CallQueueManager.java:<init>:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-03-27 08:59:55,883 INFO  ipc.Server Server.java:run:1070 - Starting Socket Reader #1 for port 8020
2019-03-27 08:59:56,069 INFO  namenode.FSNamesystem FSNamesystem.java:registerMBean:4973 - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-03-27 08:59:56,078 INFO  namenode.LeaseManager LeaseManager.java:getNumUnderConstructionBlocks:171 - Number of blocks under construction: 0
2019-03-27 08:59:56,089 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:602 - STATE* Safe mode ON. 
The reported blocks 0 needs additional 31 blocks to reach the threshold 0.9990 of total blocks 32.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-03-27 08:59:56,121 INFO  ipc.Server Server.java:run:1310 - IPC Server Responder: starting
2019-03-27 08:59:56,121 INFO  ipc.Server Server.java:run:1149 - IPC Server listener on 8020: starting
2019-03-27 08:59:56,124 INFO  namenode.NameNode NameNode.java:startCommonServices:812 - NameNode RPC up at: node-1-link-0/10.10.1.4:8020
2019-03-27 08:59:56,126 INFO  namenode.FSNamesystem FSNamesystem.java:startStandbyServices:1365 - Starting services required for standby state
2019-03-27 08:59:56,131 INFO  ha.EditLogTailer EditLogTailer.java:<init>:188 - Will roll logs on active node every 120 seconds.
2019-03-27 08:59:56,137 INFO  ha.StandbyCheckpointer StandbyCheckpointer.java:start:139 - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-0-link-0:9870]
Serving checkpoints at http://node-1-link-0:9870
2019-03-27 08:59:56,814 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=1978fbe6-d702-4915-b411-89d23e2a28ce, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-00d2bbc7-ad11-46b1-bf42-22535ada86e2;nsid=1637633049;c=1553698433502) storage 1978fbe6-d702-4915-b411-89d23e2a28ce
2019-03-27 08:59:56,815 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.5:9866
2019-03-27 08:59:56,816 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 1978fbe6-d702-4915-b411-89d23e2a28ce (10.10.1.5:9866).
2019-03-27 08:59:56,817 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.6:9866, datanodeUuid=d06206ae-c96d-4ca6-8711-ba00daed279b, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-00d2bbc7-ad11-46b1-bf42-22535ada86e2;nsid=1637633049;c=1553698433502) storage d06206ae-c96d-4ca6-8711-ba00daed279b
2019-03-27 08:59:56,817 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.6:9866
2019-03-27 08:59:56,817 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN d06206ae-c96d-4ca6-8711-ba00daed279b (10.10.1.6:9866).
2019-03-27 08:59:56,818 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=6e69d58b-f6d6-408d-bbfa-c678889f5467, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-00d2bbc7-ad11-46b1-bf42-22535ada86e2;nsid=1637633049;c=1553698433502) storage 6e69d58b-f6d6-408d-bbfa-c678889f5467
2019-03-27 08:59:56,818 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.3:9866
2019-03-27 08:59:56,818 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 6e69d58b-f6d6-408d-bbfa-c678889f5467 (10.10.1.3:9866).
2019-03-27 08:59:56,819 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=36eb9c4c-124a-4aaf-abf1-4b02b4d256cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-00d2bbc7-ad11-46b1-bf42-22535ada86e2;nsid=1637633049;c=1553698433502) storage 36eb9c4c-124a-4aaf-abf1-4b02b4d256cb
2019-03-27 08:59:56,819 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.2:9866
2019-03-27 08:59:56,819 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 36eb9c4c-124a-4aaf-abf1-4b02b4d256cb (10.10.1.2:9866).
2019-03-27 08:59:56,827 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-aa725396-6ab5-49f5-ac22-cf2ca765891e for DN 10.10.1.2:9866
2019-03-27 08:59:56,830 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-59cf5bf6-1b40-4dc8-a503-21bae09e29ab for DN 10.10.1.5:9866
2019-03-27 08:59:56,831 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-2af6710e-c2dc-4164-9cf9-8919442919d8 for DN 10.10.1.3:9866
2019-03-27 08:59:56,832 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-f267b79f-d66e-4e74-a11c-9ad21a64e5e3 for DN 10.10.1.6:9866
2019-03-27 08:59:56,843 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0x2d89a2fff59814af: Processing first storage report for DS-2af6710e-c2dc-4164-9cf9-8919442919d8 from datanode 6e69d58b-f6d6-408d-bbfa-c678889f5467
2019-03-27 08:59:56,849 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0x2d89a2fff59814af: from storage DS-2af6710e-c2dc-4164-9cf9-8919442919d8 node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=6e69d58b-f6d6-408d-bbfa-c678889f5467, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-00d2bbc7-ad11-46b1-bf42-22535ada86e2;nsid=1637633049;c=1553698433502), blocks: 28, hasStaleStorage: false, processing time: 6 msecs, invalidatedBlocks: 0
2019-03-27 08:59:56,849 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0x71932b9a350ba1cc: Processing first storage report for DS-59cf5bf6-1b40-4dc8-a503-21bae09e29ab from datanode 1978fbe6-d702-4915-b411-89d23e2a28ce
2019-03-27 08:59:56,850 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0x71932b9a350ba1cc: from storage DS-59cf5bf6-1b40-4dc8-a503-21bae09e29ab node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=1978fbe6-d702-4915-b411-89d23e2a28ce, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-00d2bbc7-ad11-46b1-bf42-22535ada86e2;nsid=1637633049;c=1553698433502), blocks: 24, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-03-27 08:59:56,850 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0xe830df9dc6cd7703: Processing first storage report for DS-aa725396-6ab5-49f5-ac22-cf2ca765891e from datanode 36eb9c4c-124a-4aaf-abf1-4b02b4d256cb
2019-03-27 08:59:56,851 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0xe830df9dc6cd7703: from storage DS-aa725396-6ab5-49f5-ac22-cf2ca765891e node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=36eb9c4c-124a-4aaf-abf1-4b02b4d256cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-00d2bbc7-ad11-46b1-bf42-22535ada86e2;nsid=1637633049;c=1553698433502), blocks: 36, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-03-27 08:59:56,851 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0x3cf7b5b2504141ce: Processing first storage report for DS-f267b79f-d66e-4e74-a11c-9ad21a64e5e3 from datanode d06206ae-c96d-4ca6-8711-ba00daed279b
2019-03-27 08:59:56,852 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0x3cf7b5b2504141ce: from storage DS-f267b79f-d66e-4e74-a11c-9ad21a64e5e3 node DatanodeRegistration(10.10.1.6:9866, datanodeUuid=d06206ae-c96d-4ca6-8711-ba00daed279b, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-00d2bbc7-ad11-46b1-bf42-22535ada86e2;nsid=1637633049;c=1553698433502), blocks: 29, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-03-27 09:00:15,763 INFO  namenode.FSNamesystem FSNamesystem.java:stopStandbyServices:1408 - Stopping services started for standby state
2019-03-27 09:00:15,764 WARN  ha.EditLogTailer EditLogTailer.java:doWork:481 - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:479)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
2019-03-27 09:00:15,767 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1203 - Starting services required for active state
2019-03-27 09:00:15,776 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:435 - Starting recovery process for unclosed journal segments...
2019-03-27 09:00:15,830 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:437 - Successfully started new epoch 3
2019-03-27 09:00:15,830 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:277 - Beginning recovery of unclosed segment starting at txid 422
2019-03-27 09:00:15,851 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:286 - Recovery prepare phase complete. Responses:
10.10.1.3:8485: segmentState { startTxId: 422 endTxId: 477 isInProgress: true } lastWriterEpoch: 2 lastCommittedTxId: 476
10.10.1.2:8485: segmentState { startTxId: 422 endTxId: 477 isInProgress: true } lastWriterEpoch: 2 lastCommittedTxId: 476
2019-03-27 09:00:15,853 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:310 - Using longest log: 10.10.1.3:8485=segmentState {
  startTxId: 422
  endTxId: 477
  isInProgress: true
}
lastWriterEpoch: 2
lastCommittedTxId: 476

2019-03-27 09:00:15,893 INFO  namenode.FileJournalManager FileJournalManager.java:recoverUnfinalizedSegments:396 - Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-03-27 09:00:15,921 INFO  namenode.FileJournalManager FileJournalManager.java:finalizeLogSegment:143 - Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000341 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000341-0000000000000000420
2019-03-27 09:00:15,937 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1214 - Catching up to latest edits from old active before taking over writer role in edits logs
2019-03-27 09:00:15,941 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3b1d0e65 expecting start txid #422
2019-03-27 09:00:15,941 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=422&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=422&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-27 09:00:15,941 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=422&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=422&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true' to transaction ID 422
2019-03-27 09:00:15,942 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=422&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true' to transaction ID 422
2019-03-27 09:00:15,958 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=422&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=422&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true of size 1048576 edits # 56 loaded in 0 seconds
2019-03-27 09:00:15,958 INFO  blockmanagement.DatanodeManager DatanodeManager.java:markAllDatanodesStale:1837 - Marking all datanodes as stale
2019-03-27 09:00:15,959 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1236 - Will take over writing edit logs at txnid 478
2019-03-27 09:00:15,962 INFO  namenode.FSEditLog FSEditLog.java:startLogSegment:1361 - Starting log segment at 478
2019-03-27 09:00:16,257 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:767 - Initializing quota with 4 thread(s)
2019-03-27 09:00:16,260 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:776 - Quota initialization completed in 3 milliseconds
name space=6
storage space=16106127360
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-03-27 09:00:16,266 INFO  blockmanagement.CacheReplicationMonitor CacheReplicationMonitor.java:run:160 - Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-03-27 09:00:16,266 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:602 - STATE* Safe mode ON. 
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-03-27 09:00:46,514 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 5 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43754
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:00:46,526 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 1 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43754
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:00:47,056 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 6 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43754
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:00:48,203 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 6 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43766
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:00:48,217 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 2 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43766
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:00:48,293 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 8 on 8020, call Call#3 Retry#3 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43754
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:00:49,595 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 9 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43766
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:00:51,301 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43776
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:00:51,315 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 2 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43776
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:00:51,567 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 8 on 8020, call Call#3 Retry#3 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43766
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:00:52,187 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 4 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43776
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:00:52,218 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#4 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43754
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:00:53,843 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 1 on 8020, call Call#3 Retry#4 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43766
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:00:54,786 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 9 on 8020, call Call#3 Retry#3 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43776
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:00:56,942 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 3 on 8020, call Call#3 Retry#5 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43754
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:00:57,636 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 7 on 8020, call Call#3 Retry#4 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43776
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:00:59,274 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 1 on 8020, call Call#3 Retry#5 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43766
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:01,707 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 2 on 8020, call Call#3 Retry#5 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43776
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:10,213 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 6 on 8020, call Call#3 Retry#6 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43776
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:10,519 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 1 on 8020, call Call#3 Retry#6 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43846
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:15,314 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 2 on 8020, call Call#3 Retry#6 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43864
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:16,750 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 4 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43868
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:16,763 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 3 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43868
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:17,799 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43868
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:20,276 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 2 on 8020, call Call#3 Retry#3 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43868
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:20,401 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 2 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43872
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:20,411 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 8 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43872
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:21,207 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 9 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43872
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:23,090 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 9 on 8020, call Call#3 Retry#3 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43872
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:23,246 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 1 on 8020, call Call#3 Retry#4 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43868
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:27,858 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 4 on 8020, call Call#3 Retry#4 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43872
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:30,178 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 2 on 8020, call Call#3 Retry#7 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43874
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:31,045 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 2 on 8020, call Call#3 Retry#7 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43876
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:32,935 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 9 on 8020, call Call#3 Retry#7 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43878
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:33,265 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 1 on 8020, call Call#3 Retry#5 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43872
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:34,355 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 5 on 8020, call Call#3 Retry#5 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43880
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:38,745 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 4 on 8020, call Call#3 Retry#8 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43874
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:47,284 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 2 on 8020, call Call#3 Retry#8 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43882
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:50,536 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 5 on 8020, call Call#3 Retry#6 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43884
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:51,223 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 3 on 8020, call Call#3 Retry#8 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43886
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:53,867 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 5 on 8020, call Call#3 Retry#6 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43888
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:56,210 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 6 on 8020, call Call#3 Retry#9 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43882
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:57,203 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 4 on 8020, call Call#3 Retry#9 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43890
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:01:59,764 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 9 on 8020, call Call#3 Retry#9 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43886
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:02:07,838 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 3 on 8020, call Call#3 Retry#7 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43892
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:02:11,684 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 2 on 8020, call Call#3 Retry#10 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43894
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:02:12,292 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#10 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43896
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:02:15,915 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 2 on 8020, call Call#3 Retry#7 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43898
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:02:16,899 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 2 on 8020, call Call#3 Retry#10 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43900
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:02:21,459 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 2 on 8020, call Call#9 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 10.10.1.1:34656
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4644)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1292)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:146)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:02:26,996 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 8 on 8020, call Call#3 Retry#11 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43902
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:02:27,752 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 3 on 8020, call Call#3 Retry#11 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43904
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:02:28,394 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#8 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43906
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:02:32,333 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 7 on 8020, call Call#3 Retry#11 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43916
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:02:35,035 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 1 on 8020, call Call#3 Retry#8 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43926
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:02:40,326 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 2 on 8020, call Call#3 Retry#9 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43958
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:02:46,881 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 7 on 8020, call Call#3 Retry#9 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:43990
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:02:50,677 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 5 on 8020, call Call#3 Retry#10 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44002
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:03:02,013 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 4 on 8020, call Call#3 Retry#10 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44060
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:03:10,660 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 5 on 8020, call Call#3 Retry#11 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44106
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:03:17,442 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 3 on 8020, call Call#3 Retry#11 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44146
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:03:21,472 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#13 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 10.10.1.1:34664
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4644)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1292)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:146)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:03:51,811 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 4 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44398
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:03:51,822 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 8 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44398
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:03:52,384 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 6 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44402
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:03:52,395 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 1 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44402
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:03:53,004 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44398
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:03:53,442 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 7 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44408
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:03:53,453 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 4 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44408
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:03:53,841 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 1 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44402
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:03:54,090 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 3 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44408
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:03:55,214 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 7 on 8020, call Call#3 Retry#3 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44402
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:03:55,989 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 3 on 8020, call Call#3 Retry#3 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44398
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:03:56,740 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 8 on 8020, call Call#3 Retry#3 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44408
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:03:58,480 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 4 on 8020, call Call#3 Retry#4 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44402
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:00,214 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 4 on 8020, call Call#3 Retry#4 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44398
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:00,309 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 8 on 8020, call Call#3 Retry#4 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44408
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:07,783 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#5 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44398
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:08,106 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 9 on 8020, call Call#3 Retry#5 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44402
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:11,129 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 8 on 8020, call Call#3 Retry#5 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44464
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:21,481 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#17 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 10.10.1.1:34672
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4644)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1292)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:146)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:21,684 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 4 on 8020, call Call#3 Retry#6 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44508
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:24,676 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 1 on 8020, call Call#3 Retry#6 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44510
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:29,892 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 4 on 8020, call Call#3 Retry#6 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44534
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:34,040 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 7 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44548
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:34,052 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 4 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44548
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:34,372 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 8 on 8020, call Call#3 Retry#7 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44550
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:34,627 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 9 on 8020, call Call#3 Retry#7 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44510
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:35,034 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 7 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44548
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:37,470 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#3 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44548
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:39,601 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 3 on 8020, call Call#3 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44554
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:39,611 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 7 on 8020, call Call#3 Retry#1 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44554
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:40,476 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 4 on 8020, call Call#3 Retry#2 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44554
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:41,866 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 6 on 8020, call Call#3 Retry#3 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44554
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:43,385 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 1 on 8020, call Call#3 Retry#4 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44548
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:47,446 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 4 on 8020, call Call#3 Retry#8 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44556
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:47,723 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#4 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44554
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:49,979 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 2 on 8020, call Call#3 Retry#7 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44558
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:52,635 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#5 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44548
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:53,910 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 3 on 8020, call Call#3 Retry#8 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44560
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:04:55,730 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 3 on 8020, call Call#3 Retry#5 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44554
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:05:04,616 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 9 on 8020, call Call#3 Retry#9 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44562
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:05:06,177 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#9 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44564
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:05:06,961 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#8 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44566
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:05:08,074 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 5 on 8020, call Call#3 Retry#6 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44568
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:05:12,527 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 6 on 8020, call Call#3 Retry#6 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44570
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:05:13,509 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 6 on 8020, call Call#3 Retry#10 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44562
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile3. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:05:21,458 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#9 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44572
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile2. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:05:21,491 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 5 on 8020, call Call#21 Retry#0 org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 10.10.1.1:34680
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4644)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1292)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:146)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12974)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Log not rolled. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:05:26,926 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 6 on 8020, call Call#3 Retry#10 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44574
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile5. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:05:27,832 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 0 on 8020, call Call#3 Retry#7 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44576
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 4 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:05:28,579 ERROR namenode.NameNode LogAdapter.java:error:75 - RECEIVED SIGNAL 15: SIGTERM
2019-03-27 09:05:28,582 INFO  namenode.NameNode LogAdapter.java:info:51 - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at clnode043.clemson.cloudlab.us/130.127.133.52
************************************************************/
2019-03-27 09:05:32,983 INFO  namenode.NameNode LogAdapter.java:info:51 - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = clnode043.clemson.cloudlab.us/130.127.133.52
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-03-17T18:59Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-03-27 09:05:32,995 INFO  namenode.NameNode LogAdapter.java:info:51 - registered UNIX signal handlers for [TERM, HUP, INT]
2019-03-27 09:05:33,000 INFO  namenode.NameNode NameNode.java:createNameNode:1583 - createNameNode []
2019-03-27 09:05:33,246 INFO  beanutils.FluentPropertyBeanIntrospector FluentPropertyBeanIntrospector.java:introspect:147 - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2019-03-27 09:05:33,290 INFO  impl.MetricsConfig MetricsConfig.java:loadFirst:121 - loaded properties from hadoop-metrics2.properties
2019-03-27 09:05:33,395 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:startTimer:374 - Scheduled Metric snapshot period at 10 second(s).
2019-03-27 09:05:33,396 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:start:191 - NameNode metrics system started
2019-03-27 09:05:33,447 INFO  namenode.NameNodeUtils NameNodeUtils.java:getClientNamenodeAddress:79 - fs.defaultFS is hdfs://mycluster
2019-03-27 09:05:33,448 INFO  namenode.NameNode NameNode.java:<init>:928 - Clients should use mycluster to access this namenode/service.
2019-03-27 09:05:33,612 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:188 - Starting JVM pause monitor
2019-03-27 09:05:33,640 INFO  hdfs.DFSUtil DFSUtil.java:httpServerTemplateForNNAndJN:1605 - Starting Web-server for hdfs at: http://node-1-link-0:9870
2019-03-27 09:05:33,657 INFO  util.log Log.java:initialized:192 - Logging initialized @1192ms
2019-03-27 09:05:33,767 INFO  server.AuthenticationFilter AuthenticationFilter.java:constructSecretProvider:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-03-27 09:05:33,780 INFO  http.HttpRequestLog HttpRequestLog.java:getRequestLog:81 - Http request log for http.requests.namenode is not defined
2019-03-27 09:05:33,791 INFO  http.HttpServer2 HttpServer2.java:addGlobalFilter:968 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-03-27 09:05:33,794 INFO  http.HttpServer2 HttpServer2.java:addFilter:941 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-03-27 09:05:33,795 INFO  http.HttpServer2 HttpServer2.java:addFilter:951 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-03-27 09:05:33,795 INFO  http.HttpServer2 HttpServer2.java:addFilter:951 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-03-27 09:05:33,822 INFO  http.HttpServer2 NameNodeHttpServer.java:initWebHdfs:100 - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-03-27 09:05:33,822 INFO  http.HttpServer2 HttpServer2.java:addJerseyResourcePackage:787 - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-03-27 09:05:33,831 INFO  http.HttpServer2 HttpServer2.java:bindListener:1185 - Jetty bound to port 9870
2019-03-27 09:05:33,832 INFO  server.Server Server.java:doStart:346 - jetty-9.3.19.v20170502
2019-03-27 09:05:33,868 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@221a3fa4{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-03-27 09:05:33,869 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@2b40ff9c{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-03-27 09:05:33,944 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.w.WebAppContext@6c7a164b{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
2019-03-27 09:05:33,965 INFO  server.AbstractConnector AbstractConnector.java:doStart:278 - Started ServerConnector@1cf56a1c{HTTP/1.1,[http/1.1]}{node-1-link-0:9870}
2019-03-27 09:05:33,966 INFO  server.Server Server.java:doStart:414 - Started @1502ms
2019-03-27 09:05:34,295 WARN  namenode.FSNamesystem FSNamesystem.java:checkConfiguration:680 - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-03-27 09:05:34,353 INFO  namenode.FSEditLog FSEditLog.java:newInstance:227 - Edit logging is async:true
2019-03-27 09:05:34,368 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:749 - KeyProvider: null
2019-03-27 09:05:34,370 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:122 - fsLock is fair: true
2019-03-27 09:05:34,373 INFO  namenode.FSNamesystem FSNamesystemLock.java:<init>:138 - Detailed lock hold time metrics enabled: false
2019-03-27 09:05:34,379 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:774 - fsOwner             = root (auth:SIMPLE)
2019-03-27 09:05:34,379 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:775 - supergroup          = supergroup
2019-03-27 09:05:34,380 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:776 - isPermissionEnabled = true
2019-03-27 09:05:34,380 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:785 - Determined nameservice ID: mycluster
2019-03-27 09:05:34,380 INFO  namenode.FSNamesystem FSNamesystem.java:<init>:787 - HA Enabled: true
2019-03-27 09:05:34,423 INFO  common.Util Util.java:isDiskStatsEnabled:395 - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-03-27 09:05:34,436 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:301 - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-03-27 09:05:34,436 INFO  blockmanagement.DatanodeManager DatanodeManager.java:<init>:309 - dfs.namenode.datanode.registration.ip-hostname-check=true
2019-03-27 09:05:34,441 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:79 - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-03-27 09:05:34,441 INFO  blockmanagement.BlockManager InvalidateBlocks.java:printBlockDeletionTime:85 - The block deletion will start around 2019 Mar 27 09:05:34
2019-03-27 09:05:34,443 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map BlocksMap
2019-03-27 09:05:34,443 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 09:05:34,445 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 2.0% max memory 26.7 GB = 546.1 MB
2019-03-27 09:05:34,445 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^26 = 67108864 entries
2019-03-27 09:05:34,581 INFO  blockmanagement.BlockManager BlockManager.java:createBlockTokenSecretManager:579 - dfs.block.access.token.enable = false
2019-03-27 09:05:34,590 INFO  Configuration.deprecation Configuration.java:logDeprecation:1395 - No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-03-27 09:05:34,590 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:161 - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-03-27 09:05:34,591 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:162 - dfs.namenode.safemode.min.datanodes = 0
2019-03-27 09:05:34,591 INFO  blockmanagement.BlockManagerSafeMode BlockManagerSafeMode.java:<init>:164 - dfs.namenode.safemode.extension = 30000
2019-03-27 09:05:34,591 INFO  blockmanagement.BlockManager BlockManager.java:<init>:565 - defaultReplication         = 3
2019-03-27 09:05:34,591 INFO  blockmanagement.BlockManager BlockManager.java:<init>:566 - maxReplication             = 512
2019-03-27 09:05:34,591 INFO  blockmanagement.BlockManager BlockManager.java:<init>:567 - minReplication             = 1
2019-03-27 09:05:34,591 INFO  blockmanagement.BlockManager BlockManager.java:<init>:568 - maxReplicationStreams      = 2
2019-03-27 09:05:34,591 INFO  blockmanagement.BlockManager BlockManager.java:<init>:569 - redundancyRecheckInterval  = 3000ms
2019-03-27 09:05:34,591 INFO  blockmanagement.BlockManager BlockManager.java:<init>:570 - encryptDataTransfer        = false
2019-03-27 09:05:34,592 INFO  blockmanagement.BlockManager BlockManager.java:<init>:571 - maxNumBlocksToLog          = 1000
2019-03-27 09:05:34,676 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map INodeMap
2019-03-27 09:05:34,676 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 09:05:34,676 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 1.0% max memory 26.7 GB = 273.0 MB
2019-03-27 09:05:34,676 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^25 = 33554432 entries
2019-03-27 09:05:34,750 INFO  namenode.FSDirectory FSDirectory.java:<init>:283 - ACLs enabled? false
2019-03-27 09:05:34,750 INFO  namenode.FSDirectory FSDirectory.java:<init>:287 - POSIX ACL inheritance enabled? true
2019-03-27 09:05:34,750 INFO  namenode.FSDirectory FSDirectory.java:<init>:291 - XAttrs enabled? true
2019-03-27 09:05:34,750 INFO  namenode.NameNode FSDirectory.java:<init>:355 - Caching file names occurring more than 10 times
2019-03-27 09:05:34,757 INFO  snapshot.SnapshotManager SnapshotManager.java:<init>:124 - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2019-03-27 09:05:34,760 INFO  snapshot.SnapshotManager DirectoryDiffListFactory.java:init:43 - SkipList is disabled
2019-03-27 09:05:34,766 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map cachedBlocks
2019-03-27 09:05:34,766 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 09:05:34,766 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.25% max memory 26.7 GB = 68.3 MB
2019-03-27 09:05:34,766 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^23 = 8388608 entries
2019-03-27 09:05:34,794 INFO  metrics.TopMetrics TopMetrics.java:logConf:76 - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-03-27 09:05:34,794 INFO  metrics.TopMetrics TopMetrics.java:logConf:78 - NNTop conf: dfs.namenode.top.num.users = 10
2019-03-27 09:05:34,794 INFO  metrics.TopMetrics TopMetrics.java:logConf:80 - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-03-27 09:05:34,799 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:979 - Retry cache on namenode is enabled
2019-03-27 09:05:34,799 INFO  namenode.FSNamesystem FSNamesystem.java:initRetryCache:987 - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-03-27 09:05:34,801 INFO  util.GSet LightWeightGSet.java:computeCapacity:395 - Computing capacity for map NameNodeRetryCache
2019-03-27 09:05:34,801 INFO  util.GSet LightWeightGSet.java:computeCapacity:396 - VM type       = 64-bit
2019-03-27 09:05:34,802 INFO  util.GSet LightWeightGSet.java:computeCapacity:397 - 0.029999999329447746% max memory 26.7 GB = 8.2 MB
2019-03-27 09:05:34,802 INFO  util.GSet LightWeightGSet.java:computeCapacity:402 - capacity      = 2^20 = 1048576 entries
2019-03-27 09:05:34,872 INFO  common.Storage Storage.java:tryLock:905 - Lock on /tmp/hadoop-root/dfs/name/in_use.lock acquired by nodename 40810@clnode043.clemson.cloudlab.us
2019-03-27 09:05:36,262 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:205 - Detected pause in JVM or host machine (eg GC): pause of approximately 1145ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=330ms
GC pool 'PS Scavenge' had collection(s): count=1 time=932ms
2019-03-27 09:05:36,424 INFO  namenode.FSImage FSImage.java:loadFSImageFile:782 - Planning to load image: FSImageFile(file=/tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-03-27 09:05:36,487 INFO  namenode.ErasureCodingPolicyManager ErasureCodingPolicyManager.java:enablePolicy:390 - Enable the erasure coding policy RS-6-3-1024k
2019-03-27 09:05:36,489 INFO  namenode.FSImageFormatPBINode FSImageFormatPBINode.java:loadINodeSection:266 - Loading 1 INodes.
2019-03-27 09:05:36,520 INFO  namenode.FSImageFormatProtobuf FSImageFormatProtobuf.java:load:190 - Loaded FSImage in 0 seconds.
2019-03-27 09:05:36,520 INFO  namenode.FSImage FSImage.java:loadFSImage:951 - Loaded image for txid 0 from /tmp/hadoop-root/dfs/name/current/fsimage_0000000000000000000
2019-03-27 09:05:36,526 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@68b6f0d6 expecting start txid #1
2019-03-27 09:05:36,526 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-27 09:05:36,530 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true' to transaction ID 1
2019-03-27 09:05:36,530 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true' to transaction ID 1
2019-03-27 09:05:36,633 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=1&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true of size 10802 edits # 199 loaded in 0 seconds
2019-03-27 09:05:36,634 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4044fb95 expecting start txid #200
2019-03-27 09:05:36,634 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=200&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=200&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=200&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-27 09:05:36,634 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=200&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=200&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=200&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true' to transaction ID 1
2019-03-27 09:05:36,634 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=200&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true' to transaction ID 1
2019-03-27 09:05:36,649 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=200&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=200&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=200&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true of size 8102 edits # 141 loaded in 0 seconds
2019-03-27 09:05:36,649 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@aa549e5 expecting start txid #341
2019-03-27 09:05:36,649 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=341&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=341&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=341&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-27 09:05:36,650 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=341&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=341&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=341&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true' to transaction ID 1
2019-03-27 09:05:36,650 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=341&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true' to transaction ID 1
2019-03-27 09:05:36,662 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=341&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=341&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=341&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true of size 1048576 edits # 81 loaded in 0 seconds
2019-03-27 09:05:36,662 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@36f48b4 expecting start txid #422
2019-03-27 09:05:36,662 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=422&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=422&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=422&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-27 09:05:36,663 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=422&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=422&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=422&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true' to transaction ID 1
2019-03-27 09:05:36,663 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=422&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true' to transaction ID 1
2019-03-27 09:05:36,672 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=422&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=422&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=422&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true of size 1048576 edits # 56 loaded in 0 seconds
2019-03-27 09:05:36,672 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5c00384f expecting start txid #478
2019-03-27 09:05:36,672 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=478&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=478&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=478&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-27 09:05:36,672 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=478&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=478&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=478&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true' to transaction ID 1
2019-03-27 09:05:36,672 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=478&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true' to transaction ID 1
2019-03-27 09:05:36,676 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=478&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=478&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-4-link-0:8480/getJournal?jid=mycluster&segmentTxId=478&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-03-27 09:05:36,676 INFO  namenode.FSNamesystem FSNamesystem.java:loadFSImage:1091 - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2019-03-27 09:05:36,677 INFO  namenode.NameCache NameCache.java:initialized:143 - initialized with 0 entries 0 lookups
2019-03-27 09:05:36,677 INFO  namenode.FSNamesystem FSNamesystem.java:loadFromDisk:721 - Finished loading FSImage in 1867 msecs
2019-03-27 09:05:36,880 INFO  namenode.NameNode NameNodeRpcServer.java:<init>:446 - RPC server is binding to node-1-link-0:8020
2019-03-27 09:05:36,885 INFO  ipc.CallQueueManager CallQueueManager.java:<init>:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-03-27 09:05:36,898 INFO  ipc.Server Server.java:run:1070 - Starting Socket Reader #1 for port 8020
2019-03-27 09:05:37,086 INFO  namenode.FSNamesystem FSNamesystem.java:registerMBean:4973 - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2019-03-27 09:05:37,096 INFO  namenode.LeaseManager LeaseManager.java:getNumUnderConstructionBlocks:171 - Number of blocks under construction: 0
2019-03-27 09:05:37,109 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:602 - STATE* Safe mode ON. 
The reported blocks 0 needs additional 39 blocks to reach the threshold 0.9990 of total blocks 40.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2019-03-27 09:05:37,143 INFO  ipc.Server Server.java:run:1310 - IPC Server Responder: starting
2019-03-27 09:05:37,143 INFO  ipc.Server Server.java:run:1149 - IPC Server listener on 8020: starting
2019-03-27 09:05:37,146 INFO  namenode.NameNode NameNode.java:startCommonServices:812 - NameNode RPC up at: node-1-link-0/10.10.1.4:8020
2019-03-27 09:05:37,150 INFO  namenode.FSNamesystem FSNamesystem.java:startStandbyServices:1365 - Starting services required for standby state
2019-03-27 09:05:37,156 INFO  ha.EditLogTailer EditLogTailer.java:<init>:188 - Will roll logs on active node every 120 seconds.
2019-03-27 09:05:37,162 INFO  ha.StandbyCheckpointer StandbyCheckpointer.java:start:139 - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://node-0-link-0:9870]
Serving checkpoints at http://node-1-link-0:9870
2019-03-27 09:05:37,974 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.2:9866, datanodeUuid=36eb9c4c-124a-4aaf-abf1-4b02b4d256cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-00d2bbc7-ad11-46b1-bf42-22535ada86e2;nsid=1637633049;c=1553698433502) storage 36eb9c4c-124a-4aaf-abf1-4b02b4d256cb
2019-03-27 09:05:37,975 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.2:9866
2019-03-27 09:05:37,976 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 36eb9c4c-124a-4aaf-abf1-4b02b4d256cb (10.10.1.2:9866).
2019-03-27 09:05:37,977 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.3:9866, datanodeUuid=6e69d58b-f6d6-408d-bbfa-c678889f5467, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-00d2bbc7-ad11-46b1-bf42-22535ada86e2;nsid=1637633049;c=1553698433502) storage 6e69d58b-f6d6-408d-bbfa-c678889f5467
2019-03-27 09:05:37,978 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.3:9866
2019-03-27 09:05:37,978 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 6e69d58b-f6d6-408d-bbfa-c678889f5467 (10.10.1.3:9866).
2019-03-27 09:05:37,978 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.6:9866, datanodeUuid=d06206ae-c96d-4ca6-8711-ba00daed279b, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-00d2bbc7-ad11-46b1-bf42-22535ada86e2;nsid=1637633049;c=1553698433502) storage d06206ae-c96d-4ca6-8711-ba00daed279b
2019-03-27 09:05:37,979 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.6:9866
2019-03-27 09:05:37,979 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN d06206ae-c96d-4ca6-8711-ba00daed279b (10.10.1.6:9866).
2019-03-27 09:05:37,979 INFO  hdfs.StateChange DatanodeManager.java:registerDatanode:1040 - BLOCK* registerDatanode: from DatanodeRegistration(10.10.1.5:9866, datanodeUuid=1978fbe6-d702-4915-b411-89d23e2a28ce, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-00d2bbc7-ad11-46b1-bf42-22535ada86e2;nsid=1637633049;c=1553698433502) storage 1978fbe6-d702-4915-b411-89d23e2a28ce
2019-03-27 09:05:37,979 INFO  net.NetworkTopology NetworkTopology.java:add:145 - Adding a new node: /default-rack/10.10.1.5:9866
2019-03-27 09:05:37,980 INFO  blockmanagement.BlockReportLeaseManager BlockReportLeaseManager.java:registerNode:204 - Registered DN 1978fbe6-d702-4915-b411-89d23e2a28ce (10.10.1.5:9866).
2019-03-27 09:05:37,988 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-2af6710e-c2dc-4164-9cf9-8919442919d8 for DN 10.10.1.3:9866
2019-03-27 09:05:37,991 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-aa725396-6ab5-49f5-ac22-cf2ca765891e for DN 10.10.1.2:9866
2019-03-27 09:05:37,992 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-59cf5bf6-1b40-4dc8-a503-21bae09e29ab for DN 10.10.1.5:9866
2019-03-27 09:05:37,992 INFO  blockmanagement.DatanodeDescriptor DatanodeDescriptor.java:updateStorage:987 - Adding new storage ID DS-f267b79f-d66e-4e74-a11c-9ad21a64e5e3 for DN 10.10.1.6:9866
2019-03-27 09:05:38,004 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0xe830df9dc6cd7704: Processing first storage report for DS-aa725396-6ab5-49f5-ac22-cf2ca765891e from datanode 36eb9c4c-124a-4aaf-abf1-4b02b4d256cb
2019-03-27 09:05:38,011 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0xe830df9dc6cd7704: from storage DS-aa725396-6ab5-49f5-ac22-cf2ca765891e node DatanodeRegistration(10.10.1.2:9866, datanodeUuid=36eb9c4c-124a-4aaf-abf1-4b02b4d256cb, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-00d2bbc7-ad11-46b1-bf42-22535ada86e2;nsid=1637633049;c=1553698433502), blocks: 39, hasStaleStorage: false, processing time: 7 msecs, invalidatedBlocks: 0
2019-03-27 09:05:38,011 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0x71932b9a350ba1cd: Processing first storage report for DS-59cf5bf6-1b40-4dc8-a503-21bae09e29ab from datanode 1978fbe6-d702-4915-b411-89d23e2a28ce
2019-03-27 09:05:38,013 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:602 - STATE* Safe mode extension entered. 
The reported blocks 39 has reached the threshold 0.9990 of total blocks 40. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2019-03-27 09:05:38,013 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0x71932b9a350ba1cd: from storage DS-59cf5bf6-1b40-4dc8-a503-21bae09e29ab node DatanodeRegistration(10.10.1.5:9866, datanodeUuid=1978fbe6-d702-4915-b411-89d23e2a28ce, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-00d2bbc7-ad11-46b1-bf42-22535ada86e2;nsid=1637633049;c=1553698433502), blocks: 29, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2019-03-27 09:05:38,013 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0x2d89a2fff59814b0: Processing first storage report for DS-2af6710e-c2dc-4164-9cf9-8919442919d8 from datanode 6e69d58b-f6d6-408d-bbfa-c678889f5467
2019-03-27 09:05:38,014 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0x2d89a2fff59814b0: from storage DS-2af6710e-c2dc-4164-9cf9-8919442919d8 node DatanodeRegistration(10.10.1.3:9866, datanodeUuid=6e69d58b-f6d6-408d-bbfa-c678889f5467, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-00d2bbc7-ad11-46b1-bf42-22535ada86e2;nsid=1637633049;c=1553698433502), blocks: 33, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-03-27 09:05:38,014 INFO  BlockStateChange BlockManager.java:processReport:2526 - BLOCK* processReport 0x3cf7b5b2504141cf: Processing first storage report for DS-f267b79f-d66e-4e74-a11c-9ad21a64e5e3 from datanode d06206ae-c96d-4ca6-8711-ba00daed279b
2019-03-27 09:05:38,015 INFO  BlockStateChange BlockManager.java:processReport:2555 - BLOCK* processReport 0x3cf7b5b2504141cf: from storage DS-f267b79f-d66e-4e74-a11c-9ad21a64e5e3 node DatanodeRegistration(10.10.1.6:9866, datanodeUuid=d06206ae-c96d-4ca6-8711-ba00daed279b, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-00d2bbc7-ad11-46b1-bf42-22535ada86e2;nsid=1637633049;c=1553698433502), blocks: 31, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-03-27 09:05:56,431 INFO  namenode.FSNamesystem FSNamesystem.java:stopStandbyServices:1408 - Stopping services started for standby state
2019-03-27 09:05:56,432 WARN  ha.EditLogTailer EditLogTailer.java:doWork:481 - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:479)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$400(EditLogTailer.java:409)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:426)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:422)
2019-03-27 09:05:56,435 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1203 - Starting services required for active state
2019-03-27 09:05:56,444 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:435 - Starting recovery process for unclosed journal segments...
2019-03-27 09:05:56,494 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnfinalizedSegments:437 - Successfully started new epoch 5
2019-03-27 09:05:56,495 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:277 - Beginning recovery of unclosed segment starting at txid 479
2019-03-27 09:05:56,515 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:286 - Recovery prepare phase complete. Responses:
10.10.1.2:8485: segmentState { startTxId: 479 endTxId: 479 isInProgress: true } lastWriterEpoch: 4 lastCommittedTxId: 476
10.10.1.3:8485: segmentState { startTxId: 479 endTxId: 479 isInProgress: true } lastWriterEpoch: 4 lastCommittedTxId: 476
2019-03-27 09:05:56,517 INFO  client.QuorumJournalManager QuorumJournalManager.java:recoverUnclosedSegment:310 - Using longest log: 10.10.1.2:8485=segmentState {
  startTxId: 479
  endTxId: 479
  isInProgress: true
}
lastWriterEpoch: 4
lastCommittedTxId: 476

2019-03-27 09:05:56,558 INFO  namenode.FileJournalManager FileJournalManager.java:recoverUnfinalizedSegments:396 - Recovering unfinalized segments in /tmp/hadoop-root/dfs/name/current
2019-03-27 09:05:56,586 INFO  namenode.FileJournalManager FileJournalManager.java:finalizeLogSegment:143 - Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000478 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000478-0000000000000000478
2019-03-27 09:05:56,602 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1214 - Catching up to latest edits from old active before taking over writer role in edits logs
2019-03-27 09:05:56,606 INFO  namenode.FSImage FSImage.java:loadEdits:887 - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@c9f5ecb expecting start txid #479
2019-03-27 09:05:56,607 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:158 - Start loading edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=479&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=479&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true maxTxnsToRead = 9223372036854775807
2019-03-27 09:05:56,607 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=479&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=479&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true' to transaction ID 479
2019-03-27 09:05:56,607 INFO  namenode.RedundantEditLogInputStream RedundantEditLogInputStream.java:nextOp:177 - Fast-forwarding stream 'http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=479&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true' to transaction ID 479
2019-03-27 09:05:56,615 INFO  namenode.FSImage FSEditLogLoader.java:loadFSEdits:162 - Edits file http://node-3-link-0:8480/getJournal?jid=mycluster&segmentTxId=479&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true, http://node-2-link-0:8480/getJournal?jid=mycluster&segmentTxId=479&storageInfo=-64%3A1637633049%3A1553698433502%3ACID-00d2bbc7-ad11-46b1-bf42-22535ada86e2&inProgressOk=true of size 1048576 edits # 1 loaded in 0 seconds
2019-03-27 09:05:56,615 INFO  blockmanagement.DatanodeManager DatanodeManager.java:markAllDatanodesStale:1837 - Marking all datanodes as stale
2019-03-27 09:05:56,616 INFO  namenode.FSNamesystem FSNamesystem.java:startActiveServices:1236 - Will take over writing edit logs at txnid 480
2019-03-27 09:05:56,619 INFO  namenode.FSEditLog FSEditLog.java:startLogSegment:1361 - Starting log segment at 480
2019-03-27 09:05:56,902 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:767 - Initializing quota with 4 thread(s)
2019-03-27 09:05:56,907 INFO  namenode.FSDirectory FSDirectory.java:updateCountForQuota:776 - Quota initialization completed in 4 milliseconds
name space=6
storage space=16106127360
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2019-03-27 09:05:56,912 INFO  blockmanagement.CacheReplicationMonitor CacheReplicationMonitor.java:run:160 - Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-03-27 09:05:58,020 INFO  hdfs.StateChange BlockManagerSafeMode.java:reportStatus:602 - STATE* Safe mode ON, in safe mode extension. 
The reported blocks 40 has reached the threshold 0.9990 of total blocks 40. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2019-03-27 09:06:03,535 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 6 on 8020, call Call#3 Retry#11 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44658
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 40 has reached the threshold 0.9990 of total blocks 40. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 4 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile4. Name node is in safe mode.
The reported blocks 40 has reached the threshold 0.9990 of total blocks 40. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 4 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:06:04,507 INFO  ipc.Server Server.java:logException:2722 - IPC Server handler 6 on 8020, call Call#3 Retry#12 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 10.10.1.7:44660
org.apache.hadoop.ipc.RetriableException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 40 has reached the threshold 0.9990 of total blocks 40. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 3 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1441)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2986)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /myfile1. Name node is in safe mode.
The reported blocks 40 has reached the threshold 0.9990 of total blocks 40. The number of live datanodes 4 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 3 seconds. NamenodeHostName:node-1-link-0
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1437)
	... 12 more
2019-03-27 09:06:08,022 INFO  blockmanagement.BlockManager BlockManager.java:initializeReplQueues:4752 - initializing replication queues
2019-03-27 09:06:08,022 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:391 - STATE* Safe mode is OFF
2019-03-27 09:06:08,023 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:396 - STATE* Leaving safe mode after 30 secs
2019-03-27 09:06:08,023 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:402 - STATE* Network topology has 1 racks and 4 datanodes
2019-03-27 09:06:08,023 INFO  hdfs.StateChange BlockManagerSafeMode.java:leaveSafeMode:404 - STATE* UnderReplicatedBlocks has 0 blocks
2019-03-27 09:06:08,086 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3447 - Total number of blocks            = 40
2019-03-27 09:06:08,086 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3448 - Number of invalid blocks          = 0
2019-03-27 09:06:08,087 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3449 - Number of under-replicated blocks = 0
2019-03-27 09:06:08,087 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3450 - Number of  over-replicated blocks = 0
2019-03-27 09:06:08,087 INFO  blockmanagement.BlockManager BlockManager.java:processMisReplicatesAsync:3452 - Number of blocks being written    = 0
2019-03-27 09:06:08,087 INFO  hdfs.StateChange BlockManager.java:processMisReplicatesAsync:3455 - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 65 msec
2019-03-27 09:06:28,531 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741961_1137, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.6:9866 for /myfile4._COPYING_
2019-03-27 09:06:29,142 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741962_1138, replicas=10.10.1.6:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-03-27 09:06:29,511 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741963_1139, replicas=10.10.1.6:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-03-27 09:06:29,940 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741964_1140, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.6:9866 for /myfile4._COPYING_
2019-03-27 09:06:30,289 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741965_1141, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-03-27 09:06:30,713 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741966_1142, replicas=10.10.1.6:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-03-27 09:06:32,238 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1524ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.5:8485
2019-03-27 09:06:32,670 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1956ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.3:8485
2019-03-27 09:06:32,761 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741967_1143, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-03-27 09:06:33,123 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741968_1144, replicas=10.10.1.2:9866, 10.10.1.6:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-03-27 09:06:33,201 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2487ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.2:8485
2019-03-27 09:06:33,413 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741969_1145, replicas=10.10.1.6:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-03-27 09:06:33,597 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741970_1146, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.6:9866 for /myfile4._COPYING_
2019-03-27 09:06:33,856 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741971_1147, replicas=10.10.1.6:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-03-27 09:06:34,050 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile4._COPYING_ is closed by DFSClient_NONMAPREDUCE_-972055274_1
2019-03-27 09:06:34,259 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741972_1148, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.6:9866 for /myfile1._COPYING_
2019-03-27 09:06:34,682 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741973_1149, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.6:9866 for /myfile1._COPYING_
2019-03-27 09:06:34,682 INFO  namenode.FSEditLog FSEditLog.java:printStatistics:774 - Number of transactions: 45 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 492 Number of syncs: 30 SyncTimes(ms): 2276 334 
2019-03-27 09:06:35,099 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741974_1150, replicas=10.10.1.6:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-03-27 09:06:35,524 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741975_1151, replicas=10.10.1.3:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-03-27 09:06:35,937 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741976_1152, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-03-27 09:06:36,327 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile1._COPYING_ is closed by DFSClient_NONMAPREDUCE_408214040_1
2019-03-27 09:06:39,840 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3512ms to send a batch of 1 edits (285 bytes) to remote journal 10.10.1.2:8485
2019-03-27 09:06:41,124 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 5186ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.5:8485
2019-03-27 09:06:41,648 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 5320ms to send a batch of 1 edits (285 bytes) to remote journal 10.10.1.3:8485
2019-03-27 09:07:00,798 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741977_1153, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.6:9866 for /myfile3._COPYING_
2019-03-27 09:07:01,351 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741978_1154, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile3._COPYING_
2019-03-27 09:07:01,742 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741979_1155, replicas=10.10.1.6:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile3._COPYING_
2019-03-27 09:07:02,163 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741980_1156, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile3._COPYING_
2019-03-27 09:07:02,590 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741981_1157, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.6:9866 for /myfile3._COPYING_
2019-03-27 09:07:03,007 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741982_1158, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.6:9866 for /myfile3._COPYING_
2019-03-27 09:07:03,462 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741983_1159, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile3._COPYING_
2019-03-27 09:07:03,901 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741984_1160, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile3._COPYING_
2019-03-27 09:07:04,408 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile3._COPYING_ is closed by DFSClient_NONMAPREDUCE_1154858262_1
2019-03-27 09:07:05,009 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2846ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.2:8485
2019-03-27 09:07:09,161 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 4752ms to send a batch of 1 edits (285 bytes) to remote journal 10.10.1.5:8485
2019-03-27 09:07:14,185 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1161ms to send a batch of 1 edits (57 bytes) to remote journal 10.10.1.5:8485
2019-03-27 09:07:18,006 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 4982ms to send a batch of 1 edits (57 bytes) to remote journal 10.10.1.2:8485
2019-03-27 09:07:18,433 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 5409ms to send a batch of 1 edits (57 bytes) to remote journal 10.10.1.3:8485
2019-03-27 09:07:22,633 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741985_1161, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-03-27 09:07:23,148 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741986_1162, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.6:9866 for /myfile5._COPYING_
2019-03-27 09:07:25,640 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741987_1163, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-03-27 09:07:25,687 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3143ms to send a batch of 1 edits (171 bytes) to remote journal 10.10.1.2:8485
2019-03-27 09:07:26,131 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741988_1164, replicas=10.10.1.3:9866, 10.10.1.6:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-03-27 09:07:26,540 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741989_1165, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-03-27 09:07:26,797 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1087ms to send a batch of 1 edits (74 bytes) to remote journal 10.10.1.2:8485
2019-03-27 09:07:26,932 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741990_1166, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.6:9866 for /myfile5._COPYING_
2019-03-27 09:07:27,357 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741991_1167, replicas=10.10.1.6:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-03-27 09:07:27,768 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741992_1168, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.6:9866 for /myfile5._COPYING_
2019-03-27 09:07:28,178 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile5._COPYING_ is closed by DFSClient_NONMAPREDUCE_-735514603_1
2019-03-27 09:07:29,738 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741993_1169, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-03-27 09:07:30,313 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741994_1170, replicas=10.10.1.6:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-03-27 09:07:30,735 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741995_1171, replicas=10.10.1.6:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-03-27 09:07:31,144 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741996_1172, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-03-27 09:07:31,549 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741997_1173, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-03-27 09:07:32,146 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741998_1174, replicas=10.10.1.3:9866, 10.10.1.6:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-03-27 09:07:32,584 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073741999_1175, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-03-27 09:07:32,993 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742000_1176, replicas=10.10.1.6:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile2._COPYING_
2019-03-27 09:07:33,402 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile2._COPYING_ is closed by DFSClient_NONMAPREDUCE_1113137826_1
2019-03-27 09:07:37,276 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 5726ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.5:8485
2019-03-27 09:07:38,173 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 4770ms to send a batch of 1 edits (285 bytes) to remote journal 10.10.1.3:8485
2019-03-27 09:07:38,218 INFO  namenode.FSEditLog FSEditLog.java:printStatistics:774 - Number of transactions: 141 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 520 Number of syncs: 99 SyncTimes(ms): 18220 911 
2019-03-27 09:07:41,308 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3089ms to send a batch of 1 edits (77 bytes) to remote journal 10.10.1.2:8485
2019-03-27 09:07:41,776 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 4456ms to send a batch of 1 edits (285 bytes) to remote journal 10.10.1.5:8485
2019-03-27 09:07:45,252 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 7034ms to send a batch of 1 edits (77 bytes) to remote journal 10.10.1.3:8485
2019-03-27 09:07:56,490 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1499ms to send a batch of 1 edits (57 bytes) to remote journal 10.10.1.2:8485
2019-03-27 09:07:57,356 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2364ms to send a batch of 1 edits (57 bytes) to remote journal 10.10.1.3:8485
2019-03-27 09:08:02,204 INFO  namenode.FSNamesystem FSNamesystem.java:rollEditLog:4646 - Roll Edit Log from 10.10.1.1
2019-03-27 09:08:02,204 INFO  namenode.FSEditLog FSEditLog.java:rollEditLog:1314 - Rolling edit logs
2019-03-27 09:08:02,204 INFO  namenode.FSEditLog FSEditLog.java:endCurrentLogSegment:1406 - Ending log segment 480, 622
2019-03-27 09:08:02,333 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1239ms to send a batch of 1 edits (171 bytes) to remote journal 10.10.1.5:8485
2019-03-27 09:08:06,214 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 5120ms to send a batch of 1 edits (171 bytes) to remote journal 10.10.1.3:8485
2019-03-27 09:08:08,897 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2665ms to send a batch of 1 edits (17 bytes) to remote journal 10.10.1.5:8485
2019-03-27 09:08:09,237 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 8143ms to send a batch of 1 edits (171 bytes) to remote journal 10.10.1.2:8485
2019-03-27 09:08:09,373 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3142ms to send a batch of 1 edits (17 bytes) to remote journal 10.10.1.3:8485
2019-03-27 09:08:09,396 INFO  namenode.FSEditLog FSEditLog.java:printStatistics:774 - Number of transactions: 144 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 520 Number of syncs: 103 SyncTimes(ms): 31567 987 
2019-03-27 09:08:09,400 INFO  namenode.FileJournalManager FileJournalManager.java:finalizeLogSegment:143 - Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000480 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000480-0000000000000000623
2019-03-27 09:08:09,401 INFO  namenode.FSEditLog FSEditLog.java:startLogSegment:1361 - Starting log segment at 624
2019-03-27 09:08:15,402 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6001 ms (timeout=20000 ms) for a response for startLogSegment(624). No responses yet.
2019-03-27 09:08:16,404 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 7003 ms (timeout=20000 ms) for a response for startLogSegment(624). No responses yet.
2019-03-27 09:08:16,519 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 7281ms to send a batch of 1 edits (17 bytes) to remote journal 10.10.1.2:8485
2019-03-27 09:08:17,592 INFO  namenode.FSNamesystem FSNamesystemLock.java:writeUnlock:282 - FSNamesystem write lock held for 15387 ms via
java.lang.Thread.getStackTrace(Thread.java:1559)
org.apache.hadoop.util.StringUtils.getStackTrace(StringUtils.java:1032)
org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.writeUnlock(FSNamesystemLock.java:284)
org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.writeUnlock(FSNamesystemLock.java:234)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.writeUnlock(FSNamesystem.java:1606)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4650)
org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:1292)
org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:146)
org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:12974)
org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
java.security.AccessController.doPrivileged(Native Method)
javax.security.auth.Subject.doAs(Subject.java:422)
org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
	Number of suppressed write-lock reports: 0
	Longest write-lock held interval: 15387
2019-03-27 09:08:17,613 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742001_1177, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-03-27 09:08:18,170 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742002_1178, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.6:9866 for /myfile4._COPYING_
2019-03-27 09:08:18,624 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742003_1179, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-03-27 09:08:19,051 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742004_1180, replicas=10.10.1.6:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-03-27 09:08:19,440 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742005_1181, replicas=10.10.1.6:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-03-27 09:08:19,846 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742006_1182, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-03-27 09:08:20,331 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742007_1183, replicas=10.10.1.6:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-03-27 09:08:20,728 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3537ms to send a batch of 1 edits (17 bytes) to remote journal 10.10.1.3:8485
2019-03-27 09:08:20,773 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742008_1184, replicas=10.10.1.6:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-03-27 09:08:21,169 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile4._COPYING_ is closed by DFSClient_NONMAPREDUCE_-548104331_1
2019-03-27 09:08:22,232 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742009_1185, replicas=10.10.1.6:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-03-27 09:08:27,118 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 6344ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.3:8485
2019-03-27 09:08:27,735 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742010_1186, replicas=10.10.1.2:9866, 10.10.1.6:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-03-27 09:08:28,256 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742011_1187, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.6:9866 for /myfile1._COPYING_
2019-03-27 09:08:28,807 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742012_1188, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-03-27 09:08:29,236 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742013_1189, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-03-27 09:08:29,629 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742014_1190, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile1._COPYING_
2019-03-27 09:08:30,056 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742015_1191, replicas=10.10.1.3:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-03-27 09:08:30,478 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742016_1192, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.6:9866 for /myfile1._COPYING_
2019-03-27 09:08:30,894 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile1._COPYING_ is closed by DFSClient_NONMAPREDUCE_1810633363_1
2019-03-27 09:08:46,030 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742017_1193, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.6:9866 for /myfile3._COPYING_
2019-03-27 09:08:46,561 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 5379ms to send a batch of 1 edits (57 bytes) to remote journal 10.10.1.2:8485
2019-03-27 09:08:50,664 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 4102ms to send a batch of 1 edits (172 bytes) to remote journal 10.10.1.2:8485
2019-03-27 09:08:50,668 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742018_1194, replicas=10.10.1.6:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile3._COPYING_
2019-03-27 09:08:53,995 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3326ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.2:8485
2019-03-27 09:08:55,252 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742019_1195, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.6:9866 for /myfile3._COPYING_
2019-03-27 09:08:57,581 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2328ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.3:8485
2019-03-27 09:08:58,893 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3640ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.2:8485
2019-03-27 09:09:00,369 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 5116ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.5:8485
2019-03-27 09:09:02,260 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1891ms to send a batch of 1 edits (74 bytes) to remote journal 10.10.1.5:8485
2019-03-27 09:09:03,941 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 5025ms to send a batch of 1 edits (74 bytes) to remote journal 10.10.1.2:8485
2019-03-27 09:09:05,175 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 6259ms to send a batch of 1 edits (74 bytes) to remote journal 10.10.1.3:8485
2019-03-27 09:09:07,174 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742020_1196, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.6:9866 for /myfile3._COPYING_
2019-03-27 09:09:11,598 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 4643ms to send a batch of 1 edits (57 bytes) to remote journal 10.10.1.5:8485
2019-03-27 09:09:11,618 INFO  namenode.FSEditLog FSEditLog.java:printStatistics:774 - Number of transactions: 70 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 19 Number of syncs: 48 SyncTimes(ms): 14171 462 
2019-03-27 09:09:12,207 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742021_1197, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile3._COPYING_
2019-03-27 09:09:13,063 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 6109ms to send a batch of 1 edits (57 bytes) to remote journal 10.10.1.3:8485
2019-03-27 09:09:15,563 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2499ms to send a batch of 3 edits (124 bytes) to remote journal 10.10.1.3:8485
2019-03-27 09:09:15,937 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742022_1198, replicas=10.10.1.3:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile3._COPYING_
2019-03-27 09:09:16,113 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742023_1199, replicas=10.10.1.6:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-03-27 09:09:18,083 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2145ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.3:8485
2019-03-27 09:09:18,959 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1936ms to send a batch of 1 edits (57 bytes) to remote journal 10.10.1.2:8485
2019-03-27 09:09:19,165 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742024_1200, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile3._COPYING_
2019-03-27 09:09:19,334 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742025_1201, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.3:9866 for /myfile5._COPYING_
2019-03-27 09:09:19,617 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742026_1202, replicas=10.10.1.2:9866, 10.10.1.6:9866, 10.10.1.3:9866 for /myfile3._COPYING_
2019-03-27 09:09:19,729 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742027_1203, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.6:9866 for /myfile5._COPYING_
2019-03-27 09:09:20,042 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile3._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1670473768_1
2019-03-27 09:09:20,139 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742028_1204, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile5._COPYING_
2019-03-27 09:09:20,541 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742029_1205, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.6:9866 for /myfile5._COPYING_
2019-03-27 09:09:20,949 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742030_1206, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.6:9866 for /myfile5._COPYING_
2019-03-27 09:09:21,363 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742031_1207, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile5._COPYING_
2019-03-27 09:09:21,759 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742032_1208, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.6:9866 for /myfile5._COPYING_
2019-03-27 09:09:22,157 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile5._COPYING_ is closed by DFSClient_NONMAPREDUCE_597187609_1
2019-03-27 09:09:22,623 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742033_1209, replicas=10.10.1.6:9866, 10.10.1.3:9866, 10.10.1.2:9866 for /myfile2._COPYING_
2019-03-27 09:09:23,179 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742034_1210, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-03-27 09:09:23,588 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742035_1211, replicas=10.10.1.6:9866, 10.10.1.2:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-03-27 09:09:24,018 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742036_1212, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile2._COPYING_
2019-03-27 09:09:24,411 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742037_1213, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile2._COPYING_
2019-03-27 09:09:24,804 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742038_1214, replicas=10.10.1.6:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile2._COPYING_
2019-03-27 09:09:25,213 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742039_1215, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.6:9866 for /myfile2._COPYING_
2019-03-27 09:09:25,612 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742040_1216, replicas=10.10.1.3:9866, 10.10.1.6:9866, 10.10.1.5:9866 for /myfile2._COPYING_
2019-03-27 09:09:26,001 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile2._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1222971920_1
2019-03-27 09:09:52,745 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2474ms to send a batch of 1 edits (172 bytes) to remote journal 10.10.1.3:8485
2019-03-27 09:09:52,808 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742041_1217, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.6:9866 for /myfile4._COPYING_
2019-03-27 09:09:58,202 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 5393ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.3:8485
2019-03-27 09:09:58,602 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 8331ms to send a batch of 1 edits (172 bytes) to remote journal 10.10.1.2:8485
2019-03-27 09:10:00,930 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2692ms to send a batch of 1 edits (56 bytes) to remote journal 10.10.1.5:8485
2019-03-27 09:10:04,238 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6001 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [10.10.1.5:8485]
2019-03-27 09:10:04,844 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 6240ms to send a batch of 1 edits (56 bytes) to remote journal 10.10.1.2:8485
2019-03-27 09:10:04,856 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 6618ms to send a batch of 1 edits (56 bytes) to remote journal 10.10.1.3:8485
2019-03-27 09:10:05,376 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742042_1218, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.6:9866 for /myfile4._COPYING_
2019-03-27 09:10:06,370 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1519ms to send a batch of 1 edits (57 bytes) to remote journal 10.10.1.5:8485
2019-03-27 09:10:07,997 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3147ms to send a batch of 1 edits (57 bytes) to remote journal 10.10.1.2:8485
2019-03-27 09:10:10,670 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 5814ms to send a batch of 1 edits (57 bytes) to remote journal 10.10.1.3:8485
2019-03-27 09:10:13,618 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 5602ms to send a batch of 3 edits (124 bytes) to remote journal 10.10.1.2:8485
2019-03-27 09:10:14,016 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6001 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [10.10.1.2:8485]
2019-03-27 09:10:14,108 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 6093ms to send a batch of 3 edits (124 bytes) to remote journal 10.10.1.5:8485
2019-03-27 09:10:14,129 INFO  namenode.FSEditLog FSEditLog.java:printStatistics:774 - Number of transactions: 149 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 44 Number of syncs: 104 SyncTimes(ms): 39606 878 
2019-03-27 09:10:15,012 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 4341ms to send a batch of 3 edits (124 bytes) to remote journal 10.10.1.3:8485
2019-03-27 09:10:17,481 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3352ms to send a batch of 1 edits (171 bytes) to remote journal 10.10.1.5:8485
2019-03-27 09:10:17,545 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742043_1219, replicas=10.10.1.6:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-03-27 09:10:17,549 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742044_1220, replicas=10.10.1.6:9866, 10.10.1.5:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-03-27 09:10:17,719 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 3589ms to send a batch of 1 edits (171 bytes) to remote journal 10.10.1.2:8485
2019-03-27 09:10:17,945 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742045_1221, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-03-27 09:10:18,083 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742046_1222, replicas=10.10.1.5:9866, 10.10.1.2:9866, 10.10.1.6:9866 for /myfile1._COPYING_
2019-03-27 09:10:18,086 INFO  namenode.FSNamesystem FSNamesystem.java:rollEditLog:4646 - Roll Edit Log from 10.10.1.1
2019-03-27 09:10:18,086 INFO  namenode.FSEditLog FSEditLog.java:rollEditLog:1314 - Rolling edit logs
2019-03-27 09:10:18,086 INFO  namenode.FSEditLog FSEditLog.java:endCurrentLogSegment:1406 - Ending log segment 624, 783
2019-03-27 09:10:18,110 INFO  namenode.FSEditLog FSEditLog.java:printStatistics:774 - Number of transactions: 162 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 51 Number of syncs: 111 SyncTimes(ms): 43030 927 
2019-03-27 09:10:18,113 INFO  namenode.FileJournalManager FileJournalManager.java:finalizeLogSegment:143 - Finalizing edits file /tmp/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000624 -> /tmp/hadoop-root/dfs/name/current/edits_0000000000000000624-0000000000000000785
2019-03-27 09:10:18,113 INFO  namenode.FSEditLog FSEditLog.java:startLogSegment:1361 - Starting log segment at 786
2019-03-27 09:10:18,387 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742047_1223, replicas=10.10.1.3:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile4._COPYING_
2019-03-27 09:10:18,490 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742048_1224, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.6:9866 for /myfile1._COPYING_
2019-03-27 09:10:18,832 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742049_1225, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.5:9866 for /myfile4._COPYING_
2019-03-27 09:10:18,940 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742050_1226, replicas=10.10.1.2:9866, 10.10.1.6:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-03-27 09:10:19,329 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742051_1227, replicas=10.10.1.6:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-03-27 09:10:19,358 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742052_1228, replicas=10.10.1.5:9866, 10.10.1.6:9866, 10.10.1.2:9866 for /myfile1._COPYING_
2019-03-27 09:10:19,759 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742053_1229, replicas=10.10.1.2:9866, 10.10.1.6:9866, 10.10.1.3:9866 for /myfile4._COPYING_
2019-03-27 09:10:19,783 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742054_1230, replicas=10.10.1.6:9866, 10.10.1.2:9866, 10.10.1.3:9866 for /myfile1._COPYING_
2019-03-27 09:10:20,214 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile4._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1679447345_1
2019-03-27 09:10:20,308 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742055_1231, replicas=10.10.1.3:9866, 10.10.1.2:9866, 10.10.1.6:9866 for /myfile1._COPYING_
2019-03-27 09:10:20,768 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 2823ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.2:8485
2019-03-27 09:10:20,893 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742056_1232, replicas=10.10.1.5:9866, 10.10.1.3:9866, 10.10.1.6:9866 for /myfile1._COPYING_
2019-03-27 09:10:21,355 INFO  hdfs.StateChange FSNamesystem.java:completeFile:2850 - DIR* completeFile: /myfile1._COPYING_ is closed by DFSClient_NONMAPREDUCE_-623655294_1
2019-03-27 09:10:50,452 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1895ms to send a batch of 1 edits (170 bytes) to remote journal 10.10.1.3:8485
2019-03-27 09:10:50,530 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742057_1233, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.6:9866 for /myfile5._COPYING_
2019-03-27 09:10:51,156 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742058_1234, replicas=10.10.1.2:9866, 10.10.1.3:9866, 10.10.1.6:9866 for /myfile5._COPYING_
2019-03-27 09:10:55,446 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 6889ms to send a batch of 1 edits (170 bytes) to remote journal 10.10.1.2:8485
2019-03-27 09:10:57,139 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 5982ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.5:8485
2019-03-27 09:10:58,247 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 1091ms to send a batch of 3 edits (415 bytes) to remote journal 10.10.1.3:8485
2019-03-27 09:10:59,603 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 4155ms to send a batch of 2 edits (50 bytes) to remote journal 10.10.1.2:8485
2019-03-27 09:11:03,157 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 6001 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [10.10.1.3:8485]
2019-03-27 09:11:04,158 INFO  client.QuorumJournalManager QuorumCall.java:waitFor:187 - Waited 7002 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [10.10.1.3:8485]
2019-03-27 09:11:04,414 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 7258ms to send a batch of 3 edits (415 bytes) to remote journal 10.10.1.5:8485
2019-03-27 09:11:04,485 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742059_1235, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.6:9866 for /myfile3._COPYING_
2019-03-27 09:11:04,486 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742060_1236, replicas=10.10.1.2:9866, 10.10.1.5:9866, 10.10.1.3:9866 for /myfile2._COPYING_
2019-03-27 09:11:06,199 WARN  client.QuorumJournalManager IPCLoggerChannel.java:call:417 - Took 6595ms to send a batch of 3 edits (415 bytes) to remote journal 10.10.1.2:8485
2019-03-27 09:11:06,906 INFO  hdfs.StateChange FSDirWriteFileOp.java:logAllocatedBlock:796 - BLOCK* allocate blk_1073742061_1237, replicas=10.10.1.3:9866, 10.10.1.5:9866, 10.10.1.6:9866 for /myfile5._COPYING_

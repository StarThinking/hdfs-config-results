2019-03-28 01:18:15,154 INFO  datanode.DataNode LogAdapter.java:info:51 - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = clnode080.clemson.cloudlab.us/130.127.133.89
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.1
STARTUP_MSG:   classpath = /root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/etc/hadoop:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jsp-api-2.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-common-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/common/hadoop-kms-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/xz-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1-tests.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/javax.inject-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/guice-4.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/fst-2.50.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.1.jar:/root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2019-03-25T05:45Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-03-28 01:18:15,166 INFO  datanode.DataNode LogAdapter.java:info:51 - registered UNIX signal handlers for [TERM, HUP, INT]
2019-03-28 01:18:15,739 INFO  checker.ThrottledAsyncChecker ThrottledAsyncChecker.java:schedule:137 - Scheduling a check for [DISK]file:/root/hdfs-root/data
2019-03-28 01:18:15,909 INFO  beanutils.FluentPropertyBeanIntrospector FluentPropertyBeanIntrospector.java:introspect:147 - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2019-03-28 01:18:15,952 INFO  impl.MetricsConfig MetricsConfig.java:loadFirst:121 - loaded properties from hadoop-metrics2.properties
2019-03-28 01:18:16,029 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:startTimer:374 - Scheduled Metric snapshot period at 10 second(s).
2019-03-28 01:18:16,030 INFO  impl.MetricsSystemImpl MetricsSystemImpl.java:start:191 - DataNode metrics system started
2019-03-28 01:18:16,291 INFO  common.Util Util.java:isDiskStatsEnabled:395 - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-03-28 01:18:16,294 INFO  datanode.BlockScanner BlockScanner.java:<init>:184 - Initialized block scanner with targetBytesPerSec 1048576
2019-03-28 01:18:16,300 INFO  datanode.DataNode DataNode.java:<init>:496 - Configured hostname is clnode080.clemson.cloudlab.us
2019-03-28 01:18:16,300 INFO  common.Util Util.java:isDiskStatsEnabled:395 - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-03-28 01:18:16,305 INFO  datanode.DataNode DataNode.java:startDataNode:1387 - Starting DataNode with maxLockedMemory = 0
2019-03-28 01:18:16,329 INFO  datanode.DataNode DataNode.java:initDataXceiver:1144 - Opened streaming server at /0.0.0.0:9866
2019-03-28 01:18:16,331 INFO  datanode.DataNode DataXceiverServer.java:<init>:78 - Balancing bandwidth is 10485760 bytes/s
2019-03-28 01:18:16,332 INFO  datanode.DataNode DataXceiverServer.java:<init>:79 - Number threads for balancing is 50
2019-03-28 01:18:16,473 INFO  util.log Log.java:initialized:192 - Logging initialized @1848ms
2019-03-28 01:18:16,592 INFO  server.AuthenticationFilter AuthenticationFilter.java:constructSecretProvider:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-03-28 01:18:16,595 INFO  http.HttpRequestLog HttpRequestLog.java:getRequestLog:81 - Http request log for http.requests.datanode is not defined
2019-03-28 01:18:16,601 INFO  http.HttpServer2 HttpServer2.java:addGlobalFilter:968 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-03-28 01:18:16,604 INFO  http.HttpServer2 HttpServer2.java:addFilter:941 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-03-28 01:18:16,604 INFO  http.HttpServer2 HttpServer2.java:addFilter:951 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-03-28 01:18:16,604 INFO  http.HttpServer2 HttpServer2.java:addFilter:951 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-03-28 01:18:16,629 INFO  http.HttpServer2 HttpServer2.java:bindListener:1185 - Jetty bound to port 46734
2019-03-28 01:18:16,630 INFO  server.Server Server.java:doStart:346 - jetty-9.3.19.v20170502
2019-03-28 01:18:16,665 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@7dda48d9{/logs,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/logs/,AVAILABLE}
2019-03-28 01:18:16,665 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.s.ServletContextHandler@4b6e2263{/static,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2019-03-28 01:18:16,736 INFO  handler.ContextHandler ContextHandler.java:doStart:781 - Started o.e.j.w.WebAppContext@663411de{/,file:///root/hadoop-3.1.1-src/hadoop-dist/target/hadoop-3.1.1/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{/datanode}
2019-03-28 01:18:16,743 INFO  server.AbstractConnector AbstractConnector.java:doStart:278 - Started ServerConnector@4b41e4dd{HTTP/1.1,[http/1.1]}{localhost:46734}
2019-03-28 01:18:16,743 INFO  server.Server Server.java:doStart:414 - Started @2118ms
2019-03-28 01:18:16,937 INFO  web.DatanodeHttpServer DatanodeHttpServer.java:start:255 - Listening HTTP traffic on /0.0.0.0:9864
2019-03-28 01:18:16,944 INFO  util.JvmPauseMonitor JvmPauseMonitor.java:run:188 - Starting JVM pause monitor
2019-03-28 01:18:16,986 INFO  datanode.DataNode DataNode.java:startDataNode:1414 - dnUserName = root
2019-03-28 01:18:16,987 INFO  datanode.DataNode DataNode.java:startDataNode:1415 - supergroup = supergroup
2019-03-28 01:18:17,032 INFO  ipc.CallQueueManager CallQueueManager.java:<init>:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-03-28 01:18:17,048 INFO  ipc.Server Server.java:run:1070 - Starting Socket Reader #1 for port 9867
2019-03-28 01:18:17,091 INFO  datanode.DataNode DataNode.java:initIpcServer:1030 - Opened IPC server at /0.0.0.0:9867
2019-03-28 01:18:17,108 INFO  datanode.DataNode BlockPoolManager.java:refreshNamenodes:149 - Refresh request received for nameservices: mycluster
2019-03-28 01:18:17,119 INFO  datanode.DataNode BlockPoolManager.java:doRefreshNamenodes:210 - Starting BPOfferServices for nameservices: mycluster
2019-03-28 01:18:17,130 INFO  datanode.DataNode BPServiceActor.java:run:809 - Block pool <registering> (Datanode Uuid unassigned) service to node-0-link-0/10.10.1.1:8020 starting to offer service
2019-03-28 01:18:17,130 INFO  datanode.DataNode BPServiceActor.java:run:809 - Block pool <registering> (Datanode Uuid unassigned) service to node-1-link-0/10.10.1.4:8020 starting to offer service
2019-03-28 01:18:17,139 INFO  ipc.Server Server.java:run:1310 - IPC Server Responder: starting
2019-03-28 01:18:17,139 INFO  ipc.Server Server.java:run:1149 - IPC Server listener on 9867: starting
2019-03-28 01:18:18,225 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-1-link-0/10.10.1.4:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-28 01:18:18,225 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-0-link-0/10.10.1.1:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-28 01:18:19,225 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-1-link-0/10.10.1.4:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-28 01:18:19,225 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-0-link-0/10.10.1.1:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-28 01:18:20,226 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-1-link-0/10.10.1.4:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-28 01:18:20,226 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-0-link-0/10.10.1.1:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-28 01:18:21,227 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-1-link-0/10.10.1.4:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-28 01:18:21,227 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-0-link-0/10.10.1.1:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-28 01:18:22,228 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-0-link-0/10.10.1.1:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-28 01:18:22,228 INFO  ipc.Client Client.java:handleConnectionFailure:942 - Retrying connect to server: node-1-link-0/10.10.1.4:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-03-28 01:18:22,316 INFO  common.Storage DataStorage.java:getParallelVolumeLoadThreadsNum:354 - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-03-28 01:18:22,364 INFO  common.Storage Storage.java:tryLock:905 - Lock on /root/hdfs-root/data/in_use.lock acquired by nodename 68932@clnode080.clemson.cloudlab.us
2019-03-28 01:18:22,366 INFO  common.Storage DataStorage.java:loadStorageDirectory:282 - Storage directory with location [DISK]file:/root/hdfs-root/data is not formatted for namespace 868784382. Formatting...
2019-03-28 01:18:22,367 INFO  common.Storage DataStorage.java:createStorageID:160 - Generated new storageID DS-97afc22e-b0ee-4f81-9ca3-85a719f5220c for directory /root/hdfs-root/data 
2019-03-28 01:18:22,442 INFO  common.Storage BlockPoolSliceStorage.java:recoverTransitionRead:251 - Analyzing storage directories for bpid BP-583823579-130.127.133.65-1553757466424
2019-03-28 01:18:22,443 INFO  common.Storage Storage.java:lock:864 - Locking is disabled for /root/hdfs-root/data/current/BP-583823579-130.127.133.65-1553757466424
2019-03-28 01:18:22,443 INFO  common.Storage BlockPoolSliceStorage.java:loadStorageDirectory:168 - Block pool storage directory for location [DISK]file:/root/hdfs-root/data and block pool id BP-583823579-130.127.133.65-1553757466424 is not formatted. Formatting ...
2019-03-28 01:18:22,443 INFO  common.Storage BlockPoolSliceStorage.java:format:280 - Formatting block pool BP-583823579-130.127.133.65-1553757466424 directory /root/hdfs-root/data/current/BP-583823579-130.127.133.65-1553757466424/current
2019-03-28 01:18:22,496 INFO  datanode.DataNode DataNode.java:initStorage:1708 - Setting up storage: nsid=868784382;bpid=BP-583823579-130.127.133.65-1553757466424;lv=-57;nsInfo=lv=-64;cid=CID-cc1c02d7-b8dd-4817-9128-117cf6935e36;nsid=868784382;c=1553757466424;bpid=BP-583823579-130.127.133.65-1553757466424;dnuuid=null
2019-03-28 01:18:22,540 INFO  datanode.DataNode DataNode.java:checkDatanodeUuid:1532 - Generated and persisted new Datanode UUID fe89b2a7-373a-41b1-ac9e-b7ce50a592aa
2019-03-28 01:18:22,614 INFO  impl.FsDatasetImpl FsVolumeList.java:addVolume:305 - Added new volume: DS-97afc22e-b0ee-4f81-9ca3-85a719f5220c
2019-03-28 01:18:22,614 INFO  impl.FsDatasetImpl FsDatasetImpl.java:addVolume:432 - Added volume - [DISK]file:/root/hdfs-root/data, StorageType: DISK
2019-03-28 01:18:22,618 INFO  impl.FsDatasetImpl FsDatasetImpl.java:registerMBean:2253 - Registered FSDatasetState MBean
2019-03-28 01:18:22,626 INFO  checker.ThrottledAsyncChecker ThrottledAsyncChecker.java:schedule:137 - Scheduling a check for /root/hdfs-root/data
2019-03-28 01:18:22,635 INFO  checker.DatasetVolumeChecker DatasetVolumeChecker.java:checkAllVolumes:219 - Scheduled health check for volume /root/hdfs-root/data
2019-03-28 01:18:22,637 INFO  impl.FsDatasetImpl FsDatasetImpl.java:addBlockPool:2764 - Adding block pool BP-583823579-130.127.133.65-1553757466424
2019-03-28 01:18:22,638 INFO  impl.FsDatasetImpl FsVolumeList.java:run:408 - Scanning block pool BP-583823579-130.127.133.65-1553757466424 on volume /root/hdfs-root/data...
2019-03-28 01:18:22,654 INFO  impl.FsDatasetImpl FsVolumeList.java:run:413 - Time taken to scan block pool BP-583823579-130.127.133.65-1553757466424 on /root/hdfs-root/data: 16ms
2019-03-28 01:18:22,654 INFO  impl.FsDatasetImpl FsVolumeList.java:addBlockPool:439 - Total time to scan all replicas for block pool BP-583823579-130.127.133.65-1553757466424: 17ms
2019-03-28 01:18:22,657 INFO  impl.FsDatasetImpl FsVolumeList.java:run:198 - Adding replicas to map for block pool BP-583823579-130.127.133.65-1553757466424 on volume /root/hdfs-root/data...
2019-03-28 01:18:22,657 INFO  impl.BlockPoolSlice BlockPoolSlice.java:readReplicasFromCache:777 - Replica Cache file: /root/hdfs-root/data/current/BP-583823579-130.127.133.65-1553757466424/current/replicas doesn't exist 
2019-03-28 01:18:22,657 INFO  impl.FsDatasetImpl FsVolumeList.java:run:203 - Time to add replicas to map for block pool BP-583823579-130.127.133.65-1553757466424 on volume /root/hdfs-root/data: 1ms
2019-03-28 01:18:22,658 INFO  impl.FsDatasetImpl FsVolumeList.java:getAllVolumesMap:229 - Total time to add all replicas to map: 1ms
2019-03-28 01:18:22,659 INFO  datanode.VolumeScanner VolumeScanner.java:findNextUsableBlockIter:386 - Now scanning bpid BP-583823579-130.127.133.65-1553757466424 on volume /root/hdfs-root/data
2019-03-28 01:18:22,660 INFO  datanode.VolumeScanner VolumeScanner.java:runLoop:544 - VolumeScanner(/root/hdfs-root/data, DS-97afc22e-b0ee-4f81-9ca3-85a719f5220c): finished scanning block pool BP-583823579-130.127.133.65-1553757466424
2019-03-28 01:18:22,670 INFO  datanode.DirectoryScanner DirectoryScanner.java:start:283 - Periodic Directory Tree Verification scan starting at 3/28/19 4:35 AM with interval of 21600000ms
2019-03-28 01:18:22,677 INFO  datanode.DataNode BPServiceActor.java:register:763 - Block pool BP-583823579-130.127.133.65-1553757466424 (Datanode Uuid fe89b2a7-373a-41b1-ac9e-b7ce50a592aa) service to node-0-link-0/10.10.1.1:8020 beginning handshake with NN
2019-03-28 01:18:22,677 INFO  datanode.DataNode BPServiceActor.java:register:763 - Block pool BP-583823579-130.127.133.65-1553757466424 (Datanode Uuid fe89b2a7-373a-41b1-ac9e-b7ce50a592aa) service to node-1-link-0/10.10.1.4:8020 beginning handshake with NN
2019-03-28 01:18:22,687 INFO  datanode.VolumeScanner VolumeScanner.java:findNextUsableBlockIter:403 - VolumeScanner(/root/hdfs-root/data, DS-97afc22e-b0ee-4f81-9ca3-85a719f5220c): no suitable block pools found to scan.  Waiting 1814399972 ms.
2019-03-28 01:18:22,715 INFO  datanode.DataNode BPServiceActor.java:register:782 - Block pool Block pool BP-583823579-130.127.133.65-1553757466424 (Datanode Uuid fe89b2a7-373a-41b1-ac9e-b7ce50a592aa) service to node-1-link-0/10.10.1.4:8020 successfully registered with NN
2019-03-28 01:18:22,715 INFO  datanode.DataNode BPServiceActor.java:offerService:612 - For namenode node-1-link-0/10.10.1.4:8020 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-03-28 01:18:22,717 INFO  datanode.DataNode BPServiceActor.java:register:782 - Block pool Block pool BP-583823579-130.127.133.65-1553757466424 (Datanode Uuid fe89b2a7-373a-41b1-ac9e-b7ce50a592aa) service to node-0-link-0/10.10.1.1:8020 successfully registered with NN
2019-03-28 01:18:22,717 INFO  datanode.DataNode BPServiceActor.java:offerService:612 - For namenode node-0-link-0/10.10.1.1:8020 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-03-28 01:18:22,872 INFO  datanode.DataNode BPServiceActor.java:blockReport:422 - Successfully sent block report 0x2c86dc4866d2d13b,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 56 msecs for RPC and NN processing. Got back no commands.
2019-03-28 01:18:22,872 INFO  datanode.DataNode BPServiceActor.java:blockReport:422 - Successfully sent block report 0x85fbd1f13b688b56,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 56 msecs for RPC and NN processing. Got back no commands.
2019-03-28 01:18:25,722 INFO  datanode.DataNode BPOfferService.java:updateActorStatesFromHeartbeat:576 - Namenode Block pool BP-583823579-130.127.133.65-1553757466424 (Datanode Uuid fe89b2a7-373a-41b1-ac9e-b7ce50a592aa) service to node-1-link-0/10.10.1.4:8020 trying to claim ACTIVE state with txid=1
2019-03-28 01:18:25,722 INFO  datanode.DataNode BPOfferService.java:updateActorStatesFromHeartbeat:588 - Acknowledging ACTIVE Namenode Block pool BP-583823579-130.127.133.65-1553757466424 (Datanode Uuid fe89b2a7-373a-41b1-ac9e-b7ce50a592aa) service to node-1-link-0/10.10.1.4:8020
2019-03-28 01:18:30,216 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741827_1003 src: /10.10.1.7:34782 dest: /10.10.1.2:9866
2019-03-28 01:18:30,333 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741830_1006 src: /10.10.1.7:34792 dest: /10.10.1.2:9866
2019-03-28 01:18:30,340 WARN  datanode.DataNode DataXceiverServer.java:run:168 - clnode080.clemson.cloudlab.us:9866:DataXceiverServer: 
java.io.IOException: Xceiver count 3 exceeds the limit of concurrent xcievers: 2
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:150)
	at java.lang.Thread.run(Thread.java:748)
2019-03-28 01:18:30,344 WARN  datanode.DataNode DataXceiverServer.java:run:168 - clnode080.clemson.cloudlab.us:9866:DataXceiverServer: 
java.io.IOException: Xceiver count 3 exceeds the limit of concurrent xcievers: 2
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:150)
	at java.lang.Thread.run(Thread.java:748)
2019-03-28 01:18:30,348 WARN  datanode.DataNode DataXceiverServer.java:run:168 - clnode080.clemson.cloudlab.us:9866:DataXceiverServer: 
java.io.IOException: Xceiver count 3 exceeds the limit of concurrent xcievers: 2
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:150)
	at java.lang.Thread.run(Thread.java:748)
2019-03-28 01:18:30,378 INFO  datanode.DataNode BlockReceiver.java:run:1454 - PacketResponder: BP-583823579-130.127.133.65-1553757466424:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[10.10.1.5:9866, 10.10.1.3:9866]
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:549)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:213)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1384)
	at java.lang.Thread.run(Thread.java:748)
2019-03-28 01:18:30,385 WARN  datanode.DataNode BlockReceiver.java:run:1489 - IOException in BlockReceiver.run(): 
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
	at sun.nio.ch.IOUtil.write(IOUtil.java:65)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:63)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:159)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:117)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)
	at java.io.DataOutputStream.flush(DataOutputStream.java:123)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.sendAckUpstreamUnprotected(BlockReceiver.java:1633)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.sendAckUpstream(BlockReceiver.java:1568)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1481)
	at java.lang.Thread.run(Thread.java:748)
2019-03-28 01:18:30,386 INFO  datanode.DataNode BlockReceiver.java:run:1492 - PacketResponder: BP-583823579-130.127.133.65-1553757466424:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[10.10.1.5:9866, 10.10.1.3:9866]
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
	at sun.nio.ch.IOUtil.write(IOUtil.java:65)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:63)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:159)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:117)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)
	at java.io.DataOutputStream.flush(DataOutputStream.java:123)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.sendAckUpstreamUnprotected(BlockReceiver.java:1633)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.sendAckUpstream(BlockReceiver.java:1568)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1481)
	at java.lang.Thread.run(Thread.java:748)
2019-03-28 01:18:30,385 INFO  datanode.DataNode BlockReceiver.java:receiveBlock:1010 - Exception for BP-583823579-130.127.133.65-1553757466424:blk_1073741827_1003
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:891)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2019-03-28 01:18:30,386 INFO  datanode.DataNode BlockReceiver.java:run:1506 - PacketResponder: BP-583823579-130.127.133.65-1553757466424:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[10.10.1.5:9866, 10.10.1.3:9866] terminating
2019-03-28 01:18:30,387 INFO  datanode.DataNode DataXceiver.java:writeBlock:922 - opWriteBlock BP-583823579-130.127.133.65-1553757466424:blk_1073741827_1003 received exception java.io.IOException: Premature EOF from inputStream
2019-03-28 01:18:30,390 ERROR datanode.DataNode DataXceiver.java:run:321 - clnode080.clemson.cloudlab.us:9866:DataXceiver error processing WRITE_BLOCK operation  src: /10.10.1.7:34782 dst: /10.10.1.2:9866
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:891)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2019-03-28 01:18:30,432 WARN  datanode.DataNode DataXceiverServer.java:run:168 - clnode080.clemson.cloudlab.us:9866:DataXceiverServer: 
java.io.IOException: Xceiver count 3 exceeds the limit of concurrent xcievers: 2
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:150)
	at java.lang.Thread.run(Thread.java:748)
2019-03-28 01:18:30,872 INFO  DataNode.clienttrace BlockReceiver.java:finalizeBlock:1533 - src: /10.10.1.7:34792, dest: /10.10.1.2:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_764555189_1, offset: 0, srvID: fe89b2a7-373a-41b1-ac9e-b7ce50a592aa, blockid: BP-583823579-130.127.133.65-1553757466424:blk_1073741830_1006, duration(ns): 519231768
2019-03-28 01:18:30,872 INFO  datanode.DataNode BlockReceiver.java:run:1506 - PacketResponder: BP-583823579-130.127.133.65-1553757466424:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[10.10.1.6:9866, 10.10.1.3:9866] terminating
2019-03-28 01:18:30,902 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741844_1020 src: /10.10.1.3:38558 dest: /10.10.1.2:9866
2019-03-28 01:18:31,316 INFO  DataNode.clienttrace BlockReceiver.java:finalizeBlock:1533 - src: /10.10.1.3:38558, dest: /10.10.1.2:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_764555189_1, offset: 0, srvID: fe89b2a7-373a-41b1-ac9e-b7ce50a592aa, blockid: BP-583823579-130.127.133.65-1553757466424:blk_1073741844_1020, duration(ns): 410304876
2019-03-28 01:18:31,316 INFO  datanode.DataNode BlockReceiver.java:run:1506 - PacketResponder: BP-583823579-130.127.133.65-1553757466424:blk_1073741844_1020, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.10.1.6:9866] terminating
2019-03-28 01:18:31,340 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741846_1022 src: /10.10.1.7:34824 dest: /10.10.1.2:9866
2019-03-28 01:18:31,733 INFO  DataNode.clienttrace BlockReceiver.java:finalizeBlock:1533 - src: /10.10.1.7:34824, dest: /10.10.1.2:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_764555189_1, offset: 0, srvID: fe89b2a7-373a-41b1-ac9e-b7ce50a592aa, blockid: BP-583823579-130.127.133.65-1553757466424:blk_1073741846_1022, duration(ns): 386758090
2019-03-28 01:18:31,734 INFO  datanode.DataNode BlockReceiver.java:run:1506 - PacketResponder: BP-583823579-130.127.133.65-1553757466424:blk_1073741846_1022, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[10.10.1.3:9866, 10.10.1.6:9866] terminating
2019-03-28 01:18:31,757 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741848_1024 src: /10.10.1.7:34828 dest: /10.10.1.2:9866
2019-03-28 01:18:32,152 INFO  DataNode.clienttrace BlockReceiver.java:finalizeBlock:1533 - src: /10.10.1.7:34828, dest: /10.10.1.2:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_764555189_1, offset: 0, srvID: fe89b2a7-373a-41b1-ac9e-b7ce50a592aa, blockid: BP-583823579-130.127.133.65-1553757466424:blk_1073741848_1024, duration(ns): 388770638
2019-03-28 01:18:32,152 INFO  datanode.DataNode BlockReceiver.java:run:1506 - PacketResponder: BP-583823579-130.127.133.65-1553757466424:blk_1073741848_1024, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[10.10.1.6:9866, 10.10.1.3:9866] terminating
2019-03-28 01:18:32,186 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741850_1026 src: /10.10.1.6:54916 dest: /10.10.1.2:9866
2019-03-28 01:18:32,545 INFO  DataNode.clienttrace BlockReceiver.java:finalizeBlock:1533 - src: /10.10.1.6:54916, dest: /10.10.1.2:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_764555189_1, offset: 0, srvID: fe89b2a7-373a-41b1-ac9e-b7ce50a592aa, blockid: BP-583823579-130.127.133.65-1553757466424:blk_1073741850_1026, duration(ns): 357737745
2019-03-28 01:18:32,546 INFO  datanode.DataNode BlockReceiver.java:run:1506 - PacketResponder: BP-583823579-130.127.133.65-1553757466424:blk_1073741850_1026, type=LAST_IN_PIPELINE terminating
2019-03-28 01:18:32,566 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741853_1029 src: /10.10.1.3:38564 dest: /10.10.1.2:9866
2019-03-28 01:18:32,948 INFO  DataNode.clienttrace BlockReceiver.java:finalizeBlock:1533 - src: /10.10.1.3:38564, dest: /10.10.1.2:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_764555189_1, offset: 0, srvID: fe89b2a7-373a-41b1-ac9e-b7ce50a592aa, blockid: BP-583823579-130.127.133.65-1553757466424:blk_1073741853_1029, duration(ns): 378229873
2019-03-28 01:18:32,949 INFO  datanode.DataNode BlockReceiver.java:run:1506 - PacketResponder: BP-583823579-130.127.133.65-1553757466424:blk_1073741853_1029, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.10.1.6:9866] terminating
2019-03-28 01:18:32,975 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741855_1031 src: /10.10.1.3:38566 dest: /10.10.1.2:9866
2019-03-28 01:18:33,359 INFO  DataNode.clienttrace BlockReceiver.java:finalizeBlock:1533 - src: /10.10.1.3:38566, dest: /10.10.1.2:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_764555189_1, offset: 0, srvID: fe89b2a7-373a-41b1-ac9e-b7ce50a592aa, blockid: BP-583823579-130.127.133.65-1553757466424:blk_1073741855_1031, duration(ns): 380818155
2019-03-28 01:18:33,359 INFO  datanode.DataNode BlockReceiver.java:run:1506 - PacketResponder: BP-583823579-130.127.133.65-1553757466424:blk_1073741855_1031, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.10.1.6:9866] terminating
2019-03-28 01:18:33,394 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741856_1032 src: /10.10.1.3:38568 dest: /10.10.1.2:9866
2019-03-28 01:18:33,753 INFO  DataNode.clienttrace BlockReceiver.java:finalizeBlock:1533 - src: /10.10.1.3:38568, dest: /10.10.1.2:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_764555189_1, offset: 0, srvID: fe89b2a7-373a-41b1-ac9e-b7ce50a592aa, blockid: BP-583823579-130.127.133.65-1553757466424:blk_1073741856_1032, duration(ns): 355725738
2019-03-28 01:18:33,754 INFO  datanode.DataNode BlockReceiver.java:run:1506 - PacketResponder: BP-583823579-130.127.133.65-1553757466424:blk_1073741856_1032, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.10.1.6:9866] terminating
2019-03-28 01:18:34,732 INFO  impl.FsDatasetAsyncDiskService FsDatasetAsyncDiskService.java:deleteAsync:225 - Scheduling blk_1073741827_1003 replica ReplicaBeingWritten, blk_1073741827_1003, RBW
  getNumBytes()     = 0
  getBytesOnDisk()  = 0
  getVisibleLength()= 0
  getVolume()       = /root/hdfs-root/data
  getBlockURI()     = file:/root/hdfs-root/data/current/BP-583823579-130.127.133.65-1553757466424/current/rbw/blk_1073741827
  bytesAcked=0
  bytesOnDisk=0 for deletion
2019-03-28 01:18:34,766 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741843_1019 src: /10.10.1.5:59520 dest: /10.10.1.2:9866
2019-03-28 01:18:36,167 WARN  datanode.DataNode BlockReceiver.java:receivePacket:598 - Slow BlockReceiver write packet to mirror took 311ms (threshold=300ms), downstream DNs=[10.10.1.6:9866], blockId=1073741843
2019-03-28 01:18:36,173 INFO  datanode.DataNode DataXceiver.java:writeBlock:914 - Received BP-583823579-130.127.133.65-1553757466424:blk_1073741843_1019 src: /10.10.1.5:59520 dest: /10.10.1.2:9866 of size 134217728
2019-03-28 01:18:36,252 INFO  impl.FsDatasetAsyncDiskService FsDatasetAsyncDiskService.java:run:333 - Deleted BP-583823579-130.127.133.65-1553757466424 blk_1073741827_1003 URI file:/root/hdfs-root/data/current/BP-583823579-130.127.133.65-1553757466424/current/rbw/blk_1073741827
2019-03-28 01:18:37,723 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741845_1021 src: /10.10.1.5:59522 dest: /10.10.1.2:9866
2019-03-28 01:18:37,725 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741847_1023 src: /10.10.1.6:54918 dest: /10.10.1.2:9866
2019-03-28 01:18:38,559 INFO  datanode.DataNode DataXceiver.java:writeBlock:914 - Received BP-583823579-130.127.133.65-1553757466424:blk_1073741845_1021 src: /10.10.1.5:59522 dest: /10.10.1.2:9866 of size 134217728
2019-03-28 01:18:38,640 INFO  datanode.DataNode DataXceiver.java:writeBlock:914 - Received BP-583823579-130.127.133.65-1553757466424:blk_1073741847_1023 src: /10.10.1.6:54918 dest: /10.10.1.2:9866 of size 134217728
2019-03-28 01:18:40,722 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741849_1025 src: /10.10.1.5:59526 dest: /10.10.1.2:9866
2019-03-28 01:18:42,076 INFO  datanode.DataNode BlockReceiver.java:handleMirrorOutError:453 - DatanodeRegistration(10.10.1.2:9866, datanodeUuid=fe89b2a7-373a-41b1-ac9e-b7ce50a592aa, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-cc1c02d7-b8dd-4817-9128-117cf6935e36;nsid=868784382;c=1553757466424):Exception writing BP-583823579-130.127.133.65-1553757466424:blk_1073741849_1025 to mirror 10.10.1.3:9866
java.io.IOException: Broken pipe
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
	at sun.nio.ch.IOUtil.write(IOUtil.java:65)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:63)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:159)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:117)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.mirrorPacketTo(PacketReceiver.java:198)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:588)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:891)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:748)
2019-03-28 01:18:43,917 INFO  datanode.DataNode DataXceiver.java:writeBlock:914 - Received BP-583823579-130.127.133.65-1553757466424:blk_1073741849_1025 src: /10.10.1.5:59526 dest: /10.10.1.2:9866 of size 134217728
2019-03-28 01:18:46,722 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741854_1030 src: /10.10.1.5:59532 dest: /10.10.1.2:9866
2019-03-28 01:18:47,885 INFO  datanode.DataNode DataXceiver.java:writeBlock:914 - Received BP-583823579-130.127.133.65-1553757466424:blk_1073741854_1030 src: /10.10.1.5:59532 dest: /10.10.1.2:9866 of size 134217728
2019-03-28 01:19:14,316 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741857_1033 src: /10.10.1.6:54924 dest: /10.10.1.2:9866
2019-03-28 01:19:14,768 WARN  datanode.DataNode DataXceiverServer.java:run:168 - clnode080.clemson.cloudlab.us:9866:DataXceiverServer: 
java.io.IOException: Xceiver count 4 exceeds the limit of concurrent xcievers: 2
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:150)
	at java.lang.Thread.run(Thread.java:748)
2019-03-28 01:19:14,826 INFO  DataNode.clienttrace BlockReceiver.java:finalizeBlock:1533 - src: /10.10.1.6:54924, dest: /10.10.1.2:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1886606182_1, offset: 0, srvID: fe89b2a7-373a-41b1-ac9e-b7ce50a592aa, blockid: BP-583823579-130.127.133.65-1553757466424:blk_1073741857_1033, duration(ns): 507940241
2019-03-28 01:19:14,826 INFO  datanode.DataNode BlockReceiver.java:run:1506 - PacketResponder: BP-583823579-130.127.133.65-1553757466424:blk_1073741857_1033, type=LAST_IN_PIPELINE terminating
2019-03-28 01:19:14,852 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741861_1037 src: /10.10.1.7:35100 dest: /10.10.1.2:9866
2019-03-28 01:19:15,042 WARN  datanode.DataNode DataXceiverServer.java:run:168 - clnode080.clemson.cloudlab.us:9866:DataXceiverServer: 
java.io.IOException: Xceiver count 4 exceeds the limit of concurrent xcievers: 2
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:150)
	at java.lang.Thread.run(Thread.java:748)
2019-03-28 01:19:15,232 INFO  DataNode.clienttrace BlockReceiver.java:finalizeBlock:1533 - src: /10.10.1.7:35100, dest: /10.10.1.2:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1886606182_1, offset: 0, srvID: fe89b2a7-373a-41b1-ac9e-b7ce50a592aa, blockid: BP-583823579-130.127.133.65-1553757466424:blk_1073741861_1037, duration(ns): 374730417
2019-03-28 01:19:15,233 INFO  datanode.DataNode BlockReceiver.java:run:1506 - PacketResponder: BP-583823579-130.127.133.65-1553757466424:blk_1073741861_1037, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[10.10.1.5:9866, 10.10.1.6:9866] terminating
2019-03-28 01:19:15,266 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741868_1044 src: /10.10.1.6:54926 dest: /10.10.1.2:9866
2019-03-28 01:19:15,660 INFO  DataNode.clienttrace BlockReceiver.java:finalizeBlock:1533 - src: /10.10.1.6:54926, dest: /10.10.1.2:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1886606182_1, offset: 0, srvID: fe89b2a7-373a-41b1-ac9e-b7ce50a592aa, blockid: BP-583823579-130.127.133.65-1553757466424:blk_1073741868_1044, duration(ns): 389416709
2019-03-28 01:19:15,660 INFO  datanode.DataNode BlockReceiver.java:run:1506 - PacketResponder: BP-583823579-130.127.133.65-1553757466424:blk_1073741868_1044, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.10.1.5:9866] terminating
2019-03-28 01:19:15,685 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741870_1046 src: /10.10.1.7:35116 dest: /10.10.1.2:9866
2019-03-28 01:19:16,077 INFO  DataNode.clienttrace BlockReceiver.java:finalizeBlock:1533 - src: /10.10.1.7:35116, dest: /10.10.1.2:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1886606182_1, offset: 0, srvID: fe89b2a7-373a-41b1-ac9e-b7ce50a592aa, blockid: BP-583823579-130.127.133.65-1553757466424:blk_1073741870_1046, duration(ns): 386062844
2019-03-28 01:19:16,078 INFO  datanode.DataNode BlockReceiver.java:run:1506 - PacketResponder: BP-583823579-130.127.133.65-1553757466424:blk_1073741870_1046, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[10.10.1.5:9866, 10.10.1.6:9866] terminating
2019-03-28 01:19:16,161 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741873_1049 src: /10.10.1.5:59540 dest: /10.10.1.2:9866
2019-03-28 01:19:16,396 WARN  datanode.DataNode DataXceiverServer.java:run:168 - clnode080.clemson.cloudlab.us:9866:DataXceiverServer: 
java.io.IOException: Xceiver count 4 exceeds the limit of concurrent xcievers: 2
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:150)
	at java.lang.Thread.run(Thread.java:748)
2019-03-28 01:19:16,433 WARN  datanode.DataNode DataXceiverServer.java:run:168 - clnode080.clemson.cloudlab.us:9866:DataXceiverServer: 
java.io.IOException: Xceiver count 4 exceeds the limit of concurrent xcievers: 2
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:150)
	at java.lang.Thread.run(Thread.java:748)
2019-03-28 01:19:16,543 INFO  DataNode.clienttrace BlockReceiver.java:finalizeBlock:1533 - src: /10.10.1.5:59540, dest: /10.10.1.2:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1886606182_1, offset: 0, srvID: fe89b2a7-373a-41b1-ac9e-b7ce50a592aa, blockid: BP-583823579-130.127.133.65-1553757466424:blk_1073741873_1049, duration(ns): 378447269
2019-03-28 01:19:16,543 INFO  datanode.DataNode BlockReceiver.java:run:1506 - PacketResponder: BP-583823579-130.127.133.65-1553757466424:blk_1073741873_1049, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.10.1.6:9866] terminating
2019-03-28 01:19:16,875 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741876_1052 src: /10.10.1.7:35144 dest: /10.10.1.2:9866
2019-03-28 01:19:17,252 INFO  DataNode.clienttrace BlockReceiver.java:finalizeBlock:1533 - src: /10.10.1.7:35144, dest: /10.10.1.2:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1886606182_1, offset: 0, srvID: fe89b2a7-373a-41b1-ac9e-b7ce50a592aa, blockid: BP-583823579-130.127.133.65-1553757466424:blk_1073741876_1052, duration(ns): 371444681
2019-03-28 01:19:17,252 INFO  datanode.DataNode BlockReceiver.java:run:1506 - PacketResponder: BP-583823579-130.127.133.65-1553757466424:blk_1073741876_1052, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[10.10.1.5:9866, 10.10.1.6:9866] terminating
2019-03-28 01:19:17,276 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741878_1054 src: /10.10.1.7:35150 dest: /10.10.1.2:9866
2019-03-28 01:19:17,662 INFO  DataNode.clienttrace BlockReceiver.java:finalizeBlock:1533 - src: /10.10.1.7:35150, dest: /10.10.1.2:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1886606182_1, offset: 0, srvID: fe89b2a7-373a-41b1-ac9e-b7ce50a592aa, blockid: BP-583823579-130.127.133.65-1553757466424:blk_1073741878_1054, duration(ns): 380737217
2019-03-28 01:19:17,662 INFO  datanode.DataNode BlockReceiver.java:run:1506 - PacketResponder: BP-583823579-130.127.133.65-1553757466424:blk_1073741878_1054, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[10.10.1.6:9866, 10.10.1.5:9866] terminating
2019-03-28 01:19:17,804 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741880_1056 src: /10.10.1.7:35158 dest: /10.10.1.2:9866
2019-03-28 01:19:18,181 INFO  DataNode.clienttrace BlockReceiver.java:finalizeBlock:1533 - src: /10.10.1.7:35158, dest: /10.10.1.2:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1886606182_1, offset: 0, srvID: fe89b2a7-373a-41b1-ac9e-b7ce50a592aa, blockid: BP-583823579-130.127.133.65-1553757466424:blk_1073741880_1056, duration(ns): 371899996
2019-03-28 01:19:18,181 INFO  datanode.DataNode BlockReceiver.java:run:1506 - PacketResponder: BP-583823579-130.127.133.65-1553757466424:blk_1073741880_1056, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[10.10.1.5:9866, 10.10.1.6:9866] terminating
2019-03-28 01:19:19,741 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741862_1038 src: /10.10.1.5:59548 dest: /10.10.1.2:9866
2019-03-28 01:19:20,785 INFO  datanode.DataNode DataXceiver.java:writeBlock:914 - Received BP-583823579-130.127.133.65-1553757466424:blk_1073741862_1038 src: /10.10.1.5:59548 dest: /10.10.1.2:9866 of size 134217728
2019-03-28 01:19:22,727 WARN  datanode.DataNode DataXceiverServer.java:run:168 - clnode080.clemson.cloudlab.us:9866:DataXceiverServer: 
java.io.IOException: Xceiver count 3 exceeds the limit of concurrent xcievers: 2
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:150)
	at java.lang.Thread.run(Thread.java:748)
2019-03-28 01:19:23,500 WARN  datanode.DataNode DataXceiverServer.java:run:168 - clnode080.clemson.cloudlab.us:9866:DataXceiverServer: 
java.io.IOException: Xceiver count 3 exceeds the limit of concurrent xcievers: 2
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:150)
	at java.lang.Thread.run(Thread.java:748)
2019-03-28 01:19:25,730 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741875_1051 src: /10.10.1.6:54932 dest: /10.10.1.2:9866
2019-03-28 01:19:26,951 INFO  datanode.DataNode DataXceiver.java:writeBlock:914 - Received BP-583823579-130.127.133.65-1553757466424:blk_1073741875_1051 src: /10.10.1.6:54932 dest: /10.10.1.2:9866 of size 134217728
2019-03-28 01:19:28,728 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741877_1053 src: /10.10.1.3:38590 dest: /10.10.1.2:9866
2019-03-28 01:19:28,730 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741879_1055 src: /10.10.1.5:59550 dest: /10.10.1.2:9866
2019-03-28 01:19:29,465 WARN  datanode.DataNode DataXceiverServer.java:run:168 - clnode080.clemson.cloudlab.us:9866:DataXceiverServer: 
java.io.IOException: Xceiver count 3 exceeds the limit of concurrent xcievers: 2
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:150)
	at java.lang.Thread.run(Thread.java:748)
2019-03-28 01:19:29,822 INFO  datanode.DataNode DataXceiver.java:writeBlock:914 - Received BP-583823579-130.127.133.65-1553757466424:blk_1073741877_1053 src: /10.10.1.3:38590 dest: /10.10.1.2:9866 of size 134217728
2019-03-28 01:19:29,993 INFO  datanode.DataNode DataXceiver.java:writeBlock:914 - Received BP-583823579-130.127.133.65-1553757466424:blk_1073741879_1055 src: /10.10.1.5:59550 dest: /10.10.1.2:9866 of size 134217728
2019-03-28 01:19:40,258 WARN  datanode.DataNode DataXceiverServer.java:run:168 - clnode080.clemson.cloudlab.us:9866:DataXceiverServer: 
java.io.IOException: Xceiver count 3 exceeds the limit of concurrent xcievers: 2
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:150)
	at java.lang.Thread.run(Thread.java:748)
2019-03-28 01:19:41,682 WARN  datanode.DataNode DataXceiverServer.java:run:168 - clnode080.clemson.cloudlab.us:9866:DataXceiverServer: 
java.io.IOException: Xceiver count 3 exceeds the limit of concurrent xcievers: 2
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:150)
	at java.lang.Thread.run(Thread.java:748)
2019-03-28 01:19:48,084 WARN  datanode.DataNode DataXceiverServer.java:run:168 - clnode080.clemson.cloudlab.us:9866:DataXceiverServer: 
java.io.IOException: Xceiver count 3 exceeds the limit of concurrent xcievers: 2
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:150)
	at java.lang.Thread.run(Thread.java:748)
2019-03-28 01:19:48,387 WARN  datanode.DataNode DataXceiverServer.java:run:168 - clnode080.clemson.cloudlab.us:9866:DataXceiverServer: 
java.io.IOException: Xceiver count 3 exceeds the limit of concurrent xcievers: 2
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:150)
	at java.lang.Thread.run(Thread.java:748)
2019-03-28 01:19:55,394 WARN  datanode.DataNode DataXceiverServer.java:run:168 - clnode080.clemson.cloudlab.us:9866:DataXceiverServer: 
java.io.IOException: Xceiver count 3 exceeds the limit of concurrent xcievers: 2
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:150)
	at java.lang.Thread.run(Thread.java:748)
2019-03-28 01:19:56,149 WARN  datanode.DataNode DataXceiverServer.java:run:168 - clnode080.clemson.cloudlab.us:9866:DataXceiverServer: 
java.io.IOException: Xceiver count 3 exceeds the limit of concurrent xcievers: 2
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:150)
	at java.lang.Thread.run(Thread.java:748)
2019-03-28 01:20:01,094 WARN  datanode.DataNode DataXceiverServer.java:run:168 - clnode080.clemson.cloudlab.us:9866:DataXceiverServer: 
java.io.IOException: Xceiver count 3 exceeds the limit of concurrent xcievers: 2
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:150)
	at java.lang.Thread.run(Thread.java:748)
2019-03-28 01:20:05,877 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741890_1066 src: /10.10.1.5:59564 dest: /10.10.1.2:9866
2019-03-28 01:20:06,294 INFO  DataNode.clienttrace BlockReceiver.java:finalizeBlock:1533 - src: /10.10.1.5:59564, dest: /10.10.1.2:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1743046858_1, offset: 0, srvID: fe89b2a7-373a-41b1-ac9e-b7ce50a592aa, blockid: BP-583823579-130.127.133.65-1553757466424:blk_1073741890_1066, duration(ns): 415167665
2019-03-28 01:20:06,294 INFO  datanode.DataNode BlockReceiver.java:run:1506 - PacketResponder: BP-583823579-130.127.133.65-1553757466424:blk_1073741890_1066, type=LAST_IN_PIPELINE terminating
2019-03-28 01:20:06,336 INFO  datanode.DataNode DataXceiver.java:writeBlock:738 - Receiving BP-583823579-130.127.133.65-1553757466424:blk_1073741891_1067 src: /10.10.1.6:54948 dest: /10.10.1.2:9866
2019-03-28 01:20:06,701 INFO  DataNode.clienttrace BlockReceiver.java:finalizeBlock:1533 - src: /10.10.1.6:54948, dest: /10.10.1.2:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1743046858_1, offset: 0, srvID: fe89b2a7-373a-41b1-ac9e-b7ce50a592aa, blockid: BP-583823579-130.127.133.65-1553757466424:blk_1073741891_1067, duration(ns): 362242448
2019-03-28 01:20:06,701 INFO  datanode.DataNode BlockReceiver.java:run:1506 - PacketResponder: BP-583823579-130.127.133.65-1553757466424:blk_1073741891_1067, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.10.1.3:9866] terminating
2019-03-28 01:20:07,719 INFO  impl.FsDatasetAsyncDiskService FsDatasetAsyncDiskService.java:deleteAsync:225 - Scheduling blk_1073741856_1032 replica FinalizedReplica, blk_1073741856_1032, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/hdfs-root/data
  getBlockURI()     = file:/root/hdfs-root/data/current/BP-583823579-130.127.133.65-1553757466424/current/finalized/subdir0/subdir0/blk_1073741856 for deletion
2019-03-28 01:20:07,720 INFO  impl.FsDatasetAsyncDiskService FsDatasetAsyncDiskService.java:deleteAsync:225 - Scheduling blk_1073741844_1020 replica FinalizedReplica, blk_1073741844_1020, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/hdfs-root/data
  getBlockURI()     = file:/root/hdfs-root/data/current/BP-583823579-130.127.133.65-1553757466424/current/finalized/subdir0/subdir0/blk_1073741844 for deletion
2019-03-28 01:20:07,720 INFO  impl.FsDatasetAsyncDiskService FsDatasetAsyncDiskService.java:deleteAsync:225 - Scheduling blk_1073741830_1006 replica FinalizedReplica, blk_1073741830_1006, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/hdfs-root/data
  getBlockURI()     = file:/root/hdfs-root/data/current/BP-583823579-130.127.133.65-1553757466424/current/finalized/subdir0/subdir0/blk_1073741830 for deletion
2019-03-28 01:20:07,720 INFO  impl.FsDatasetAsyncDiskService FsDatasetAsyncDiskService.java:deleteAsync:225 - Scheduling blk_1073741846_1022 replica FinalizedReplica, blk_1073741846_1022, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/hdfs-root/data
  getBlockURI()     = file:/root/hdfs-root/data/current/BP-583823579-130.127.133.65-1553757466424/current/finalized/subdir0/subdir0/blk_1073741846 for deletion
2019-03-28 01:20:07,721 INFO  impl.FsDatasetAsyncDiskService FsDatasetAsyncDiskService.java:deleteAsync:225 - Scheduling blk_1073741848_1024 replica FinalizedReplica, blk_1073741848_1024, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/hdfs-root/data
  getBlockURI()     = file:/root/hdfs-root/data/current/BP-583823579-130.127.133.65-1553757466424/current/finalized/subdir0/subdir0/blk_1073741848 for deletion
2019-03-28 01:20:07,721 INFO  impl.FsDatasetAsyncDiskService FsDatasetAsyncDiskService.java:deleteAsync:225 - Scheduling blk_1073741850_1026 replica FinalizedReplica, blk_1073741850_1026, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/hdfs-root/data
  getBlockURI()     = file:/root/hdfs-root/data/current/BP-583823579-130.127.133.65-1553757466424/current/finalized/subdir0/subdir0/blk_1073741850 for deletion
2019-03-28 01:20:07,721 INFO  impl.FsDatasetAsyncDiskService FsDatasetAsyncDiskService.java:deleteAsync:225 - Scheduling blk_1073741853_1029 replica FinalizedReplica, blk_1073741853_1029, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/hdfs-root/data
  getBlockURI()     = file:/root/hdfs-root/data/current/BP-583823579-130.127.133.65-1553757466424/current/finalized/subdir0/subdir0/blk_1073741853 for deletion
2019-03-28 01:20:07,722 INFO  impl.FsDatasetAsyncDiskService FsDatasetAsyncDiskService.java:deleteAsync:225 - Scheduling blk_1073741855_1031 replica FinalizedReplica, blk_1073741855_1031, FINALIZED
  getNumBytes()     = 134217728
  getBytesOnDisk()  = 134217728
  getVisibleLength()= 134217728
  getVolume()       = /root/hdfs-root/data
  getBlockURI()     = file:/root/hdfs-root/data/current/BP-583823579-130.127.133.65-1553757466424/current/finalized/subdir0/subdir0/blk_1073741855 for deletion
2019-03-28 01:20:07,743 INFO  impl.FsDatasetAsyncDiskService FsDatasetAsyncDiskService.java:run:333 - Deleted BP-583823579-130.127.133.65-1553757466424 blk_1073741856_1032 URI file:/root/hdfs-root/data/current/BP-583823579-130.127.133.65-1553757466424/current/finalized/subdir0/subdir0/blk_1073741856
2019-03-28 01:20:07,768 INFO  impl.FsDatasetAsyncDiskService FsDatasetAsyncDiskService.java:run:333 - Deleted BP-583823579-130.127.133.65-1553757466424 blk_1073741844_1020 URI file:/root/hdfs-root/data/current/BP-583823579-130.127.133.65-1553757466424/current/finalized/subdir0/subdir0/blk_1073741844
2019-03-28 01:20:07,793 INFO  impl.FsDatasetAsyncDiskService FsDatasetAsyncDiskService.java:run:333 - Deleted BP-583823579-130.127.133.65-1553757466424 blk_1073741830_1006 URI file:/root/hdfs-root/data/current/BP-583823579-130.127.133.65-1553757466424/current/finalized/subdir0/subdir0/blk_1073741830
2019-03-28 01:20:07,818 INFO  impl.FsDatasetAsyncDiskService FsDatasetAsyncDiskService.java:run:333 - Deleted BP-583823579-130.127.133.65-1553757466424 blk_1073741846_1022 URI file:/root/hdfs-root/data/current/BP-583823579-130.127.133.65-1553757466424/current/finalized/subdir0/subdir0/blk_1073741846
2019-03-28 01:20:07,843 INFO  impl.FsDatasetAsyncDiskService FsDatasetAsyncDiskService.java:run:333 - Deleted BP-583823579-130.127.133.65-1553757466424 blk_1073741848_1024 URI file:/root/hdfs-root/data/current/BP-583823579-130.127.133.65-1553757466424/current/finalized/subdir0/subdir0/blk_1073741848
2019-03-28 01:20:07,868 INFO  impl.FsDatasetAsyncDiskService FsDatasetAsyncDiskService.java:run:333 - Deleted BP-583823579-130.127.133.65-1553757466424 blk_1073741850_1026 URI file:/root/hdfs-root/data/current/BP-583823579-130.127.133.65-1553757466424/current/finalized/subdir0/subdir0/blk_1073741850
2019-03-28 01:20:07,892 INFO  impl.FsDatasetAsyncDiskService FsDatasetAsyncDiskService.java:run:333 - Deleted BP-583823579-130.127.133.65-1553757466424 blk_1073741853_1029 URI file:/root/hdfs-root/data/current/BP-583823579-130.127.133.65-1553757466424/current/finalized/subdir0/subdir0/blk_1073741853
2019-03-28 01:20:07,916 INFO  impl.FsDatasetAsyncDiskService FsDatasetAsyncDiskService.java:run:333 - Deleted BP-583823579-130.127.133.65-1553757466424 blk_1073741855_1031 URI file:/root/hdfs-root/data/current/BP-583823579-130.127.133.65-1553757466424/current/finalized/subdir0/subdir0/blk_1073741855
